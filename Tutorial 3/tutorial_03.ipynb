{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "918a149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58103ac6",
   "metadata": {},
   "source": [
    "### First, we load the titatic dataset and convert all categorical variables to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "de2501c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass        Age     Fare  Sex_female  Sex_male   \n0              1         0       3  22.000000   7.2500       False      True  \\\n1              2         1       1  38.000000  71.2833        True     False   \n2              3         1       3  26.000000   7.9250        True     False   \n3              4         1       1  35.000000  53.1000        True     False   \n4              5         0       3  35.000000   8.0500       False      True   \n..           ...       ...     ...        ...      ...         ...       ...   \n886          887         0       2  27.000000  13.0000       False      True   \n887          888         1       1  19.000000  30.0000        True     False   \n888          889         0       3  29.699118  23.4500        True     False   \n889          890         1       1  26.000000  30.0000       False      True   \n890          891         0       3  32.000000   7.7500       False      True   \n\n     Embarked_C  Embarked_Q  Embarked_S  \n0         False       False        True  \n1          True       False       False  \n2         False       False        True  \n3         False       False        True  \n4         False       False        True  \n..          ...         ...         ...  \n886       False       False        True  \n887       False       False        True  \n888       False       False        True  \n889        True       False       False  \n890       False        True       False  \n\n[891 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>22.000000</td>\n      <td>7.2500</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>38.000000</td>\n      <td>71.2833</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>26.000000</td>\n      <td>7.9250</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.000000</td>\n      <td>53.1000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>35.000000</td>\n      <td>8.0500</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>27.000000</td>\n      <td>13.0000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>19.000000</td>\n      <td>30.0000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>29.699118</td>\n      <td>23.4500</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>26.000000</td>\n      <td>30.0000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>32.000000</td>\n      <td>7.7500</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.read_csv('titanic.csv')\n",
    "data_frame = data_frame.drop(['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'], axis=1)\n",
    "data_frame = pd.get_dummies(data_frame, columns=['Sex', 'Embarked'])\n",
    "data_frame = data_frame.fillna(data_frame.mean())\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d57442",
   "metadata": {},
   "source": [
    "### Next, we convert the dataset to a NumPy array and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d69c4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_frame[['Survived']].to_numpy().astype(float)\n",
    "observ = data_frame.drop(['PassengerId', 'Survived'], axis=1).to_numpy().astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(observ, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55cc6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to normalize Age and Fare, so columns 0,3\n",
    "age_min, age_max = min(data_frame['Age']), max(data_frame['Age'])\n",
    "fare_min, fare_max = min(data_frame['Fare']), max(data_frame['Fare'])\n",
    "\"\"\"age_min, age_max = data_frame['Age'].min(), data_frame['Age'].min()\n",
    "fare_min, fare_max = data_frame['Fare'].max(), data_frame['Fare'].max()\"\"\"\n",
    "# Apply\n",
    "X_train[:,0] = (X_train[:,0] - age_min) / (age_max - age_min + 1e-5)\n",
    "X_test[:,0] = (X_test[:,0] - age_min) / (age_max - age_min + 1e-5)\n",
    "X_train[:,3] = (X_train[:,3] - fare_min) / (fare_max - fare_min + 1e-5)\n",
    "X_test[:,3] = (X_test[:,3] - fare_min) / (fare_max - fare_min + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c978636",
   "metadata": {},
   "source": [
    "### Now, let's create our sequential model with four linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c5ad6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "first_model = nn.Sequential(\n",
    "    nn.Linear(len(observ[0]), 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(64, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d05f0",
   "metadata": {},
   "source": [
    "### We can already apply it to our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "05f5b5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=8, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=256, out_features=128, bias=True)\n  (4): ReLU()\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=128, out_features=64, bias=True)\n  (7): ReLU()\n  (8): Dropout(p=0.5, inplace=False)\n  (9): Linear(in_features=64, out_features=1, bias=True)\n  (10): Sigmoid()\n)"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model(torch.tensor(X_test[:20], dtype=torch.float))\n",
    "first_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e2188",
   "metadata": {},
   "source": [
    "### Now, let's fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e6631ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[97], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mfirst_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m(X_train, y_train, X_test, y_test)\n",
      "File \u001B[1;32m~\\PycharmProjects\\deeplearningvm\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Sequential' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "first_model.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44284ecb",
   "metadata": {},
   "source": [
    "### As you may have seen, this does not work. We have to implement the training ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "de5b3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLPModel(nn.Module):\n",
    "    def __init__(self, input, *hidden_layers, lr=0.07, dropout=0.2):\n",
    "        super().__init__() # <- Very important!\n",
    "        self.lr = lr\n",
    "        ## Build model\n",
    "        n_neurons = [input] + list(hidden_layers)\n",
    "        self.layers = []\n",
    "        for i, o in zip(n_neurons[:-1], n_neurons[1:]):\n",
    "            self.layers += [\n",
    "                    nn.Linear(i, o),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(dropout),\n",
    "            ]\n",
    "        self.layers += [\n",
    "                nn.Linear(n_neurons[-1], 1),\n",
    "                nn.Sigmoid()\n",
    "        ]\n",
    "        \n",
    "        self.layers = nn.Sequential(*self.layers) # Create a sequential model\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "    \n",
    "    def predict(self, X, th=0.5):\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            y_hat = self.forward(X)\n",
    "        return (y_hat >= th).float()\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        y_hat = self.forward(X)\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "        \n",
    "    def validation_step(self, X, y):\n",
    "        with torch.no_grad():\n",
    "            return self.train_step(X, y)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_valid, y_valid, epochs=10):\n",
    "        ## Convert dataset\n",
    "        X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float)\n",
    "        \n",
    "        X_valid = torch.tensor(X_valid, dtype=torch.float)\n",
    "        y_valid = torch.tensor(y_valid, dtype=torch.float)\n",
    "        \n",
    "        ## Load Optimizer\n",
    "        optimizer = self.configure_optimizers()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f'{epoch+1}/{epochs}:')\n",
    "            # Training\n",
    "            self.train() # Set model to training mode\n",
    "            optimizer.zero_grad() # Sets all gradients to Zero\n",
    "            loss = self.train_step(X_train, y_train) # Execute Forward pass and calculate Loss\n",
    "            loss.backward() # Execute Backward pass\n",
    "            optimizer.step() # Update weights\n",
    "            self.eval() # Set model to validation mode\n",
    "            \n",
    "            # Validation\n",
    "            loss_valid = self.validation_step(X_valid, y_valid)\n",
    "            print(f'Training Loss: {loss.item():1.4f}', f'Validation Loss: {loss_valid.item():1.4f}')\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4f12f",
   "metadata": {},
   "source": [
    "### Create a model similar to the one before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7cdd767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "MyMLPModel(\n  (layers): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=32, out_features=16, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.2, inplace=False)\n    (6): Linear(in_features=16, out_features=8, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.2, inplace=False)\n    (9): Linear(in_features=8, out_features=4, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.2, inplace=False)\n    (12): Linear(in_features=4, out_features=1, bias=True)\n    (13): Sigmoid()\n  )\n)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_model = MyMLPModel(X_train.shape[1], 32, 16, 8, 4)\n",
    "second_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ef8b6bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.]])"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_model.predict(X_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee888a",
   "metadata": {},
   "source": [
    "### Train it and calculate the test accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1343e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.4983\n",
      "2/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5080\n",
      "3/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4989\n",
      "4/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5014\n",
      "5/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5009\n",
      "6/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5008\n",
      "7/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5043\n",
      "8/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5291\n",
      "9/15000:\n",
      "Training Loss: 0.5345 Validation Loss: 0.5137\n",
      "10/15000:\n",
      "Training Loss: 0.5234 Validation Loss: 0.4984\n",
      "11/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5004\n",
      "12/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.4984\n",
      "13/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4980\n",
      "14/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.5014\n",
      "15/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5027\n",
      "16/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.4948\n",
      "17/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.4964\n",
      "18/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.4963\n",
      "19/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5054\n",
      "20/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5101\n",
      "21/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5036\n",
      "22/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5014\n",
      "23/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5011\n",
      "24/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5058\n",
      "25/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5003\n",
      "26/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5044\n",
      "27/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5095\n",
      "28/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5096\n",
      "29/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5076\n",
      "30/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5096\n",
      "31/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5058\n",
      "32/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5054\n",
      "33/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.4959\n",
      "34/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.4993\n",
      "35/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.4994\n",
      "36/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4985\n",
      "37/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.4966\n",
      "38/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4948\n",
      "39/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.4956\n",
      "40/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.4970\n",
      "41/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4998\n",
      "42/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5030\n",
      "43/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5317\n",
      "44/15000:\n",
      "Training Loss: 0.5294 Validation Loss: 0.5293\n",
      "45/15000:\n",
      "Training Loss: 0.5614 Validation Loss: 0.5507\n",
      "46/15000:\n",
      "Training Loss: 0.5639 Validation Loss: 0.5910\n",
      "47/15000:\n",
      "Training Loss: 0.6403 Validation Loss: 0.5588\n",
      "48/15000:\n",
      "Training Loss: 0.5956 Validation Loss: 0.5671\n",
      "49/15000:\n",
      "Training Loss: 0.6179 Validation Loss: 0.5140\n",
      "50/15000:\n",
      "Training Loss: 0.5311 Validation Loss: 0.5157\n",
      "51/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5174\n",
      "52/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5044\n",
      "53/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5063\n",
      "54/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5050\n",
      "55/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5056\n",
      "56/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5010\n",
      "57/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5036\n",
      "58/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5059\n",
      "59/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5001\n",
      "60/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5036\n",
      "61/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5055\n",
      "62/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5218\n",
      "63/15000:\n",
      "Training Loss: 0.5296 Validation Loss: 0.5249\n",
      "64/15000:\n",
      "Training Loss: 0.5378 Validation Loss: 0.5264\n",
      "65/15000:\n",
      "Training Loss: 0.5176 Validation Loss: 0.5121\n",
      "66/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5192\n",
      "67/15000:\n",
      "Training Loss: 0.5377 Validation Loss: 0.5188\n",
      "68/15000:\n",
      "Training Loss: 0.5286 Validation Loss: 0.5214\n",
      "69/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5240\n",
      "70/15000:\n",
      "Training Loss: 0.5570 Validation Loss: 0.5639\n",
      "71/15000:\n",
      "Training Loss: 0.5926 Validation Loss: 0.8957\n",
      "72/15000:\n",
      "Training Loss: 0.8884 Validation Loss: 0.5248\n",
      "73/15000:\n",
      "Training Loss: 0.5520 Validation Loss: 0.5261\n",
      "74/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.5245\n",
      "75/15000:\n",
      "Training Loss: 0.5393 Validation Loss: 0.5269\n",
      "76/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.5270\n",
      "77/15000:\n",
      "Training Loss: 0.5359 Validation Loss: 0.5237\n",
      "78/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5292\n",
      "79/15000:\n",
      "Training Loss: 0.5235 Validation Loss: 0.5240\n",
      "80/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5199\n",
      "81/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5213\n",
      "82/15000:\n",
      "Training Loss: 0.5303 Validation Loss: 0.5115\n",
      "83/15000:\n",
      "Training Loss: 0.5316 Validation Loss: 0.5232\n",
      "84/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5156\n",
      "85/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.5172\n",
      "86/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5139\n",
      "87/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.5108\n",
      "88/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5160\n",
      "89/15000:\n",
      "Training Loss: 0.5241 Validation Loss: 0.5110\n",
      "90/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5090\n",
      "91/15000:\n",
      "Training Loss: 0.5187 Validation Loss: 0.5090\n",
      "92/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5116\n",
      "93/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5171\n",
      "94/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5151\n",
      "95/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5090\n",
      "96/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5140\n",
      "97/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5101\n",
      "98/15000:\n",
      "Training Loss: 0.5221 Validation Loss: 0.5088\n",
      "99/15000:\n",
      "Training Loss: 0.5281 Validation Loss: 0.5192\n",
      "100/15000:\n",
      "Training Loss: 0.5341 Validation Loss: 0.5176\n",
      "101/15000:\n",
      "Training Loss: 0.5586 Validation Loss: 0.5439\n",
      "102/15000:\n",
      "Training Loss: 0.5308 Validation Loss: 0.5318\n",
      "103/15000:\n",
      "Training Loss: 0.5536 Validation Loss: 0.5272\n",
      "104/15000:\n",
      "Training Loss: 0.5450 Validation Loss: 0.5116\n",
      "105/15000:\n",
      "Training Loss: 0.5323 Validation Loss: 0.5169\n",
      "106/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5110\n",
      "107/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.5195\n",
      "108/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.5154\n",
      "109/15000:\n",
      "Training Loss: 0.5277 Validation Loss: 0.5097\n",
      "110/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5149\n",
      "111/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.5174\n",
      "112/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5184\n",
      "113/15000:\n",
      "Training Loss: 0.5384 Validation Loss: 0.5497\n",
      "114/15000:\n",
      "Training Loss: 0.5591 Validation Loss: 0.6329\n",
      "115/15000:\n",
      "Training Loss: 0.6731 Validation Loss: 0.5297\n",
      "116/15000:\n",
      "Training Loss: 0.5684 Validation Loss: 0.5153\n",
      "117/15000:\n",
      "Training Loss: 0.5409 Validation Loss: 0.5414\n",
      "118/15000:\n",
      "Training Loss: 0.5568 Validation Loss: 0.5773\n",
      "119/15000:\n",
      "Training Loss: 0.6206 Validation Loss: 0.5638\n",
      "120/15000:\n",
      "Training Loss: 0.5792 Validation Loss: 0.5486\n",
      "121/15000:\n",
      "Training Loss: 0.5945 Validation Loss: 0.5464\n",
      "122/15000:\n",
      "Training Loss: 0.5435 Validation Loss: 0.5102\n",
      "123/15000:\n",
      "Training Loss: 0.5280 Validation Loss: 0.5207\n",
      "124/15000:\n",
      "Training Loss: 0.5257 Validation Loss: 0.5185\n",
      "125/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5178\n",
      "126/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5212\n",
      "127/15000:\n",
      "Training Loss: 0.5252 Validation Loss: 0.5177\n",
      "128/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5159\n",
      "129/15000:\n",
      "Training Loss: 0.5350 Validation Loss: 0.5124\n",
      "130/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5136\n",
      "131/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5106\n",
      "132/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.5190\n",
      "133/15000:\n",
      "Training Loss: 0.5245 Validation Loss: 0.4999\n",
      "134/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5051\n",
      "135/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5030\n",
      "136/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5047\n",
      "137/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5071\n",
      "138/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5136\n",
      "139/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.5004\n",
      "140/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5059\n",
      "141/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5007\n",
      "142/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4995\n",
      "143/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.4989\n",
      "144/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5026\n",
      "145/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5000\n",
      "146/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5052\n",
      "147/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5082\n",
      "148/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.5227\n",
      "149/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.5095\n",
      "150/15000:\n",
      "Training Loss: 0.5352 Validation Loss: 0.5300\n",
      "151/15000:\n",
      "Training Loss: 0.5353 Validation Loss: 0.6255\n",
      "152/15000:\n",
      "Training Loss: 0.6464 Validation Loss: 0.5231\n",
      "153/15000:\n",
      "Training Loss: 0.5452 Validation Loss: 0.5012\n",
      "154/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5058\n",
      "155/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5061\n",
      "156/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5079\n",
      "157/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5042\n",
      "158/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5050\n",
      "159/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5079\n",
      "160/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5045\n",
      "161/15000:\n",
      "Training Loss: 0.5259 Validation Loss: 0.5009\n",
      "162/15000:\n",
      "Training Loss: 0.5195 Validation Loss: 0.5258\n",
      "163/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.5211\n",
      "164/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5113\n",
      "165/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5220\n",
      "166/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5335\n",
      "167/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5156\n",
      "168/15000:\n",
      "Training Loss: 0.5264 Validation Loss: 0.5166\n",
      "169/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5088\n",
      "170/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5072\n",
      "171/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5142\n",
      "172/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5102\n",
      "173/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5121\n",
      "174/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5954\n",
      "175/15000:\n",
      "Training Loss: 0.6141 Validation Loss: 1.0428\n",
      "176/15000:\n",
      "Training Loss: 1.0106 Validation Loss: 0.5512\n",
      "177/15000:\n",
      "Training Loss: 0.6074 Validation Loss: 0.5192\n",
      "178/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.5226\n",
      "179/15000:\n",
      "Training Loss: 0.5446 Validation Loss: 0.5261\n",
      "180/15000:\n",
      "Training Loss: 0.5347 Validation Loss: 0.5291\n",
      "181/15000:\n",
      "Training Loss: 0.5262 Validation Loss: 0.5191\n",
      "182/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5265\n",
      "183/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5263\n",
      "184/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5185\n",
      "185/15000:\n",
      "Training Loss: 0.5418 Validation Loss: 0.5272\n",
      "186/15000:\n",
      "Training Loss: 0.5327 Validation Loss: 0.5239\n",
      "187/15000:\n",
      "Training Loss: 0.5222 Validation Loss: 0.5195\n",
      "188/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5189\n",
      "189/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5333\n",
      "190/15000:\n",
      "Training Loss: 0.5249 Validation Loss: 0.5241\n",
      "191/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5186\n",
      "192/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5121\n",
      "193/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5180\n",
      "194/15000:\n",
      "Training Loss: 0.5260 Validation Loss: 0.5071\n",
      "195/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5162\n",
      "196/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5101\n",
      "197/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5106\n",
      "198/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5057\n",
      "199/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5044\n",
      "200/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5041\n",
      "201/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5078\n",
      "202/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.5180\n",
      "203/15000:\n",
      "Training Loss: 0.5310 Validation Loss: 0.5099\n",
      "204/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.5128\n",
      "205/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5332\n",
      "206/15000:\n",
      "Training Loss: 0.5449 Validation Loss: 0.5067\n",
      "207/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5072\n",
      "208/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5088\n",
      "209/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5243\n",
      "210/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5048\n",
      "211/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5031\n",
      "212/15000:\n",
      "Training Loss: 0.5156 Validation Loss: 0.5127\n",
      "213/15000:\n",
      "Training Loss: 0.5333 Validation Loss: 0.5178\n",
      "214/15000:\n",
      "Training Loss: 0.5300 Validation Loss: 0.4982\n",
      "215/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5034\n",
      "216/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5112\n",
      "217/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5110\n",
      "218/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5084\n",
      "219/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.5055\n",
      "220/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5127\n",
      "221/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5092\n",
      "222/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5276\n",
      "223/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.4971\n",
      "224/15000:\n",
      "Training Loss: 0.5206 Validation Loss: 0.5127\n",
      "225/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5163\n",
      "226/15000:\n",
      "Training Loss: 0.5363 Validation Loss: 0.5174\n",
      "227/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5041\n",
      "228/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5092\n",
      "229/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5075\n",
      "230/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5030\n",
      "231/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5036\n",
      "232/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5063\n",
      "233/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5070\n",
      "234/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5205\n",
      "235/15000:\n",
      "Training Loss: 0.5279 Validation Loss: 0.5058\n",
      "236/15000:\n",
      "Training Loss: 0.5290 Validation Loss: 0.5157\n",
      "237/15000:\n",
      "Training Loss: 0.5259 Validation Loss: 0.5179\n",
      "238/15000:\n",
      "Training Loss: 0.5296 Validation Loss: 0.5180\n",
      "239/15000:\n",
      "Training Loss: 0.5224 Validation Loss: 0.5178\n",
      "240/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.5400\n",
      "241/15000:\n",
      "Training Loss: 0.5419 Validation Loss: 0.5399\n",
      "242/15000:\n",
      "Training Loss: 0.5562 Validation Loss: 0.5196\n",
      "243/15000:\n",
      "Training Loss: 0.5284 Validation Loss: 0.5355\n",
      "244/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5180\n",
      "245/15000:\n",
      "Training Loss: 0.5242 Validation Loss: 0.5642\n",
      "246/15000:\n",
      "Training Loss: 0.5777 Validation Loss: 0.5288\n",
      "247/15000:\n",
      "Training Loss: 0.5429 Validation Loss: 0.5161\n",
      "248/15000:\n",
      "Training Loss: 0.5318 Validation Loss: 0.5100\n",
      "249/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5132\n",
      "250/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5095\n",
      "251/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5031\n",
      "252/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5120\n",
      "253/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5058\n",
      "254/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5089\n",
      "255/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5243\n",
      "256/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5041\n",
      "257/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5045\n",
      "258/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5037\n",
      "259/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5028\n",
      "260/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5078\n",
      "261/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5103\n",
      "262/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5088\n",
      "263/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5120\n",
      "264/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5332\n",
      "265/15000:\n",
      "Training Loss: 0.5233 Validation Loss: 0.5154\n",
      "266/15000:\n",
      "Training Loss: 0.5603 Validation Loss: 0.5212\n",
      "267/15000:\n",
      "Training Loss: 0.5259 Validation Loss: 0.5106\n",
      "268/15000:\n",
      "Training Loss: 0.5208 Validation Loss: 0.5078\n",
      "269/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5117\n",
      "270/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5041\n",
      "271/15000:\n",
      "Training Loss: 0.5235 Validation Loss: 0.5028\n",
      "272/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5069\n",
      "273/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5191\n",
      "274/15000:\n",
      "Training Loss: 0.5318 Validation Loss: 0.5139\n",
      "275/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5079\n",
      "276/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5079\n",
      "277/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.5117\n",
      "278/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5117\n",
      "279/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5045\n",
      "280/15000:\n",
      "Training Loss: 0.5226 Validation Loss: 0.5175\n",
      "281/15000:\n",
      "Training Loss: 0.5199 Validation Loss: 0.5146\n",
      "282/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5246\n",
      "283/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5269\n",
      "284/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5151\n",
      "285/15000:\n",
      "Training Loss: 0.5234 Validation Loss: 0.5065\n",
      "286/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5023\n",
      "287/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5093\n",
      "288/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4981\n",
      "289/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.4993\n",
      "290/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5060\n",
      "291/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5071\n",
      "292/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.4992\n",
      "293/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4976\n",
      "294/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5008\n",
      "295/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5119\n",
      "296/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5031\n",
      "297/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5017\n",
      "298/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5038\n",
      "299/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5083\n",
      "300/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5160\n",
      "301/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5130\n",
      "302/15000:\n",
      "Training Loss: 0.5199 Validation Loss: 0.5177\n",
      "303/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.5033\n",
      "304/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5244\n",
      "305/15000:\n",
      "Training Loss: 0.5227 Validation Loss: 0.5017\n",
      "306/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5018\n",
      "307/15000:\n",
      "Training Loss: 0.5228 Validation Loss: 0.4984\n",
      "308/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4988\n",
      "309/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5048\n",
      "310/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5137\n",
      "311/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5542\n",
      "312/15000:\n",
      "Training Loss: 0.5599 Validation Loss: 0.5855\n",
      "313/15000:\n",
      "Training Loss: 0.6414 Validation Loss: 0.5721\n",
      "314/15000:\n",
      "Training Loss: 0.5770 Validation Loss: 0.6646\n",
      "315/15000:\n",
      "Training Loss: 0.6915 Validation Loss: 0.5691\n",
      "316/15000:\n",
      "Training Loss: 0.5794 Validation Loss: 0.6568\n",
      "317/15000:\n",
      "Training Loss: 0.6851 Validation Loss: 0.5486\n",
      "318/15000:\n",
      "Training Loss: 0.5707 Validation Loss: 0.5135\n",
      "319/15000:\n",
      "Training Loss: 0.5461 Validation Loss: 0.5183\n",
      "320/15000:\n",
      "Training Loss: 0.5321 Validation Loss: 0.5129\n",
      "321/15000:\n",
      "Training Loss: 0.5299 Validation Loss: 0.5109\n",
      "322/15000:\n",
      "Training Loss: 0.5254 Validation Loss: 0.5051\n",
      "323/15000:\n",
      "Training Loss: 0.5176 Validation Loss: 0.5009\n",
      "324/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5050\n",
      "325/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5049\n",
      "326/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5112\n",
      "327/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5043\n",
      "328/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5058\n",
      "329/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5009\n",
      "330/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5041\n",
      "331/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5003\n",
      "332/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5085\n",
      "333/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5037\n",
      "334/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5221\n",
      "335/15000:\n",
      "Training Loss: 0.5247 Validation Loss: 0.5378\n",
      "336/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5239\n",
      "337/15000:\n",
      "Training Loss: 0.5192 Validation Loss: 0.5019\n",
      "338/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5110\n",
      "339/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5043\n",
      "340/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5063\n",
      "341/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5055\n",
      "342/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5024\n",
      "343/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.5094\n",
      "344/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5090\n",
      "345/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5107\n",
      "346/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.5205\n",
      "347/15000:\n",
      "Training Loss: 0.5312 Validation Loss: 0.5165\n",
      "348/15000:\n",
      "Training Loss: 0.5265 Validation Loss: 0.5175\n",
      "349/15000:\n",
      "Training Loss: 0.5280 Validation Loss: 0.5233\n",
      "350/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5060\n",
      "351/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5104\n",
      "352/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5097\n",
      "353/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5290\n",
      "354/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5119\n",
      "355/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5148\n",
      "356/15000:\n",
      "Training Loss: 0.5331 Validation Loss: 0.5202\n",
      "357/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5162\n",
      "358/15000:\n",
      "Training Loss: 0.5226 Validation Loss: 0.5170\n",
      "359/15000:\n",
      "Training Loss: 0.5298 Validation Loss: 0.5102\n",
      "360/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5112\n",
      "361/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5268\n",
      "362/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5163\n",
      "363/15000:\n",
      "Training Loss: 0.5321 Validation Loss: 0.5175\n",
      "364/15000:\n",
      "Training Loss: 0.5278 Validation Loss: 0.5058\n",
      "365/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5050\n",
      "366/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5150\n",
      "367/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4994\n",
      "368/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5051\n",
      "369/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.5089\n",
      "370/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5054\n",
      "371/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5092\n",
      "372/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5076\n",
      "373/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5037\n",
      "374/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5095\n",
      "375/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5039\n",
      "376/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4998\n",
      "377/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5044\n",
      "378/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5066\n",
      "379/15000:\n",
      "Training Loss: 0.5212 Validation Loss: 0.5043\n",
      "380/15000:\n",
      "Training Loss: 0.5228 Validation Loss: 0.5209\n",
      "381/15000:\n",
      "Training Loss: 0.5286 Validation Loss: 0.5033\n",
      "382/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5063\n",
      "383/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5008\n",
      "384/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.4989\n",
      "385/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5024\n",
      "386/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4981\n",
      "387/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4989\n",
      "388/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4981\n",
      "389/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.4985\n",
      "390/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5149\n",
      "391/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5150\n",
      "392/15000:\n",
      "Training Loss: 0.5369 Validation Loss: 0.5339\n",
      "393/15000:\n",
      "Training Loss: 0.5366 Validation Loss: 0.5215\n",
      "394/15000:\n",
      "Training Loss: 0.5402 Validation Loss: 0.5183\n",
      "395/15000:\n",
      "Training Loss: 0.5295 Validation Loss: 0.5060\n",
      "396/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.4966\n",
      "397/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5005\n",
      "398/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5125\n",
      "399/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5275\n",
      "400/15000:\n",
      "Training Loss: 0.5410 Validation Loss: 0.5748\n",
      "401/15000:\n",
      "Training Loss: 0.6153 Validation Loss: 0.5493\n",
      "402/15000:\n",
      "Training Loss: 0.5629 Validation Loss: 0.5231\n",
      "403/15000:\n",
      "Training Loss: 0.5221 Validation Loss: 0.5205\n",
      "404/15000:\n",
      "Training Loss: 0.5294 Validation Loss: 0.5148\n",
      "405/15000:\n",
      "Training Loss: 0.5382 Validation Loss: 0.5133\n",
      "406/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5084\n",
      "407/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5180\n",
      "408/15000:\n",
      "Training Loss: 0.5292 Validation Loss: 0.5276\n",
      "409/15000:\n",
      "Training Loss: 0.5639 Validation Loss: 0.5228\n",
      "410/15000:\n",
      "Training Loss: 0.5379 Validation Loss: 0.5021\n",
      "411/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5029\n",
      "412/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5021\n",
      "413/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5017\n",
      "414/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5011\n",
      "415/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5064\n",
      "416/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5081\n",
      "417/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5031\n",
      "418/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5167\n",
      "419/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.4972\n",
      "420/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.4990\n",
      "421/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4985\n",
      "422/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5036\n",
      "423/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5036\n",
      "424/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5125\n",
      "425/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5103\n",
      "426/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.5409\n",
      "427/15000:\n",
      "Training Loss: 0.5511 Validation Loss: 0.5179\n",
      "428/15000:\n",
      "Training Loss: 0.5673 Validation Loss: 0.5184\n",
      "429/15000:\n",
      "Training Loss: 0.5246 Validation Loss: 0.5233\n",
      "430/15000:\n",
      "Training Loss: 0.5633 Validation Loss: 0.5144\n",
      "431/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5176\n",
      "432/15000:\n",
      "Training Loss: 0.5323 Validation Loss: 0.5069\n",
      "433/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5051\n",
      "434/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5038\n",
      "435/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5037\n",
      "436/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5194\n",
      "437/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.4993\n",
      "438/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5013\n",
      "439/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4987\n",
      "440/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.4990\n",
      "441/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5109\n",
      "442/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5065\n",
      "443/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5092\n",
      "444/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.5114\n",
      "445/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5291\n",
      "446/15000:\n",
      "Training Loss: 0.5176 Validation Loss: 0.5050\n",
      "447/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5021\n",
      "448/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5003\n",
      "449/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5097\n",
      "450/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5305\n",
      "451/15000:\n",
      "Training Loss: 0.5342 Validation Loss: 0.5268\n",
      "452/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.5237\n",
      "453/15000:\n",
      "Training Loss: 0.5423 Validation Loss: 0.5265\n",
      "454/15000:\n",
      "Training Loss: 0.5306 Validation Loss: 0.5405\n",
      "455/15000:\n",
      "Training Loss: 0.5560 Validation Loss: 0.5419\n",
      "456/15000:\n",
      "Training Loss: 0.5412 Validation Loss: 0.5407\n",
      "457/15000:\n",
      "Training Loss: 0.5655 Validation Loss: 0.5272\n",
      "458/15000:\n",
      "Training Loss: 0.5389 Validation Loss: 0.5259\n",
      "459/15000:\n",
      "Training Loss: 0.5619 Validation Loss: 0.5190\n",
      "460/15000:\n",
      "Training Loss: 0.5405 Validation Loss: 0.5033\n",
      "461/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5088\n",
      "462/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5092\n",
      "463/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.5129\n",
      "464/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5106\n",
      "465/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5110\n",
      "466/15000:\n",
      "Training Loss: 0.5324 Validation Loss: 0.5242\n",
      "467/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5243\n",
      "468/15000:\n",
      "Training Loss: 0.5434 Validation Loss: 0.5041\n",
      "469/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.4997\n",
      "470/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4985\n",
      "471/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5109\n",
      "472/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5091\n",
      "473/15000:\n",
      "Training Loss: 0.5252 Validation Loss: 0.5113\n",
      "474/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.4989\n",
      "475/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.4987\n",
      "476/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5113\n",
      "477/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5052\n",
      "478/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.4978\n",
      "479/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5060\n",
      "480/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5000\n",
      "481/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5098\n",
      "482/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5031\n",
      "483/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5304\n",
      "484/15000:\n",
      "Training Loss: 0.5384 Validation Loss: 0.5045\n",
      "485/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5077\n",
      "486/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5109\n",
      "487/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5191\n",
      "488/15000:\n",
      "Training Loss: 0.5262 Validation Loss: 0.5061\n",
      "489/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.5297\n",
      "490/15000:\n",
      "Training Loss: 0.5334 Validation Loss: 0.5058\n",
      "491/15000:\n",
      "Training Loss: 0.5195 Validation Loss: 0.5070\n",
      "492/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5131\n",
      "493/15000:\n",
      "Training Loss: 0.5211 Validation Loss: 0.5204\n",
      "494/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5011\n",
      "495/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.4989\n",
      "496/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5006\n",
      "497/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4969\n",
      "498/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.4956\n",
      "499/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5015\n",
      "500/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4956\n",
      "501/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.4987\n",
      "502/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5035\n",
      "503/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5049\n",
      "504/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5102\n",
      "505/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5130\n",
      "506/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.4969\n",
      "507/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.4998\n",
      "508/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5068\n",
      "509/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.4992\n",
      "510/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5000\n",
      "511/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5059\n",
      "512/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4997\n",
      "513/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5025\n",
      "514/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5064\n",
      "515/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5079\n",
      "516/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5202\n",
      "517/15000:\n",
      "Training Loss: 0.5192 Validation Loss: 0.5436\n",
      "518/15000:\n",
      "Training Loss: 0.5620 Validation Loss: 0.5506\n",
      "519/15000:\n",
      "Training Loss: 0.5478 Validation Loss: 0.5839\n",
      "520/15000:\n",
      "Training Loss: 0.6139 Validation Loss: 0.5495\n",
      "521/15000:\n",
      "Training Loss: 0.5864 Validation Loss: 1.2363\n",
      "522/15000:\n",
      "Training Loss: 1.3055 Validation Loss: 0.5171\n",
      "523/15000:\n",
      "Training Loss: 0.5540 Validation Loss: 0.5185\n",
      "524/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5166\n",
      "525/15000:\n",
      "Training Loss: 0.5203 Validation Loss: 0.5157\n",
      "526/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5194\n",
      "527/15000:\n",
      "Training Loss: 0.5234 Validation Loss: 0.5199\n",
      "528/15000:\n",
      "Training Loss: 0.5267 Validation Loss: 0.5197\n",
      "529/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5182\n",
      "530/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5168\n",
      "531/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.5173\n",
      "532/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5121\n",
      "533/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5091\n",
      "534/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5103\n",
      "535/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5129\n",
      "536/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5173\n",
      "537/15000:\n",
      "Training Loss: 0.5375 Validation Loss: 0.5089\n",
      "538/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5099\n",
      "539/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5106\n",
      "540/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5079\n",
      "541/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5044\n",
      "542/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5132\n",
      "543/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5031\n",
      "544/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5084\n",
      "545/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5027\n",
      "546/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5056\n",
      "547/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5039\n",
      "548/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5028\n",
      "549/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5057\n",
      "550/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5135\n",
      "551/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5113\n",
      "552/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5061\n",
      "553/15000:\n",
      "Training Loss: 0.5373 Validation Loss: 0.5112\n",
      "554/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5088\n",
      "555/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5094\n",
      "556/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5071\n",
      "557/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5099\n",
      "558/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5062\n",
      "559/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.5056\n",
      "560/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5268\n",
      "561/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5387\n",
      "562/15000:\n",
      "Training Loss: 0.5467 Validation Loss: 0.5130\n",
      "563/15000:\n",
      "Training Loss: 0.5306 Validation Loss: 0.5086\n",
      "564/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5176\n",
      "565/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5065\n",
      "566/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5153\n",
      "567/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.5010\n",
      "568/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5021\n",
      "569/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5014\n",
      "570/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5173\n",
      "571/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5015\n",
      "572/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5097\n",
      "573/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5071\n",
      "574/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5057\n",
      "575/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5045\n",
      "576/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5025\n",
      "577/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5084\n",
      "578/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5088\n",
      "579/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5116\n",
      "580/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5364\n",
      "581/15000:\n",
      "Training Loss: 0.5470 Validation Loss: 0.5052\n",
      "582/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.4989\n",
      "583/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5032\n",
      "584/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5039\n",
      "585/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5070\n",
      "586/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5002\n",
      "587/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5142\n",
      "588/15000:\n",
      "Training Loss: 0.5276 Validation Loss: 0.5222\n",
      "589/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5136\n",
      "590/15000:\n",
      "Training Loss: 0.5330 Validation Loss: 0.5181\n",
      "591/15000:\n",
      "Training Loss: 0.5269 Validation Loss: 0.5099\n",
      "592/15000:\n",
      "Training Loss: 0.5316 Validation Loss: 0.5092\n",
      "593/15000:\n",
      "Training Loss: 0.5257 Validation Loss: 0.5094\n",
      "594/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5095\n",
      "595/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5096\n",
      "596/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5073\n",
      "597/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5037\n",
      "598/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5033\n",
      "599/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5010\n",
      "600/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5015\n",
      "601/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5047\n",
      "602/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.4986\n",
      "603/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5017\n",
      "604/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5003\n",
      "605/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5007\n",
      "606/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5004\n",
      "607/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4975\n",
      "608/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5081\n",
      "609/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5000\n",
      "610/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5013\n",
      "611/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5093\n",
      "612/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5059\n",
      "613/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5044\n",
      "614/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5107\n",
      "615/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5660\n",
      "616/15000:\n",
      "Training Loss: 0.5665 Validation Loss: 0.8336\n",
      "617/15000:\n",
      "Training Loss: 0.8390 Validation Loss: 0.5132\n",
      "618/15000:\n",
      "Training Loss: 0.5385 Validation Loss: 0.5184\n",
      "619/15000:\n",
      "Training Loss: 0.5230 Validation Loss: 0.5084\n",
      "620/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5087\n",
      "621/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5097\n",
      "622/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5075\n",
      "623/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5221\n",
      "624/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5088\n",
      "625/15000:\n",
      "Training Loss: 0.5308 Validation Loss: 0.5047\n",
      "626/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5119\n",
      "627/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5071\n",
      "628/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5045\n",
      "629/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5108\n",
      "630/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5329\n",
      "631/15000:\n",
      "Training Loss: 0.5448 Validation Loss: 0.5118\n",
      "632/15000:\n",
      "Training Loss: 0.5361 Validation Loss: 0.5060\n",
      "633/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5056\n",
      "634/15000:\n",
      "Training Loss: 0.5206 Validation Loss: 0.5116\n",
      "635/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5000\n",
      "636/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5042\n",
      "637/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.5078\n",
      "638/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5111\n",
      "639/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.4973\n",
      "640/15000:\n",
      "Training Loss: 0.5233 Validation Loss: 0.5016\n",
      "641/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5084\n",
      "642/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5134\n",
      "643/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.5150\n",
      "644/15000:\n",
      "Training Loss: 0.5292 Validation Loss: 0.5413\n",
      "645/15000:\n",
      "Training Loss: 0.5646 Validation Loss: 0.5308\n",
      "646/15000:\n",
      "Training Loss: 0.5778 Validation Loss: 0.5068\n",
      "647/15000:\n",
      "Training Loss: 0.5373 Validation Loss: 0.5142\n",
      "648/15000:\n",
      "Training Loss: 0.5276 Validation Loss: 0.5044\n",
      "649/15000:\n",
      "Training Loss: 0.5328 Validation Loss: 0.5257\n",
      "650/15000:\n",
      "Training Loss: 0.5467 Validation Loss: 0.5176\n",
      "651/15000:\n",
      "Training Loss: 0.5387 Validation Loss: 0.5013\n",
      "652/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5006\n",
      "653/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.4991\n",
      "654/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5035\n",
      "655/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.4988\n",
      "656/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.4966\n",
      "657/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5067\n",
      "658/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5030\n",
      "659/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5013\n",
      "660/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4998\n",
      "661/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5081\n",
      "662/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5050\n",
      "663/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.4973\n",
      "664/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4957\n",
      "665/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5043\n",
      "666/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5017\n",
      "667/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5379\n",
      "668/15000:\n",
      "Training Loss: 0.5267 Validation Loss: 0.5253\n",
      "669/15000:\n",
      "Training Loss: 0.5294 Validation Loss: 0.5051\n",
      "670/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5041\n",
      "671/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5067\n",
      "672/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5082\n",
      "673/15000:\n",
      "Training Loss: 0.5233 Validation Loss: 0.5095\n",
      "674/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5152\n",
      "675/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5012\n",
      "676/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5041\n",
      "677/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5024\n",
      "678/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5017\n",
      "679/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5088\n",
      "680/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5127\n",
      "681/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5007\n",
      "682/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5124\n",
      "683/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5177\n",
      "684/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5062\n",
      "685/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5032\n",
      "686/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5231\n",
      "687/15000:\n",
      "Training Loss: 0.5367 Validation Loss: 0.5144\n",
      "688/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5041\n",
      "689/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5011\n",
      "690/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4990\n",
      "691/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5057\n",
      "692/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5042\n",
      "693/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4991\n",
      "694/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5105\n",
      "695/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5013\n",
      "696/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5183\n",
      "697/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5164\n",
      "698/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5023\n",
      "699/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5065\n",
      "700/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5240\n",
      "701/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5415\n",
      "702/15000:\n",
      "Training Loss: 0.5320 Validation Loss: 0.5460\n",
      "703/15000:\n",
      "Training Loss: 0.5585 Validation Loss: 0.5773\n",
      "704/15000:\n",
      "Training Loss: 0.5960 Validation Loss: 0.5121\n",
      "705/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5030\n",
      "706/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5065\n",
      "707/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5020\n",
      "708/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5122\n",
      "709/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5110\n",
      "710/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5083\n",
      "711/15000:\n",
      "Training Loss: 0.5240 Validation Loss: 0.5236\n",
      "712/15000:\n",
      "Training Loss: 0.5397 Validation Loss: 0.5163\n",
      "713/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5081\n",
      "714/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5012\n",
      "715/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5091\n",
      "716/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5007\n",
      "717/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.4957\n",
      "718/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.4995\n",
      "719/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4991\n",
      "720/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5030\n",
      "721/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5080\n",
      "722/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.4993\n",
      "723/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5054\n",
      "724/15000:\n",
      "Training Loss: 0.5163 Validation Loss: 0.4946\n",
      "725/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5060\n",
      "726/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5085\n",
      "727/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4949\n",
      "728/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4961\n",
      "729/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5037\n",
      "730/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.4995\n",
      "731/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5046\n",
      "732/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4973\n",
      "733/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5066\n",
      "734/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5102\n",
      "735/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5108\n",
      "736/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5181\n",
      "737/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.4990\n",
      "738/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5006\n",
      "739/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5036\n",
      "740/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4949\n",
      "741/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4957\n",
      "742/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4965\n",
      "743/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5024\n",
      "744/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5042\n",
      "745/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5127\n",
      "746/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5257\n",
      "747/15000:\n",
      "Training Loss: 0.5335 Validation Loss: 0.5367\n",
      "748/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.5575\n",
      "749/15000:\n",
      "Training Loss: 0.5968 Validation Loss: 0.5896\n",
      "750/15000:\n",
      "Training Loss: 0.6247 Validation Loss: 0.9373\n",
      "751/15000:\n",
      "Training Loss: 0.9116 Validation Loss: 0.5241\n",
      "752/15000:\n",
      "Training Loss: 0.5294 Validation Loss: 0.5214\n",
      "753/15000:\n",
      "Training Loss: 0.5263 Validation Loss: 0.5167\n",
      "754/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5146\n",
      "755/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5121\n",
      "756/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5170\n",
      "757/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.5139\n",
      "758/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5149\n",
      "759/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5117\n",
      "760/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5064\n",
      "761/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5078\n",
      "762/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5077\n",
      "763/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5074\n",
      "764/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5071\n",
      "765/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5071\n",
      "766/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5088\n",
      "767/15000:\n",
      "Training Loss: 0.5280 Validation Loss: 0.5089\n",
      "768/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.4974\n",
      "769/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5039\n",
      "770/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5083\n",
      "771/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5118\n",
      "772/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5083\n",
      "773/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.5060\n",
      "774/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5081\n",
      "775/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5028\n",
      "776/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5078\n",
      "777/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5099\n",
      "778/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5073\n",
      "779/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5069\n",
      "780/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5059\n",
      "781/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5086\n",
      "782/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5091\n",
      "783/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5103\n",
      "784/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5034\n",
      "785/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5046\n",
      "786/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5010\n",
      "787/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5097\n",
      "788/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5009\n",
      "789/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.5105\n",
      "790/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5020\n",
      "791/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5127\n",
      "792/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4963\n",
      "793/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.4987\n",
      "794/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5020\n",
      "795/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5020\n",
      "796/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5067\n",
      "797/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5058\n",
      "798/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5122\n",
      "799/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5022\n",
      "800/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.4962\n",
      "801/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.4961\n",
      "802/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5085\n",
      "803/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5182\n",
      "804/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5057\n",
      "805/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5094\n",
      "806/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5031\n",
      "807/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5008\n",
      "808/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5003\n",
      "809/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4986\n",
      "810/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.4975\n",
      "811/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4966\n",
      "812/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4937\n",
      "813/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5068\n",
      "814/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4987\n",
      "815/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5043\n",
      "816/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5098\n",
      "817/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5073\n",
      "818/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5065\n",
      "819/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.4959\n",
      "820/15000:\n",
      "Training Loss: 0.5212 Validation Loss: 0.4987\n",
      "821/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5035\n",
      "822/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5176\n",
      "823/15000:\n",
      "Training Loss: 0.5383 Validation Loss: 0.5194\n",
      "824/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.4960\n",
      "825/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.4968\n",
      "826/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4949\n",
      "827/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4972\n",
      "828/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5125\n",
      "829/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4966\n",
      "830/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5028\n",
      "831/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.5034\n",
      "832/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5090\n",
      "833/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5016\n",
      "834/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4973\n",
      "835/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5023\n",
      "836/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4987\n",
      "837/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5124\n",
      "838/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5297\n",
      "839/15000:\n",
      "Training Loss: 0.5322 Validation Loss: 0.5253\n",
      "840/15000:\n",
      "Training Loss: 0.5447 Validation Loss: 0.5188\n",
      "841/15000:\n",
      "Training Loss: 0.5451 Validation Loss: 0.5083\n",
      "842/15000:\n",
      "Training Loss: 0.5412 Validation Loss: 0.5102\n",
      "843/15000:\n",
      "Training Loss: 0.5233 Validation Loss: 0.5075\n",
      "844/15000:\n",
      "Training Loss: 0.5309 Validation Loss: 0.5307\n",
      "845/15000:\n",
      "Training Loss: 0.5409 Validation Loss: 0.5508\n",
      "846/15000:\n",
      "Training Loss: 0.5873 Validation Loss: 0.5885\n",
      "847/15000:\n",
      "Training Loss: 0.6258 Validation Loss: 0.8144\n",
      "848/15000:\n",
      "Training Loss: 0.8489 Validation Loss: 0.5257\n",
      "849/15000:\n",
      "Training Loss: 0.5515 Validation Loss: 0.5134\n",
      "850/15000:\n",
      "Training Loss: 0.5453 Validation Loss: 0.5198\n",
      "851/15000:\n",
      "Training Loss: 0.5336 Validation Loss: 0.5145\n",
      "852/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5086\n",
      "853/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5078\n",
      "854/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5050\n",
      "855/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5069\n",
      "856/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5110\n",
      "857/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5183\n",
      "858/15000:\n",
      "Training Loss: 0.5277 Validation Loss: 0.5041\n",
      "859/15000:\n",
      "Training Loss: 0.5190 Validation Loss: 0.5010\n",
      "860/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5074\n",
      "861/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5094\n",
      "862/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5120\n",
      "863/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5111\n",
      "864/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5003\n",
      "865/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5011\n",
      "866/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4995\n",
      "867/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5029\n",
      "868/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5071\n",
      "869/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5098\n",
      "870/15000:\n",
      "Training Loss: 0.5263 Validation Loss: 0.5184\n",
      "871/15000:\n",
      "Training Loss: 0.5377 Validation Loss: 0.5420\n",
      "872/15000:\n",
      "Training Loss: 0.5702 Validation Loss: 0.5014\n",
      "873/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5070\n",
      "874/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5133\n",
      "875/15000:\n",
      "Training Loss: 0.5353 Validation Loss: 0.5344\n",
      "876/15000:\n",
      "Training Loss: 0.5908 Validation Loss: 0.5243\n",
      "877/15000:\n",
      "Training Loss: 0.5378 Validation Loss: 0.5138\n",
      "878/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5025\n",
      "879/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5009\n",
      "880/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5029\n",
      "881/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5045\n",
      "882/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5147\n",
      "883/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5240\n",
      "884/15000:\n",
      "Training Loss: 0.5386 Validation Loss: 0.5029\n",
      "885/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5055\n",
      "886/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5007\n",
      "887/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5037\n",
      "888/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4986\n",
      "889/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.4987\n",
      "890/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5010\n",
      "891/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5027\n",
      "892/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5010\n",
      "893/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5105\n",
      "894/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5110\n",
      "895/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5177\n",
      "896/15000:\n",
      "Training Loss: 0.5255 Validation Loss: 0.5803\n",
      "897/15000:\n",
      "Training Loss: 0.5939 Validation Loss: 0.8372\n",
      "898/15000:\n",
      "Training Loss: 0.8395 Validation Loss: 0.6028\n",
      "899/15000:\n",
      "Training Loss: 0.6303 Validation Loss: 0.5199\n",
      "900/15000:\n",
      "Training Loss: 0.5500 Validation Loss: 0.5111\n",
      "901/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5110\n",
      "902/15000:\n",
      "Training Loss: 0.5222 Validation Loss: 0.5103\n",
      "903/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5165\n",
      "904/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5121\n",
      "905/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.5132\n",
      "906/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5127\n",
      "907/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5076\n",
      "908/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5118\n",
      "909/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5076\n",
      "910/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5144\n",
      "911/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5153\n",
      "912/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5063\n",
      "913/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4932\n",
      "914/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.5057\n",
      "915/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.4950\n",
      "916/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5002\n",
      "917/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5196\n",
      "918/15000:\n",
      "Training Loss: 0.5371 Validation Loss: 0.5282\n",
      "919/15000:\n",
      "Training Loss: 0.5438 Validation Loss: 0.5417\n",
      "920/15000:\n",
      "Training Loss: 0.5469 Validation Loss: 0.5099\n",
      "921/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4984\n",
      "922/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4984\n",
      "923/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5015\n",
      "924/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5054\n",
      "925/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5071\n",
      "926/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5087\n",
      "927/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5064\n",
      "928/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5055\n",
      "929/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5100\n",
      "930/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5120\n",
      "931/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5199\n",
      "932/15000:\n",
      "Training Loss: 0.5321 Validation Loss: 0.5239\n",
      "933/15000:\n",
      "Training Loss: 0.5290 Validation Loss: 0.5120\n",
      "934/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5193\n",
      "935/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.5098\n",
      "936/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4992\n",
      "937/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5077\n",
      "938/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5002\n",
      "939/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5032\n",
      "940/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5358\n",
      "941/15000:\n",
      "Training Loss: 0.5473 Validation Loss: 0.4985\n",
      "942/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5078\n",
      "943/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5134\n",
      "944/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5128\n",
      "945/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5144\n",
      "946/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.5325\n",
      "947/15000:\n",
      "Training Loss: 0.5488 Validation Loss: 0.5283\n",
      "948/15000:\n",
      "Training Loss: 0.5290 Validation Loss: 0.5285\n",
      "949/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5111\n",
      "950/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5012\n",
      "951/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.4957\n",
      "952/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5133\n",
      "953/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5067\n",
      "954/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5043\n",
      "955/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5026\n",
      "956/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5051\n",
      "957/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5044\n",
      "958/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.4976\n",
      "959/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5016\n",
      "960/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.4964\n",
      "961/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5042\n",
      "962/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5058\n",
      "963/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5068\n",
      "964/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5127\n",
      "965/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5354\n",
      "966/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.5277\n",
      "967/15000:\n",
      "Training Loss: 0.5388 Validation Loss: 0.5721\n",
      "968/15000:\n",
      "Training Loss: 0.6559 Validation Loss: 0.5704\n",
      "969/15000:\n",
      "Training Loss: 0.5585 Validation Loss: 0.9751\n",
      "970/15000:\n",
      "Training Loss: 1.0000 Validation Loss: 0.5080\n",
      "971/15000:\n",
      "Training Loss: 0.5475 Validation Loss: 0.5054\n",
      "972/15000:\n",
      "Training Loss: 0.5246 Validation Loss: 0.5130\n",
      "973/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5051\n",
      "974/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5046\n",
      "975/15000:\n",
      "Training Loss: 0.5221 Validation Loss: 0.5056\n",
      "976/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5057\n",
      "977/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5065\n",
      "978/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5078\n",
      "979/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5081\n",
      "980/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5074\n",
      "981/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5089\n",
      "982/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5083\n",
      "983/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5065\n",
      "984/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5094\n",
      "985/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5055\n",
      "986/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5097\n",
      "987/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5135\n",
      "988/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5157\n",
      "989/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5085\n",
      "990/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5101\n",
      "991/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5026\n",
      "992/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5113\n",
      "993/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.4998\n",
      "994/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5032\n",
      "995/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.5221\n",
      "996/15000:\n",
      "Training Loss: 0.5254 Validation Loss: 0.5117\n",
      "997/15000:\n",
      "Training Loss: 0.5187 Validation Loss: 0.5371\n",
      "998/15000:\n",
      "Training Loss: 0.5312 Validation Loss: 0.5661\n",
      "999/15000:\n",
      "Training Loss: 0.5935 Validation Loss: 0.5042\n",
      "1000/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5000\n",
      "1001/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5040\n",
      "1002/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.5013\n",
      "1003/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5079\n",
      "1004/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5006\n",
      "1005/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5080\n",
      "1006/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5013\n",
      "1007/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5064\n",
      "1008/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5004\n",
      "1009/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5004\n",
      "1010/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5055\n",
      "1011/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5043\n",
      "1012/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5001\n",
      "1013/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5012\n",
      "1014/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5090\n",
      "1015/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.4988\n",
      "1016/15000:\n",
      "Training Loss: 0.5302 Validation Loss: 0.5070\n",
      "1017/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5083\n",
      "1018/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5054\n",
      "1019/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5019\n",
      "1020/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5068\n",
      "1021/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5024\n",
      "1022/15000:\n",
      "Training Loss: 0.5199 Validation Loss: 0.5042\n",
      "1023/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5049\n",
      "1024/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5045\n",
      "1025/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5083\n",
      "1026/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5196\n",
      "1027/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5200\n",
      "1028/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5101\n",
      "1029/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5035\n",
      "1030/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5065\n",
      "1031/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5005\n",
      "1032/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5016\n",
      "1033/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5042\n",
      "1034/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5005\n",
      "1035/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4996\n",
      "1036/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.4975\n",
      "1037/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5024\n",
      "1038/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5081\n",
      "1039/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5047\n",
      "1040/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5001\n",
      "1041/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5121\n",
      "1042/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5198\n",
      "1043/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5090\n",
      "1044/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5128\n",
      "1045/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5033\n",
      "1046/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.4980\n",
      "1047/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5031\n",
      "1048/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5064\n",
      "1049/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.4960\n",
      "1050/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5060\n",
      "1051/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4970\n",
      "1052/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5015\n",
      "1053/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.4997\n",
      "1054/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5025\n",
      "1055/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5031\n",
      "1056/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5156\n",
      "1057/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5219\n",
      "1058/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.5198\n",
      "1059/15000:\n",
      "Training Loss: 0.5226 Validation Loss: 0.5423\n",
      "1060/15000:\n",
      "Training Loss: 0.5728 Validation Loss: 0.5393\n",
      "1061/15000:\n",
      "Training Loss: 0.5552 Validation Loss: 0.5014\n",
      "1062/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5048\n",
      "1063/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4977\n",
      "1064/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.4997\n",
      "1065/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5030\n",
      "1066/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5080\n",
      "1067/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5213\n",
      "1068/15000:\n",
      "Training Loss: 0.5460 Validation Loss: 0.5619\n",
      "1069/15000:\n",
      "Training Loss: 0.5704 Validation Loss: 0.5633\n",
      "1070/15000:\n",
      "Training Loss: 0.6186 Validation Loss: 0.5170\n",
      "1071/15000:\n",
      "Training Loss: 0.5305 Validation Loss: 0.4988\n",
      "1072/15000:\n",
      "Training Loss: 0.5289 Validation Loss: 0.5018\n",
      "1073/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5021\n",
      "1074/15000:\n",
      "Training Loss: 0.5192 Validation Loss: 0.5040\n",
      "1075/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5045\n",
      "1076/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5038\n",
      "1077/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.5151\n",
      "1078/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5289\n",
      "1079/15000:\n",
      "Training Loss: 0.5392 Validation Loss: 0.5056\n",
      "1080/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5102\n",
      "1081/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5055\n",
      "1082/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5121\n",
      "1083/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5091\n",
      "1084/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5012\n",
      "1085/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5032\n",
      "1086/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5114\n",
      "1087/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5113\n",
      "1088/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5010\n",
      "1089/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5009\n",
      "1090/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5004\n",
      "1091/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.4985\n",
      "1092/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5009\n",
      "1093/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4955\n",
      "1094/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5032\n",
      "1095/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4975\n",
      "1096/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5128\n",
      "1097/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5060\n",
      "1098/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5126\n",
      "1099/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5216\n",
      "1100/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5011\n",
      "1101/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5047\n",
      "1102/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5249\n",
      "1103/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5230\n",
      "1104/15000:\n",
      "Training Loss: 0.5411 Validation Loss: 0.5567\n",
      "1105/15000:\n",
      "Training Loss: 0.5576 Validation Loss: 0.5375\n",
      "1106/15000:\n",
      "Training Loss: 0.5252 Validation Loss: 0.5056\n",
      "1107/15000:\n",
      "Training Loss: 0.5281 Validation Loss: 0.5082\n",
      "1108/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5086\n",
      "1109/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5216\n",
      "1110/15000:\n",
      "Training Loss: 0.5258 Validation Loss: 0.5024\n",
      "1111/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.4950\n",
      "1112/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5013\n",
      "1113/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5005\n",
      "1114/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5009\n",
      "1115/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.4992\n",
      "1116/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5007\n",
      "1117/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5025\n",
      "1118/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5067\n",
      "1119/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4999\n",
      "1120/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5090\n",
      "1121/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5380\n",
      "1122/15000:\n",
      "Training Loss: 0.5356 Validation Loss: 0.5305\n",
      "1123/15000:\n",
      "Training Loss: 0.5723 Validation Loss: 0.4891\n",
      "1124/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.4969\n",
      "1125/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4991\n",
      "1126/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5038\n",
      "1127/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5048\n",
      "1128/15000:\n",
      "Training Loss: 0.5235 Validation Loss: 0.5276\n",
      "1129/15000:\n",
      "Training Loss: 0.5662 Validation Loss: 0.5163\n",
      "1130/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.4963\n",
      "1131/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5035\n",
      "1132/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5014\n",
      "1133/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5023\n",
      "1134/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.4979\n",
      "1135/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5003\n",
      "1136/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5012\n",
      "1137/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5034\n",
      "1138/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5133\n",
      "1139/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5071\n",
      "1140/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5039\n",
      "1141/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5152\n",
      "1142/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5088\n",
      "1143/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5163\n",
      "1144/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5213\n",
      "1145/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5314\n",
      "1146/15000:\n",
      "Training Loss: 0.5166 Validation Loss: 0.5000\n",
      "1147/15000:\n",
      "Training Loss: 0.5177 Validation Loss: 0.5014\n",
      "1148/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5108\n",
      "1149/15000:\n",
      "Training Loss: 0.5257 Validation Loss: 0.4977\n",
      "1150/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5187\n",
      "1151/15000:\n",
      "Training Loss: 0.5348 Validation Loss: 0.5017\n",
      "1152/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.5161\n",
      "1153/15000:\n",
      "Training Loss: 0.5239 Validation Loss: 0.5051\n",
      "1154/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.4970\n",
      "1155/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5000\n",
      "1156/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5047\n",
      "1157/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5136\n",
      "1158/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5192\n",
      "1159/15000:\n",
      "Training Loss: 0.5267 Validation Loss: 0.5224\n",
      "1160/15000:\n",
      "Training Loss: 0.5539 Validation Loss: 0.5140\n",
      "1161/15000:\n",
      "Training Loss: 0.5249 Validation Loss: 0.5026\n",
      "1162/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5001\n",
      "1163/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5064\n",
      "1164/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5018\n",
      "1165/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5166\n",
      "1166/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5138\n",
      "1167/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5055\n",
      "1168/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5043\n",
      "1169/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5132\n",
      "1170/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5026\n",
      "1171/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5105\n",
      "1172/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4965\n",
      "1173/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5134\n",
      "1174/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5493\n",
      "1175/15000:\n",
      "Training Loss: 0.5676 Validation Loss: 0.9652\n",
      "1176/15000:\n",
      "Training Loss: 0.9695 Validation Loss: 0.5215\n",
      "1177/15000:\n",
      "Training Loss: 0.5482 Validation Loss: 0.5125\n",
      "1178/15000:\n",
      "Training Loss: 0.5379 Validation Loss: 0.5199\n",
      "1179/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5119\n",
      "1180/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5183\n",
      "1181/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5198\n",
      "1182/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5220\n",
      "1183/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5174\n",
      "1184/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5135\n",
      "1185/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5176\n",
      "1186/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5038\n",
      "1187/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5113\n",
      "1188/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5139\n",
      "1189/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5136\n",
      "1190/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5129\n",
      "1191/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5117\n",
      "1192/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5104\n",
      "1193/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5234\n",
      "1194/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5149\n",
      "1195/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.4999\n",
      "1196/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5068\n",
      "1197/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5099\n",
      "1198/15000:\n",
      "Training Loss: 0.5167 Validation Loss: 0.5048\n",
      "1199/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5044\n",
      "1200/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5083\n",
      "1201/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5049\n",
      "1202/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5084\n",
      "1203/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4982\n",
      "1204/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5049\n",
      "1205/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5127\n",
      "1206/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5162\n",
      "1207/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5146\n",
      "1208/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5098\n",
      "1209/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5027\n",
      "1210/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5048\n",
      "1211/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5110\n",
      "1212/15000:\n",
      "Training Loss: 0.5221 Validation Loss: 0.5178\n",
      "1213/15000:\n",
      "Training Loss: 0.5235 Validation Loss: 0.5014\n",
      "1214/15000:\n",
      "Training Loss: 0.5435 Validation Loss: 0.5025\n",
      "1215/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5071\n",
      "1216/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5147\n",
      "1217/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5158\n",
      "1218/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5161\n",
      "1219/15000:\n",
      "Training Loss: 0.5255 Validation Loss: 0.5024\n",
      "1220/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5005\n",
      "1221/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5008\n",
      "1222/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5201\n",
      "1223/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.6215\n",
      "1224/15000:\n",
      "Training Loss: 0.6107 Validation Loss: 0.6938\n",
      "1225/15000:\n",
      "Training Loss: 0.7340 Validation Loss: 0.5405\n",
      "1226/15000:\n",
      "Training Loss: 0.5704 Validation Loss: 0.5191\n",
      "1227/15000:\n",
      "Training Loss: 0.5394 Validation Loss: 0.5163\n",
      "1228/15000:\n",
      "Training Loss: 0.5281 Validation Loss: 0.5140\n",
      "1229/15000:\n",
      "Training Loss: 0.5348 Validation Loss: 0.5175\n",
      "1230/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5201\n",
      "1231/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.5144\n",
      "1232/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5100\n",
      "1233/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5103\n",
      "1234/15000:\n",
      "Training Loss: 0.5283 Validation Loss: 0.5138\n",
      "1235/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5070\n",
      "1236/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5123\n",
      "1237/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5078\n",
      "1238/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5050\n",
      "1239/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5037\n",
      "1240/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5030\n",
      "1241/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5089\n",
      "1242/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5136\n",
      "1243/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5040\n",
      "1244/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5007\n",
      "1245/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5043\n",
      "1246/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5094\n",
      "1247/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.5130\n",
      "1248/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5075\n",
      "1249/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5028\n",
      "1250/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5014\n",
      "1251/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5059\n",
      "1252/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5003\n",
      "1253/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5032\n",
      "1254/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5067\n",
      "1255/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4950\n",
      "1256/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5046\n",
      "1257/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5057\n",
      "1258/15000:\n",
      "Training Loss: 0.5257 Validation Loss: 0.5621\n",
      "1259/15000:\n",
      "Training Loss: 0.5522 Validation Loss: 0.5260\n",
      "1260/15000:\n",
      "Training Loss: 0.5760 Validation Loss: 0.5078\n",
      "1261/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4982\n",
      "1262/15000:\n",
      "Training Loss: 0.5176 Validation Loss: 0.5035\n",
      "1263/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5024\n",
      "1264/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4989\n",
      "1265/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5038\n",
      "1266/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5062\n",
      "1267/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.4982\n",
      "1268/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.4991\n",
      "1269/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5094\n",
      "1270/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5108\n",
      "1271/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5000\n",
      "1272/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5055\n",
      "1273/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5049\n",
      "1274/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5153\n",
      "1275/15000:\n",
      "Training Loss: 0.5185 Validation Loss: 0.4970\n",
      "1276/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4991\n",
      "1277/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5006\n",
      "1278/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5015\n",
      "1279/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.4958\n",
      "1280/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.4946\n",
      "1281/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4975\n",
      "1282/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5003\n",
      "1283/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5008\n",
      "1284/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4951\n",
      "1285/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5056\n",
      "1286/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5068\n",
      "1287/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.4984\n",
      "1288/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5007\n",
      "1289/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5034\n",
      "1290/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5059\n",
      "1291/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5115\n",
      "1292/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5434\n",
      "1293/15000:\n",
      "Training Loss: 0.5430 Validation Loss: 0.5125\n",
      "1294/15000:\n",
      "Training Loss: 0.5348 Validation Loss: 0.5065\n",
      "1295/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5135\n",
      "1296/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5184\n",
      "1297/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.4986\n",
      "1298/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5005\n",
      "1299/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5033\n",
      "1300/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5004\n",
      "1301/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5023\n",
      "1302/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5079\n",
      "1303/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5146\n",
      "1304/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5027\n",
      "1305/15000:\n",
      "Training Loss: 0.5284 Validation Loss: 0.5096\n",
      "1306/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5013\n",
      "1307/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5041\n",
      "1308/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5112\n",
      "1309/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.5828\n",
      "1310/15000:\n",
      "Training Loss: 0.5691 Validation Loss: 0.6877\n",
      "1311/15000:\n",
      "Training Loss: 0.7168 Validation Loss: 0.5268\n",
      "1312/15000:\n",
      "Training Loss: 0.5429 Validation Loss: 0.5109\n",
      "1313/15000:\n",
      "Training Loss: 0.5309 Validation Loss: 0.5049\n",
      "1314/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5044\n",
      "1315/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5034\n",
      "1316/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5113\n",
      "1317/15000:\n",
      "Training Loss: 0.5195 Validation Loss: 0.5137\n",
      "1318/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5026\n",
      "1319/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5102\n",
      "1320/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5095\n",
      "1321/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5133\n",
      "1322/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5104\n",
      "1323/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5062\n",
      "1324/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.5136\n",
      "1325/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.5042\n",
      "1326/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5006\n",
      "1327/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.4973\n",
      "1328/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.4983\n",
      "1329/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5040\n",
      "1330/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5153\n",
      "1331/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5263\n",
      "1332/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5069\n",
      "1333/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5035\n",
      "1334/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5071\n",
      "1335/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5028\n",
      "1336/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5024\n",
      "1337/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5021\n",
      "1338/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4977\n",
      "1339/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5052\n",
      "1340/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5110\n",
      "1341/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5409\n",
      "1342/15000:\n",
      "Training Loss: 0.5570 Validation Loss: 0.5220\n",
      "1343/15000:\n",
      "Training Loss: 0.5341 Validation Loss: 0.5118\n",
      "1344/15000:\n",
      "Training Loss: 0.5311 Validation Loss: 0.5121\n",
      "1345/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.4957\n",
      "1346/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5000\n",
      "1347/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.4989\n",
      "1348/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.4935\n",
      "1349/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5014\n",
      "1350/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5051\n",
      "1351/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5094\n",
      "1352/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5013\n",
      "1353/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.4967\n",
      "1354/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5004\n",
      "1355/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5020\n",
      "1356/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5022\n",
      "1357/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5161\n",
      "1358/15000:\n",
      "Training Loss: 0.5226 Validation Loss: 0.4987\n",
      "1359/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.4968\n",
      "1360/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.4984\n",
      "1361/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4954\n",
      "1362/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5044\n",
      "1363/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5052\n",
      "1364/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4998\n",
      "1365/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.4998\n",
      "1366/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5042\n",
      "1367/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5060\n",
      "1368/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5016\n",
      "1369/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.5119\n",
      "1370/15000:\n",
      "Training Loss: 0.5260 Validation Loss: 0.5079\n",
      "1371/15000:\n",
      "Training Loss: 0.5429 Validation Loss: 0.5147\n",
      "1372/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.5186\n",
      "1373/15000:\n",
      "Training Loss: 0.5234 Validation Loss: 0.5016\n",
      "1374/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5053\n",
      "1375/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5038\n",
      "1376/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5016\n",
      "1377/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5020\n",
      "1378/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5000\n",
      "1379/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5041\n",
      "1380/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5140\n",
      "1381/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5044\n",
      "1382/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.6030\n",
      "1383/15000:\n",
      "Training Loss: 0.5904 Validation Loss: 0.6414\n",
      "1384/15000:\n",
      "Training Loss: 0.6598 Validation Loss: 0.5157\n",
      "1385/15000:\n",
      "Training Loss: 0.5327 Validation Loss: 0.5073\n",
      "1386/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5012\n",
      "1387/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5051\n",
      "1388/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.4975\n",
      "1389/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5064\n",
      "1390/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5072\n",
      "1391/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5037\n",
      "1392/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5134\n",
      "1393/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5038\n",
      "1394/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5026\n",
      "1395/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5118\n",
      "1396/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5101\n",
      "1397/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5090\n",
      "1398/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5133\n",
      "1399/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5039\n",
      "1400/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5071\n",
      "1401/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5093\n",
      "1402/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5263\n",
      "1403/15000:\n",
      "Training Loss: 0.5305 Validation Loss: 0.5036\n",
      "1404/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5266\n",
      "1405/15000:\n",
      "Training Loss: 0.5287 Validation Loss: 0.5232\n",
      "1406/15000:\n",
      "Training Loss: 0.5570 Validation Loss: 0.5120\n",
      "1407/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.4994\n",
      "1408/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.4962\n",
      "1409/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5050\n",
      "1410/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5008\n",
      "1411/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5014\n",
      "1412/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5044\n",
      "1413/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5055\n",
      "1414/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4981\n",
      "1415/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.4975\n",
      "1416/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5001\n",
      "1417/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5042\n",
      "1418/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5045\n",
      "1419/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5070\n",
      "1420/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5054\n",
      "1421/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5147\n",
      "1422/15000:\n",
      "Training Loss: 0.5245 Validation Loss: 0.5244\n",
      "1423/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5168\n",
      "1424/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.4955\n",
      "1425/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.4985\n",
      "1426/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5082\n",
      "1427/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.4970\n",
      "1428/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5039\n",
      "1429/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5093\n",
      "1430/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5056\n",
      "1431/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.5081\n",
      "1432/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5048\n",
      "1433/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5103\n",
      "1434/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5117\n",
      "1435/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5018\n",
      "1436/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5160\n",
      "1437/15000:\n",
      "Training Loss: 0.5211 Validation Loss: 0.5269\n",
      "1438/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.5047\n",
      "1439/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5193\n",
      "1440/15000:\n",
      "Training Loss: 0.5284 Validation Loss: 0.5129\n",
      "1441/15000:\n",
      "Training Loss: 0.5212 Validation Loss: 0.5265\n",
      "1442/15000:\n",
      "Training Loss: 0.5289 Validation Loss: 0.5036\n",
      "1443/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5053\n",
      "1444/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5679\n",
      "1445/15000:\n",
      "Training Loss: 0.5608 Validation Loss: 0.5721\n",
      "1446/15000:\n",
      "Training Loss: 0.6037 Validation Loss: 0.5582\n",
      "1447/15000:\n",
      "Training Loss: 0.5632 Validation Loss: 0.5304\n",
      "1448/15000:\n",
      "Training Loss: 0.5497 Validation Loss: 0.5121\n",
      "1449/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5051\n",
      "1450/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5132\n",
      "1451/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5041\n",
      "1452/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5118\n",
      "1453/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.5021\n",
      "1454/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5129\n",
      "1455/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.5081\n",
      "1456/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5170\n",
      "1457/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5247\n",
      "1458/15000:\n",
      "Training Loss: 0.5386 Validation Loss: 0.5149\n",
      "1459/15000:\n",
      "Training Loss: 0.5156 Validation Loss: 0.5130\n",
      "1460/15000:\n",
      "Training Loss: 0.5242 Validation Loss: 0.4995\n",
      "1461/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5001\n",
      "1462/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5051\n",
      "1463/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5030\n",
      "1464/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5080\n",
      "1465/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5391\n",
      "1466/15000:\n",
      "Training Loss: 0.5364 Validation Loss: 0.5496\n",
      "1467/15000:\n",
      "Training Loss: 0.5997 Validation Loss: 0.5159\n",
      "1468/15000:\n",
      "Training Loss: 0.5306 Validation Loss: 0.5060\n",
      "1469/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.5057\n",
      "1470/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5037\n",
      "1471/15000:\n",
      "Training Loss: 0.5329 Validation Loss: 0.5078\n",
      "1472/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5095\n",
      "1473/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5074\n",
      "1474/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5135\n",
      "1475/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5057\n",
      "1476/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.5101\n",
      "1477/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4984\n",
      "1478/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5075\n",
      "1479/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5270\n",
      "1480/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.5097\n",
      "1481/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5350\n",
      "1482/15000:\n",
      "Training Loss: 0.5350 Validation Loss: 0.5584\n",
      "1483/15000:\n",
      "Training Loss: 0.5955 Validation Loss: 0.5187\n",
      "1484/15000:\n",
      "Training Loss: 0.5337 Validation Loss: 0.5232\n",
      "1485/15000:\n",
      "Training Loss: 0.5394 Validation Loss: 0.5128\n",
      "1486/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5058\n",
      "1487/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5067\n",
      "1488/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5066\n",
      "1489/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5055\n",
      "1490/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5068\n",
      "1491/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5085\n",
      "1492/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5070\n",
      "1493/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.4997\n",
      "1494/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5005\n",
      "1495/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5005\n",
      "1496/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4975\n",
      "1497/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.4996\n",
      "1498/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5098\n",
      "1499/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5005\n",
      "1500/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.4975\n",
      "1501/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.4991\n",
      "1502/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.4999\n",
      "1503/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5069\n",
      "1504/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5280\n",
      "1505/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5160\n",
      "1506/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5007\n",
      "1507/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5043\n",
      "1508/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4979\n",
      "1509/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.4976\n",
      "1510/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5069\n",
      "1511/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5023\n",
      "1512/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5122\n",
      "1513/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5133\n",
      "1514/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5302\n",
      "1515/15000:\n",
      "Training Loss: 0.5370 Validation Loss: 0.5455\n",
      "1516/15000:\n",
      "Training Loss: 0.5727 Validation Loss: 0.5162\n",
      "1517/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.4990\n",
      "1518/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.4989\n",
      "1519/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.4976\n",
      "1520/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5124\n",
      "1521/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5183\n",
      "1522/15000:\n",
      "Training Loss: 0.5274 Validation Loss: 0.5131\n",
      "1523/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4956\n",
      "1524/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.4980\n",
      "1525/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.4985\n",
      "1526/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5033\n",
      "1527/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.4970\n",
      "1528/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5015\n",
      "1529/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.4984\n",
      "1530/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.4958\n",
      "1531/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.4947\n",
      "1532/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.4957\n",
      "1533/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.4986\n",
      "1534/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5011\n",
      "1535/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5016\n",
      "1536/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.4930\n",
      "1537/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4984\n",
      "1538/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4956\n",
      "1539/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5012\n",
      "1540/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4968\n",
      "1541/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5057\n",
      "1542/15000:\n",
      "Training Loss: 0.5352 Validation Loss: 0.5053\n",
      "1543/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5560\n",
      "1544/15000:\n",
      "Training Loss: 0.5301 Validation Loss: 0.5315\n",
      "1545/15000:\n",
      "Training Loss: 0.5672 Validation Loss: 0.5110\n",
      "1546/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5044\n",
      "1547/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5078\n",
      "1548/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5025\n",
      "1549/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.4991\n",
      "1550/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5074\n",
      "1551/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5084\n",
      "1552/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4963\n",
      "1553/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5017\n",
      "1554/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5033\n",
      "1555/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5033\n",
      "1556/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5027\n",
      "1557/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5155\n",
      "1558/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5052\n",
      "1559/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5030\n",
      "1560/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5126\n",
      "1561/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5568\n",
      "1562/15000:\n",
      "Training Loss: 0.5574 Validation Loss: 0.5205\n",
      "1563/15000:\n",
      "Training Loss: 0.5425 Validation Loss: 0.5073\n",
      "1564/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5048\n",
      "1565/15000:\n",
      "Training Loss: 0.5342 Validation Loss: 0.5131\n",
      "1566/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5043\n",
      "1567/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.4974\n",
      "1568/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.4982\n",
      "1569/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5026\n",
      "1570/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5130\n",
      "1571/15000:\n",
      "Training Loss: 0.5295 Validation Loss: 0.5089\n",
      "1572/15000:\n",
      "Training Loss: 0.5296 Validation Loss: 0.5039\n",
      "1573/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5068\n",
      "1574/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4966\n",
      "1575/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.4989\n",
      "1576/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4996\n",
      "1577/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5000\n",
      "1578/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5070\n",
      "1579/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5076\n",
      "1580/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5169\n",
      "1581/15000:\n",
      "Training Loss: 0.5353 Validation Loss: 0.5134\n",
      "1582/15000:\n",
      "Training Loss: 0.5476 Validation Loss: 0.5216\n",
      "1583/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5007\n",
      "1584/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.4980\n",
      "1585/15000:\n",
      "Training Loss: 0.5328 Validation Loss: 0.4985\n",
      "1586/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4956\n",
      "1587/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4928\n",
      "1588/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4949\n",
      "1589/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5012\n",
      "1590/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4996\n",
      "1591/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5053\n",
      "1592/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5179\n",
      "1593/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.5180\n",
      "1594/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5135\n",
      "1595/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5216\n",
      "1596/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5568\n",
      "1597/15000:\n",
      "Training Loss: 0.5584 Validation Loss: 0.5475\n",
      "1598/15000:\n",
      "Training Loss: 0.5770 Validation Loss: 0.5167\n",
      "1599/15000:\n",
      "Training Loss: 0.5320 Validation Loss: 0.5087\n",
      "1600/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5026\n",
      "1601/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5029\n",
      "1602/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5052\n",
      "1603/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5074\n",
      "1604/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5089\n",
      "1605/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5111\n",
      "1606/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5058\n",
      "1607/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4985\n",
      "1608/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5052\n",
      "1609/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5036\n",
      "1610/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5048\n",
      "1611/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5060\n",
      "1612/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5146\n",
      "1613/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5183\n",
      "1614/15000:\n",
      "Training Loss: 0.5224 Validation Loss: 0.5432\n",
      "1615/15000:\n",
      "Training Loss: 0.5534 Validation Loss: 0.5276\n",
      "1616/15000:\n",
      "Training Loss: 0.5431 Validation Loss: 0.5195\n",
      "1617/15000:\n",
      "Training Loss: 0.5206 Validation Loss: 0.4960\n",
      "1618/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4996\n",
      "1619/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5025\n",
      "1620/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5016\n",
      "1621/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5016\n",
      "1622/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4990\n",
      "1623/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5058\n",
      "1624/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5076\n",
      "1625/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5009\n",
      "1626/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4969\n",
      "1627/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5049\n",
      "1628/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5000\n",
      "1629/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5049\n",
      "1630/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.4972\n",
      "1631/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5046\n",
      "1632/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4944\n",
      "1633/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4988\n",
      "1634/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5037\n",
      "1635/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5053\n",
      "1636/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4952\n",
      "1637/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5028\n",
      "1638/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5089\n",
      "1639/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.4963\n",
      "1640/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4919\n",
      "1641/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.4965\n",
      "1642/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4933\n",
      "1643/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5145\n",
      "1644/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5145\n",
      "1645/15000:\n",
      "Training Loss: 0.5281 Validation Loss: 0.5330\n",
      "1646/15000:\n",
      "Training Loss: 0.5634 Validation Loss: 0.5268\n",
      "1647/15000:\n",
      "Training Loss: 0.5517 Validation Loss: 0.5043\n",
      "1648/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5054\n",
      "1649/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5033\n",
      "1650/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4989\n",
      "1651/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5119\n",
      "1652/15000:\n",
      "Training Loss: 0.5307 Validation Loss: 0.5004\n",
      "1653/15000:\n",
      "Training Loss: 0.5192 Validation Loss: 0.5045\n",
      "1654/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.4966\n",
      "1655/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5071\n",
      "1656/15000:\n",
      "Training Loss: 0.5356 Validation Loss: 0.5002\n",
      "1657/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4913\n",
      "1658/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5008\n",
      "1659/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5000\n",
      "1660/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.4945\n",
      "1661/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.4979\n",
      "1662/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4903\n",
      "1663/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.4899\n",
      "1664/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.4937\n",
      "1665/15000:\n",
      "Training Loss: 0.4680 Validation Loss: 0.4996\n",
      "1666/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5025\n",
      "1667/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.4968\n",
      "1668/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5048\n",
      "1669/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5186\n",
      "1670/15000:\n",
      "Training Loss: 0.5208 Validation Loss: 0.5138\n",
      "1671/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5116\n",
      "1672/15000:\n",
      "Training Loss: 0.5190 Validation Loss: 0.5097\n",
      "1673/15000:\n",
      "Training Loss: 0.5313 Validation Loss: 0.5268\n",
      "1674/15000:\n",
      "Training Loss: 0.5214 Validation Loss: 0.4957\n",
      "1675/15000:\n",
      "Training Loss: 0.5275 Validation Loss: 0.5010\n",
      "1676/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5036\n",
      "1677/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5040\n",
      "1678/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5074\n",
      "1679/15000:\n",
      "Training Loss: 0.5260 Validation Loss: 0.5273\n",
      "1680/15000:\n",
      "Training Loss: 0.5538 Validation Loss: 0.5286\n",
      "1681/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5063\n",
      "1682/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5264\n",
      "1683/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5109\n",
      "1684/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5162\n",
      "1685/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.4955\n",
      "1686/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5014\n",
      "1687/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5076\n",
      "1688/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5009\n",
      "1689/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.4935\n",
      "1690/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4947\n",
      "1691/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5059\n",
      "1692/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4987\n",
      "1693/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5004\n",
      "1694/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4934\n",
      "1695/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4945\n",
      "1696/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4962\n",
      "1697/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5184\n",
      "1698/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.4987\n",
      "1699/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.4919\n",
      "1700/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5014\n",
      "1701/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4924\n",
      "1702/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4958\n",
      "1703/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4896\n",
      "1704/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5005\n",
      "1705/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5022\n",
      "1706/15000:\n",
      "Training Loss: 0.5156 Validation Loss: 0.5032\n",
      "1707/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.4881\n",
      "1708/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.4942\n",
      "1709/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4985\n",
      "1710/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.4949\n",
      "1711/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4922\n",
      "1712/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5017\n",
      "1713/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.4991\n",
      "1714/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5166\n",
      "1715/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.5431\n",
      "1716/15000:\n",
      "Training Loss: 0.5360 Validation Loss: 0.5382\n",
      "1717/15000:\n",
      "Training Loss: 0.5700 Validation Loss: 0.5264\n",
      "1718/15000:\n",
      "Training Loss: 0.5571 Validation Loss: 0.5450\n",
      "1719/15000:\n",
      "Training Loss: 0.5624 Validation Loss: 0.5141\n",
      "1720/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5292\n",
      "1721/15000:\n",
      "Training Loss: 0.5301 Validation Loss: 0.5445\n",
      "1722/15000:\n",
      "Training Loss: 0.5537 Validation Loss: 0.5070\n",
      "1723/15000:\n",
      "Training Loss: 0.5359 Validation Loss: 0.4998\n",
      "1724/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5077\n",
      "1725/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5007\n",
      "1726/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5011\n",
      "1727/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5143\n",
      "1728/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.5128\n",
      "1729/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.4960\n",
      "1730/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4962\n",
      "1731/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4988\n",
      "1732/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5046\n",
      "1733/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5104\n",
      "1734/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5063\n",
      "1735/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5043\n",
      "1736/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4994\n",
      "1737/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.4970\n",
      "1738/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5005\n",
      "1739/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.4933\n",
      "1740/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5128\n",
      "1741/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5133\n",
      "1742/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.4947\n",
      "1743/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.4963\n",
      "1744/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5087\n",
      "1745/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5367\n",
      "1746/15000:\n",
      "Training Loss: 0.5330 Validation Loss: 0.5544\n",
      "1747/15000:\n",
      "Training Loss: 0.5806 Validation Loss: 0.5380\n",
      "1748/15000:\n",
      "Training Loss: 0.5313 Validation Loss: 0.5046\n",
      "1749/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5036\n",
      "1750/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4986\n",
      "1751/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4980\n",
      "1752/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.5024\n",
      "1753/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.4994\n",
      "1754/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5020\n",
      "1755/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.4951\n",
      "1756/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.4981\n",
      "1757/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4945\n",
      "1758/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.4934\n",
      "1759/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5063\n",
      "1760/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.4973\n",
      "1761/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4940\n",
      "1762/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4991\n",
      "1763/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.4998\n",
      "1764/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5002\n",
      "1765/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5034\n",
      "1766/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.5042\n",
      "1767/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5097\n",
      "1768/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5002\n",
      "1769/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4955\n",
      "1770/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5012\n",
      "1771/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5334\n",
      "1772/15000:\n",
      "Training Loss: 0.5655 Validation Loss: 0.5023\n",
      "1773/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5096\n",
      "1774/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5028\n",
      "1775/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5063\n",
      "1776/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5034\n",
      "1777/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5120\n",
      "1778/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4976\n",
      "1779/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.5033\n",
      "1780/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.4971\n",
      "1781/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4974\n",
      "1782/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4918\n",
      "1783/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4920\n",
      "1784/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4930\n",
      "1785/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4936\n",
      "1786/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5030\n",
      "1787/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5076\n",
      "1788/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5214\n",
      "1789/15000:\n",
      "Training Loss: 0.5345 Validation Loss: 0.5287\n",
      "1790/15000:\n",
      "Training Loss: 0.5269 Validation Loss: 0.5247\n",
      "1791/15000:\n",
      "Training Loss: 0.5203 Validation Loss: 0.5152\n",
      "1792/15000:\n",
      "Training Loss: 0.5307 Validation Loss: 0.5119\n",
      "1793/15000:\n",
      "Training Loss: 0.5271 Validation Loss: 0.5016\n",
      "1794/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5153\n",
      "1795/15000:\n",
      "Training Loss: 0.5226 Validation Loss: 0.5022\n",
      "1796/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4914\n",
      "1797/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.4895\n",
      "1798/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4933\n",
      "1799/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5020\n",
      "1800/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.4980\n",
      "1801/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.4950\n",
      "1802/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5060\n",
      "1803/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5149\n",
      "1804/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.4993\n",
      "1805/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.4975\n",
      "1806/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4947\n",
      "1807/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5039\n",
      "1808/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5059\n",
      "1809/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5103\n",
      "1810/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5193\n",
      "1811/15000:\n",
      "Training Loss: 0.5250 Validation Loss: 0.4954\n",
      "1812/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5110\n",
      "1813/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5035\n",
      "1814/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4971\n",
      "1815/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4960\n",
      "1816/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.4946\n",
      "1817/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.4940\n",
      "1818/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4976\n",
      "1819/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4990\n",
      "1820/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5002\n",
      "1821/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5102\n",
      "1822/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5252\n",
      "1823/15000:\n",
      "Training Loss: 0.5259 Validation Loss: 0.5338\n",
      "1824/15000:\n",
      "Training Loss: 0.5642 Validation Loss: 0.5081\n",
      "1825/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5191\n",
      "1826/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5177\n",
      "1827/15000:\n",
      "Training Loss: 0.5185 Validation Loss: 0.4934\n",
      "1828/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.4939\n",
      "1829/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.4940\n",
      "1830/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4941\n",
      "1831/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4999\n",
      "1832/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5022\n",
      "1833/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5005\n",
      "1834/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4934\n",
      "1835/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4908\n",
      "1836/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.4969\n",
      "1837/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4940\n",
      "1838/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.4933\n",
      "1839/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4981\n",
      "1840/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.4909\n",
      "1841/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4905\n",
      "1842/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4961\n",
      "1843/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.4976\n",
      "1844/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5053\n",
      "1845/15000:\n",
      "Training Loss: 0.5290 Validation Loss: 0.5204\n",
      "1846/15000:\n",
      "Training Loss: 0.5185 Validation Loss: 0.5032\n",
      "1847/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5112\n",
      "1848/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.5275\n",
      "1849/15000:\n",
      "Training Loss: 0.5451 Validation Loss: 0.5088\n",
      "1850/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5123\n",
      "1851/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.4995\n",
      "1852/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.4929\n",
      "1853/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5042\n",
      "1854/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5013\n",
      "1855/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4973\n",
      "1856/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4970\n",
      "1857/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.4930\n",
      "1858/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4898\n",
      "1859/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.4930\n",
      "1860/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4885\n",
      "1861/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4953\n",
      "1862/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.4990\n",
      "1863/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.4993\n",
      "1864/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.4970\n",
      "1865/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4980\n",
      "1866/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.4865\n",
      "1867/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4895\n",
      "1868/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4899\n",
      "1869/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.4930\n",
      "1870/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5180\n",
      "1871/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5342\n",
      "1872/15000:\n",
      "Training Loss: 0.5272 Validation Loss: 0.5117\n",
      "1873/15000:\n",
      "Training Loss: 0.5349 Validation Loss: 0.5384\n",
      "1874/15000:\n",
      "Training Loss: 0.5609 Validation Loss: 0.5391\n",
      "1875/15000:\n",
      "Training Loss: 0.5532 Validation Loss: 0.6286\n",
      "1876/15000:\n",
      "Training Loss: 0.6853 Validation Loss: 0.5739\n",
      "1877/15000:\n",
      "Training Loss: 0.5851 Validation Loss: 0.6191\n",
      "1878/15000:\n",
      "Training Loss: 0.6635 Validation Loss: 0.5084\n",
      "1879/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5085\n",
      "1880/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5006\n",
      "1881/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.4993\n",
      "1882/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5023\n",
      "1883/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5076\n",
      "1884/15000:\n",
      "Training Loss: 0.5332 Validation Loss: 0.5147\n",
      "1885/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5048\n",
      "1886/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5024\n",
      "1887/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5037\n",
      "1888/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5100\n",
      "1889/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5011\n",
      "1890/15000:\n",
      "Training Loss: 0.5221 Validation Loss: 0.5022\n",
      "1891/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5013\n",
      "1892/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.4985\n",
      "1893/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.4988\n",
      "1894/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5006\n",
      "1895/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5032\n",
      "1896/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5045\n",
      "1897/15000:\n",
      "Training Loss: 0.5179 Validation Loss: 0.5032\n",
      "1898/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5007\n",
      "1899/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5002\n",
      "1900/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5056\n",
      "1901/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5027\n",
      "1902/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5071\n",
      "1903/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5100\n",
      "1904/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5027\n",
      "1905/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5124\n",
      "1906/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5147\n",
      "1907/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5366\n",
      "1908/15000:\n",
      "Training Loss: 0.5457 Validation Loss: 0.5138\n",
      "1909/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4960\n",
      "1910/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.4970\n",
      "1911/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5087\n",
      "1912/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.4958\n",
      "1913/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.4961\n",
      "1914/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.4961\n",
      "1915/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.4971\n",
      "1916/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4982\n",
      "1917/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5018\n",
      "1918/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5027\n",
      "1919/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5123\n",
      "1920/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.4968\n",
      "1921/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5114\n",
      "1922/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5165\n",
      "1923/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.4932\n",
      "1924/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5042\n",
      "1925/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.4941\n",
      "1926/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5156\n",
      "1927/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.5014\n",
      "1928/15000:\n",
      "Training Loss: 0.5156 Validation Loss: 0.5180\n",
      "1929/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.4907\n",
      "1930/15000:\n",
      "Training Loss: 0.5255 Validation Loss: 0.5011\n",
      "1931/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5068\n",
      "1932/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5050\n",
      "1933/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5005\n",
      "1934/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5314\n",
      "1935/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.5032\n",
      "1936/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5032\n",
      "1937/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4941\n",
      "1938/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5001\n",
      "1939/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4938\n",
      "1940/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4948\n",
      "1941/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4976\n",
      "1942/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4956\n",
      "1943/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5290\n",
      "1944/15000:\n",
      "Training Loss: 0.5414 Validation Loss: 0.5281\n",
      "1945/15000:\n",
      "Training Loss: 0.5274 Validation Loss: 0.5020\n",
      "1946/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5172\n",
      "1947/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.4924\n",
      "1948/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.4970\n",
      "1949/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.4983\n",
      "1950/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5029\n",
      "1951/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5030\n",
      "1952/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5031\n",
      "1953/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.4943\n",
      "1954/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4964\n",
      "1955/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5105\n",
      "1956/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.4993\n",
      "1957/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5011\n",
      "1958/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5073\n",
      "1959/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5044\n",
      "1960/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5163\n",
      "1961/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5005\n",
      "1962/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5005\n",
      "1963/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5213\n",
      "1964/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5479\n",
      "1965/15000:\n",
      "Training Loss: 0.5771 Validation Loss: 0.5227\n",
      "1966/15000:\n",
      "Training Loss: 0.5319 Validation Loss: 0.5792\n",
      "1967/15000:\n",
      "Training Loss: 0.6101 Validation Loss: 0.5682\n",
      "1968/15000:\n",
      "Training Loss: 0.5583 Validation Loss: 0.5787\n",
      "1969/15000:\n",
      "Training Loss: 0.6386 Validation Loss: 0.5219\n",
      "1970/15000:\n",
      "Training Loss: 0.5364 Validation Loss: 0.5173\n",
      "1971/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5149\n",
      "1972/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5214\n",
      "1973/15000:\n",
      "Training Loss: 0.5334 Validation Loss: 0.5090\n",
      "1974/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.5178\n",
      "1975/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.5020\n",
      "1976/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5066\n",
      "1977/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5025\n",
      "1978/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5017\n",
      "1979/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5054\n",
      "1980/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.4958\n",
      "1981/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.4950\n",
      "1982/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.4991\n",
      "1983/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4991\n",
      "1984/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5039\n",
      "1985/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5009\n",
      "1986/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5070\n",
      "1987/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.4957\n",
      "1988/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5068\n",
      "1989/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5017\n",
      "1990/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.4943\n",
      "1991/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5010\n",
      "1992/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5051\n",
      "1993/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.5134\n",
      "1994/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5069\n",
      "1995/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.4962\n",
      "1996/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5042\n",
      "1997/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4962\n",
      "1998/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5016\n",
      "1999/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4947\n",
      "2000/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4999\n",
      "2001/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5101\n",
      "2002/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5516\n",
      "2003/15000:\n",
      "Training Loss: 0.5494 Validation Loss: 0.5227\n",
      "2004/15000:\n",
      "Training Loss: 0.5494 Validation Loss: 0.5172\n",
      "2005/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5000\n",
      "2006/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5032\n",
      "2007/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5028\n",
      "2008/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5214\n",
      "2009/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5143\n",
      "2010/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.4987\n",
      "2011/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5140\n",
      "2012/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5037\n",
      "2013/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5032\n",
      "2014/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5038\n",
      "2015/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5048\n",
      "2016/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5035\n",
      "2017/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4972\n",
      "2018/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5019\n",
      "2019/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5062\n",
      "2020/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5058\n",
      "2021/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.4986\n",
      "2022/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5135\n",
      "2023/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5030\n",
      "2024/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5103\n",
      "2025/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4965\n",
      "2026/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4965\n",
      "2027/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.4993\n",
      "2028/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5022\n",
      "2029/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.4962\n",
      "2030/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4985\n",
      "2031/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5018\n",
      "2032/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5043\n",
      "2033/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5053\n",
      "2034/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5010\n",
      "2035/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5037\n",
      "2036/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5135\n",
      "2037/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5108\n",
      "2038/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5163\n",
      "2039/15000:\n",
      "Training Loss: 0.5275 Validation Loss: 0.5468\n",
      "2040/15000:\n",
      "Training Loss: 0.5660 Validation Loss: 0.5459\n",
      "2041/15000:\n",
      "Training Loss: 0.5898 Validation Loss: 0.5405\n",
      "2042/15000:\n",
      "Training Loss: 0.5727 Validation Loss: 0.6541\n",
      "2043/15000:\n",
      "Training Loss: 0.6931 Validation Loss: 0.5658\n",
      "2044/15000:\n",
      "Training Loss: 0.5752 Validation Loss: 0.5084\n",
      "2045/15000:\n",
      "Training Loss: 0.5182 Validation Loss: 0.5157\n",
      "2046/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5034\n",
      "2047/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5026\n",
      "2048/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5031\n",
      "2049/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5039\n",
      "2050/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5026\n",
      "2051/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.4995\n",
      "2052/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4993\n",
      "2053/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5018\n",
      "2054/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5117\n",
      "2055/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5155\n",
      "2056/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5459\n",
      "2057/15000:\n",
      "Training Loss: 0.5493 Validation Loss: 0.4983\n",
      "2058/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5072\n",
      "2059/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5108\n",
      "2060/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5143\n",
      "2061/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5029\n",
      "2062/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5068\n",
      "2063/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5033\n",
      "2064/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5047\n",
      "2065/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.4982\n",
      "2066/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5054\n",
      "2067/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5018\n",
      "2068/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5171\n",
      "2069/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5149\n",
      "2070/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5036\n",
      "2071/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5018\n",
      "2072/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5106\n",
      "2073/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5049\n",
      "2074/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5036\n",
      "2075/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5187\n",
      "2076/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4997\n",
      "2077/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5006\n",
      "2078/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5057\n",
      "2079/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5105\n",
      "2080/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.4986\n",
      "2081/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5017\n",
      "2082/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5013\n",
      "2083/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4922\n",
      "2084/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5135\n",
      "2085/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5037\n",
      "2086/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.4984\n",
      "2087/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5110\n",
      "2088/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5092\n",
      "2089/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5148\n",
      "2090/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5021\n",
      "2091/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4977\n",
      "2092/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4979\n",
      "2093/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.4961\n",
      "2094/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5023\n",
      "2095/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5109\n",
      "2096/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5282\n",
      "2097/15000:\n",
      "Training Loss: 0.5269 Validation Loss: 0.5025\n",
      "2098/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4950\n",
      "2099/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5147\n",
      "2100/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4963\n",
      "2101/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4961\n",
      "2102/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5047\n",
      "2103/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5065\n",
      "2104/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5019\n",
      "2105/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5046\n",
      "2106/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5016\n",
      "2107/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5051\n",
      "2108/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5153\n",
      "2109/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5005\n",
      "2110/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5080\n",
      "2111/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5060\n",
      "2112/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5035\n",
      "2113/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5038\n",
      "2114/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5207\n",
      "2115/15000:\n",
      "Training Loss: 0.5274 Validation Loss: 0.5115\n",
      "2116/15000:\n",
      "Training Loss: 0.5281 Validation Loss: 0.5250\n",
      "2117/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5297\n",
      "2118/15000:\n",
      "Training Loss: 0.5299 Validation Loss: 0.4964\n",
      "2119/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4957\n",
      "2120/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.4945\n",
      "2121/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.4988\n",
      "2122/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5004\n",
      "2123/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5042\n",
      "2124/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5123\n",
      "2125/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5228\n",
      "2126/15000:\n",
      "Training Loss: 0.5284 Validation Loss: 0.5240\n",
      "2127/15000:\n",
      "Training Loss: 0.5386 Validation Loss: 0.5074\n",
      "2128/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5000\n",
      "2129/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5115\n",
      "2130/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5003\n",
      "2131/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5176\n",
      "2132/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5024\n",
      "2133/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5331\n",
      "2134/15000:\n",
      "Training Loss: 0.5325 Validation Loss: 0.5090\n",
      "2135/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5077\n",
      "2136/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5071\n",
      "2137/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5087\n",
      "2138/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.4983\n",
      "2139/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.4960\n",
      "2140/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5071\n",
      "2141/15000:\n",
      "Training Loss: 0.5225 Validation Loss: 0.5070\n",
      "2142/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5177\n",
      "2143/15000:\n",
      "Training Loss: 0.5264 Validation Loss: 0.5600\n",
      "2144/15000:\n",
      "Training Loss: 0.5560 Validation Loss: 0.5178\n",
      "2145/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.5075\n",
      "2146/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5016\n",
      "2147/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5030\n",
      "2148/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5018\n",
      "2149/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5029\n",
      "2150/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5087\n",
      "2151/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5062\n",
      "2152/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5198\n",
      "2153/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5098\n",
      "2154/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5095\n",
      "2155/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5153\n",
      "2156/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5103\n",
      "2157/15000:\n",
      "Training Loss: 0.5264 Validation Loss: 0.5079\n",
      "2158/15000:\n",
      "Training Loss: 0.5459 Validation Loss: 0.5046\n",
      "2159/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.5060\n",
      "2160/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5197\n",
      "2161/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5105\n",
      "2162/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5018\n",
      "2163/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5075\n",
      "2164/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5143\n",
      "2165/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5247\n",
      "2166/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5300\n",
      "2167/15000:\n",
      "Training Loss: 0.5302 Validation Loss: 0.5070\n",
      "2168/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5093\n",
      "2169/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5032\n",
      "2170/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5009\n",
      "2171/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5224\n",
      "2172/15000:\n",
      "Training Loss: 0.5360 Validation Loss: 0.5067\n",
      "2173/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4984\n",
      "2174/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5015\n",
      "2175/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.4955\n",
      "2176/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5097\n",
      "2177/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5111\n",
      "2178/15000:\n",
      "Training Loss: 0.5290 Validation Loss: 0.5208\n",
      "2179/15000:\n",
      "Training Loss: 0.5250 Validation Loss: 0.5020\n",
      "2180/15000:\n",
      "Training Loss: 0.5187 Validation Loss: 0.5000\n",
      "2181/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4940\n",
      "2182/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4997\n",
      "2183/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5045\n",
      "2184/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4985\n",
      "2185/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5012\n",
      "2186/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5016\n",
      "2187/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5006\n",
      "2188/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5106\n",
      "2189/15000:\n",
      "Training Loss: 0.5334 Validation Loss: 0.5895\n",
      "2190/15000:\n",
      "Training Loss: 0.5598 Validation Loss: 0.7009\n",
      "2191/15000:\n",
      "Training Loss: 0.7412 Validation Loss: 0.5349\n",
      "2192/15000:\n",
      "Training Loss: 0.5623 Validation Loss: 0.5192\n",
      "2193/15000:\n",
      "Training Loss: 0.5211 Validation Loss: 0.5111\n",
      "2194/15000:\n",
      "Training Loss: 0.5344 Validation Loss: 0.5060\n",
      "2195/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5140\n",
      "2196/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5066\n",
      "2197/15000:\n",
      "Training Loss: 0.5192 Validation Loss: 0.5071\n",
      "2198/15000:\n",
      "Training Loss: 0.5167 Validation Loss: 0.5054\n",
      "2199/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5022\n",
      "2200/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5071\n",
      "2201/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5029\n",
      "2202/15000:\n",
      "Training Loss: 0.5289 Validation Loss: 0.5149\n",
      "2203/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5034\n",
      "2204/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5095\n",
      "2205/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5083\n",
      "2206/15000:\n",
      "Training Loss: 0.5163 Validation Loss: 0.5158\n",
      "2207/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5032\n",
      "2208/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5038\n",
      "2209/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5123\n",
      "2210/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5415\n",
      "2211/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.5128\n",
      "2212/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5049\n",
      "2213/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5064\n",
      "2214/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.4994\n",
      "2215/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5054\n",
      "2216/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.4989\n",
      "2217/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5026\n",
      "2218/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4944\n",
      "2219/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4930\n",
      "2220/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5036\n",
      "2221/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4996\n",
      "2222/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5029\n",
      "2223/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.4988\n",
      "2224/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4950\n",
      "2225/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5104\n",
      "2226/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5158\n",
      "2227/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4999\n",
      "2228/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5004\n",
      "2229/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4981\n",
      "2230/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4967\n",
      "2231/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5054\n",
      "2232/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5087\n",
      "2233/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5119\n",
      "2234/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4985\n",
      "2235/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5075\n",
      "2236/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4958\n",
      "2237/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5034\n",
      "2238/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5049\n",
      "2239/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5053\n",
      "2240/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.4984\n",
      "2241/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5151\n",
      "2242/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5135\n",
      "2243/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5085\n",
      "2244/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4973\n",
      "2245/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5007\n",
      "2246/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5018\n",
      "2247/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5015\n",
      "2248/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5053\n",
      "2249/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5045\n",
      "2250/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.5089\n",
      "2251/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4948\n",
      "2252/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.4956\n",
      "2253/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5018\n",
      "2254/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4956\n",
      "2255/15000:\n",
      "Training Loss: 0.5192 Validation Loss: 0.5021\n",
      "2256/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5037\n",
      "2257/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.4993\n",
      "2258/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5134\n",
      "2259/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5052\n",
      "2260/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5195\n",
      "2261/15000:\n",
      "Training Loss: 0.5240 Validation Loss: 0.5154\n",
      "2262/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5161\n",
      "2263/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5194\n",
      "2264/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5109\n",
      "2265/15000:\n",
      "Training Loss: 0.5422 Validation Loss: 0.5077\n",
      "2266/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5027\n",
      "2267/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4933\n",
      "2268/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4918\n",
      "2269/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.4939\n",
      "2270/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4931\n",
      "2271/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.4991\n",
      "2272/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5013\n",
      "2273/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5160\n",
      "2274/15000:\n",
      "Training Loss: 0.5294 Validation Loss: 0.4980\n",
      "2275/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.4981\n",
      "2276/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.4960\n",
      "2277/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5112\n",
      "2278/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.5106\n",
      "2279/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5100\n",
      "2280/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5108\n",
      "2281/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5070\n",
      "2282/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5360\n",
      "2283/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.5265\n",
      "2284/15000:\n",
      "Training Loss: 0.5339 Validation Loss: 0.5461\n",
      "2285/15000:\n",
      "Training Loss: 0.5526 Validation Loss: 0.6004\n",
      "2286/15000:\n",
      "Training Loss: 0.6619 Validation Loss: 0.5343\n",
      "2287/15000:\n",
      "Training Loss: 0.5624 Validation Loss: 0.5157\n",
      "2288/15000:\n",
      "Training Loss: 0.5396 Validation Loss: 0.5038\n",
      "2289/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.4995\n",
      "2290/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5045\n",
      "2291/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5006\n",
      "2292/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.4993\n",
      "2293/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5025\n",
      "2294/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5061\n",
      "2295/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5063\n",
      "2296/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5097\n",
      "2297/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5091\n",
      "2298/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5079\n",
      "2299/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5021\n",
      "2300/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.4974\n",
      "2301/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4983\n",
      "2302/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5094\n",
      "2303/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5038\n",
      "2304/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5042\n",
      "2305/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4974\n",
      "2306/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.4962\n",
      "2307/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4999\n",
      "2308/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5004\n",
      "2309/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5005\n",
      "2310/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5141\n",
      "2311/15000:\n",
      "Training Loss: 0.5372 Validation Loss: 0.5025\n",
      "2312/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.4972\n",
      "2313/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4978\n",
      "2314/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5168\n",
      "2315/15000:\n",
      "Training Loss: 0.5306 Validation Loss: 0.4995\n",
      "2316/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5035\n",
      "2317/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5114\n",
      "2318/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.4958\n",
      "2319/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5044\n",
      "2320/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5087\n",
      "2321/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.4981\n",
      "2322/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4995\n",
      "2323/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4988\n",
      "2324/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4982\n",
      "2325/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5064\n",
      "2326/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4952\n",
      "2327/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5053\n",
      "2328/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5395\n",
      "2329/15000:\n",
      "Training Loss: 0.5155 Validation Loss: 0.5733\n",
      "2330/15000:\n",
      "Training Loss: 0.5820 Validation Loss: 0.5140\n",
      "2331/15000:\n",
      "Training Loss: 0.5259 Validation Loss: 0.4985\n",
      "2332/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.4962\n",
      "2333/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5038\n",
      "2334/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5054\n",
      "2335/15000:\n",
      "Training Loss: 0.5243 Validation Loss: 0.5103\n",
      "2336/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5079\n",
      "2337/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.4974\n",
      "2338/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4946\n",
      "2339/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4972\n",
      "2340/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5079\n",
      "2341/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5122\n",
      "2342/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5052\n",
      "2343/15000:\n",
      "Training Loss: 0.5163 Validation Loss: 0.5115\n",
      "2344/15000:\n",
      "Training Loss: 0.5250 Validation Loss: 0.5126\n",
      "2345/15000:\n",
      "Training Loss: 0.5363 Validation Loss: 0.5083\n",
      "2346/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5082\n",
      "2347/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5067\n",
      "2348/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5035\n",
      "2349/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5221\n",
      "2350/15000:\n",
      "Training Loss: 0.5235 Validation Loss: 0.5165\n",
      "2351/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5009\n",
      "2352/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.4996\n",
      "2353/15000:\n",
      "Training Loss: 0.5260 Validation Loss: 0.5001\n",
      "2354/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.4970\n",
      "2355/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.4926\n",
      "2356/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.4914\n",
      "2357/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.4936\n",
      "2358/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.4986\n",
      "2359/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5008\n",
      "2360/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5053\n",
      "2361/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.4938\n",
      "2362/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5026\n",
      "2363/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5061\n",
      "2364/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5247\n",
      "2365/15000:\n",
      "Training Loss: 0.5454 Validation Loss: 0.5607\n",
      "2366/15000:\n",
      "Training Loss: 0.5771 Validation Loss: 0.5153\n",
      "2367/15000:\n",
      "Training Loss: 0.5287 Validation Loss: 0.5091\n",
      "2368/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5091\n",
      "2369/15000:\n",
      "Training Loss: 0.5364 Validation Loss: 0.5027\n",
      "2370/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.4953\n",
      "2371/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4978\n",
      "2372/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4975\n",
      "2373/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5010\n",
      "2374/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5009\n",
      "2375/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5089\n",
      "2376/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5161\n",
      "2377/15000:\n",
      "Training Loss: 0.5253 Validation Loss: 0.4995\n",
      "2378/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5133\n",
      "2379/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.4988\n",
      "2380/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5024\n",
      "2381/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4940\n",
      "2382/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.4987\n",
      "2383/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5110\n",
      "2384/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5012\n",
      "2385/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.4974\n",
      "2386/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.4960\n",
      "2387/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.4992\n",
      "2388/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5095\n",
      "2389/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5124\n",
      "2390/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5202\n",
      "2391/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.5144\n",
      "2392/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5132\n",
      "2393/15000:\n",
      "Training Loss: 0.5253 Validation Loss: 0.5064\n",
      "2394/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5064\n",
      "2395/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5133\n",
      "2396/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.5143\n",
      "2397/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4988\n",
      "2398/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5041\n",
      "2399/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.4961\n",
      "2400/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.4953\n",
      "2401/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4948\n",
      "2402/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4979\n",
      "2403/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5048\n",
      "2404/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5003\n",
      "2405/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5046\n",
      "2406/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5152\n",
      "2407/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5010\n",
      "2408/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5066\n",
      "2409/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5018\n",
      "2410/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5035\n",
      "2411/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4948\n",
      "2412/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5010\n",
      "2413/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5085\n",
      "2414/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5437\n",
      "2415/15000:\n",
      "Training Loss: 0.5556 Validation Loss: 0.6119\n",
      "2416/15000:\n",
      "Training Loss: 0.6207 Validation Loss: 0.5438\n",
      "2417/15000:\n",
      "Training Loss: 0.5671 Validation Loss: 0.8000\n",
      "2418/15000:\n",
      "Training Loss: 0.8320 Validation Loss: 0.5253\n",
      "2419/15000:\n",
      "Training Loss: 0.5426 Validation Loss: 0.5139\n",
      "2420/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5186\n",
      "2421/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5172\n",
      "2422/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5119\n",
      "2423/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5127\n",
      "2424/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5116\n",
      "2425/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5020\n",
      "2426/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5009\n",
      "2427/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.4995\n",
      "2428/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5020\n",
      "2429/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5064\n",
      "2430/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5066\n",
      "2431/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5087\n",
      "2432/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5024\n",
      "2433/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5011\n",
      "2434/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5050\n",
      "2435/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4954\n",
      "2436/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4936\n",
      "2437/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5098\n",
      "2438/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.4995\n",
      "2439/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5010\n",
      "2440/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4977\n",
      "2441/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5086\n",
      "2442/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.5101\n",
      "2443/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.4925\n",
      "2444/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5056\n",
      "2445/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.4945\n",
      "2446/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5013\n",
      "2447/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5060\n",
      "2448/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.4973\n",
      "2449/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.4991\n",
      "2450/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5047\n",
      "2451/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5005\n",
      "2452/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4966\n",
      "2453/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4986\n",
      "2454/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.4976\n",
      "2455/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.4982\n",
      "2456/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5030\n",
      "2457/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5016\n",
      "2458/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5098\n",
      "2459/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5019\n",
      "2460/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4965\n",
      "2461/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4963\n",
      "2462/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5028\n",
      "2463/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5013\n",
      "2464/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5050\n",
      "2465/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5079\n",
      "2466/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5031\n",
      "2467/15000:\n",
      "Training Loss: 0.5264 Validation Loss: 0.5261\n",
      "2468/15000:\n",
      "Training Loss: 0.5359 Validation Loss: 0.5557\n",
      "2469/15000:\n",
      "Training Loss: 0.5937 Validation Loss: 0.5160\n",
      "2470/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5081\n",
      "2471/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.4984\n",
      "2472/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5044\n",
      "2473/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5081\n",
      "2474/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.4946\n",
      "2475/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4940\n",
      "2476/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.4959\n",
      "2477/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4977\n",
      "2478/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5021\n",
      "2479/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5070\n",
      "2480/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4925\n",
      "2481/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4965\n",
      "2482/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4944\n",
      "2483/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5042\n",
      "2484/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5079\n",
      "2485/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5031\n",
      "2486/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.4981\n",
      "2487/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.4981\n",
      "2488/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5046\n",
      "2489/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5139\n",
      "2490/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5100\n",
      "2491/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5038\n",
      "2492/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5085\n",
      "2493/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5222\n",
      "2494/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5242\n",
      "2495/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5002\n",
      "2496/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5047\n",
      "2497/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.5071\n",
      "2498/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5038\n",
      "2499/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5056\n",
      "2500/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5004\n",
      "2501/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.4989\n",
      "2502/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5001\n",
      "2503/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5032\n",
      "2504/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.4986\n",
      "2505/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5021\n",
      "2506/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4958\n",
      "2507/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5029\n",
      "2508/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4972\n",
      "2509/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5085\n",
      "2510/15000:\n",
      "Training Loss: 0.5247 Validation Loss: 0.5042\n",
      "2511/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5081\n",
      "2512/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5349\n",
      "2513/15000:\n",
      "Training Loss: 0.5283 Validation Loss: 0.5139\n",
      "2514/15000:\n",
      "Training Loss: 0.5401 Validation Loss: 0.5041\n",
      "2515/15000:\n",
      "Training Loss: 0.5274 Validation Loss: 0.5078\n",
      "2516/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.4997\n",
      "2517/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5041\n",
      "2518/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5037\n",
      "2519/15000:\n",
      "Training Loss: 0.5230 Validation Loss: 0.4961\n",
      "2520/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5024\n",
      "2521/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5024\n",
      "2522/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5011\n",
      "2523/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.4991\n",
      "2524/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5075\n",
      "2525/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5074\n",
      "2526/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.4918\n",
      "2527/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5044\n",
      "2528/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.4951\n",
      "2529/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.4937\n",
      "2530/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.4965\n",
      "2531/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5167\n",
      "2532/15000:\n",
      "Training Loss: 0.5417 Validation Loss: 0.5188\n",
      "2533/15000:\n",
      "Training Loss: 0.5214 Validation Loss: 0.5258\n",
      "2534/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.4957\n",
      "2535/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4970\n",
      "2536/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4980\n",
      "2537/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5036\n",
      "2538/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5090\n",
      "2539/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5177\n",
      "2540/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.5046\n",
      "2541/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.4976\n",
      "2542/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5022\n",
      "2543/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.4962\n",
      "2544/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5003\n",
      "2545/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5003\n",
      "2546/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.4989\n",
      "2547/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.4926\n",
      "2548/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5064\n",
      "2549/15000:\n",
      "Training Loss: 0.5185 Validation Loss: 0.5032\n",
      "2550/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5060\n",
      "2551/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.4972\n",
      "2552/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5007\n",
      "2553/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5023\n",
      "2554/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.4907\n",
      "2555/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.4923\n",
      "2556/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4944\n",
      "2557/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4994\n",
      "2558/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.4962\n",
      "2559/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4949\n",
      "2560/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4917\n",
      "2561/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4996\n",
      "2562/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5028\n",
      "2563/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4935\n",
      "2564/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4941\n",
      "2565/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4980\n",
      "2566/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5087\n",
      "2567/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4914\n",
      "2568/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.4963\n",
      "2569/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5128\n",
      "2570/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5139\n",
      "2571/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.4978\n",
      "2572/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5066\n",
      "2573/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4898\n",
      "2574/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4903\n",
      "2575/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5015\n",
      "2576/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5048\n",
      "2577/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.4959\n",
      "2578/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.4988\n",
      "2579/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5004\n",
      "2580/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5154\n",
      "2581/15000:\n",
      "Training Loss: 0.5285 Validation Loss: 0.5338\n",
      "2582/15000:\n",
      "Training Loss: 0.5359 Validation Loss: 0.5498\n",
      "2583/15000:\n",
      "Training Loss: 0.5630 Validation Loss: 0.5102\n",
      "2584/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5001\n",
      "2585/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5055\n",
      "2586/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5017\n",
      "2587/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5186\n",
      "2588/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5127\n",
      "2589/15000:\n",
      "Training Loss: 0.5187 Validation Loss: 0.5054\n",
      "2590/15000:\n",
      "Training Loss: 0.5213 Validation Loss: 0.5066\n",
      "2591/15000:\n",
      "Training Loss: 0.5355 Validation Loss: 0.5045\n",
      "2592/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5104\n",
      "2593/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5071\n",
      "2594/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5049\n",
      "2595/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5036\n",
      "2596/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5228\n",
      "2597/15000:\n",
      "Training Loss: 0.5609 Validation Loss: 0.5182\n",
      "2598/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5144\n",
      "2599/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5216\n",
      "2600/15000:\n",
      "Training Loss: 0.5163 Validation Loss: 0.5021\n",
      "2601/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5029\n",
      "2602/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5038\n",
      "2603/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5024\n",
      "2604/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5009\n",
      "2605/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5069\n",
      "2606/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5011\n",
      "2607/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5103\n",
      "2608/15000:\n",
      "Training Loss: 0.5190 Validation Loss: 0.5160\n",
      "2609/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.4976\n",
      "2610/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.4956\n",
      "2611/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4961\n",
      "2612/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4968\n",
      "2613/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5219\n",
      "2614/15000:\n",
      "Training Loss: 0.5474 Validation Loss: 0.5767\n",
      "2615/15000:\n",
      "Training Loss: 0.5515 Validation Loss: 0.5530\n",
      "2616/15000:\n",
      "Training Loss: 0.5938 Validation Loss: 0.5259\n",
      "2617/15000:\n",
      "Training Loss: 0.5292 Validation Loss: 0.5069\n",
      "2618/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5095\n",
      "2619/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4980\n",
      "2620/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.4988\n",
      "2621/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5031\n",
      "2622/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5008\n",
      "2623/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5101\n",
      "2624/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5066\n",
      "2625/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5128\n",
      "2626/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.4973\n",
      "2627/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.4954\n",
      "2628/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5001\n",
      "2629/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.4998\n",
      "2630/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5031\n",
      "2631/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5009\n",
      "2632/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4948\n",
      "2633/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.4948\n",
      "2634/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5034\n",
      "2635/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5103\n",
      "2636/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5072\n",
      "2637/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5201\n",
      "2638/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5057\n",
      "2639/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5157\n",
      "2640/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5000\n",
      "2641/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.4980\n",
      "2642/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5010\n",
      "2643/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4972\n",
      "2644/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5176\n",
      "2645/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5318\n",
      "2646/15000:\n",
      "Training Loss: 0.5324 Validation Loss: 0.5185\n",
      "2647/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5229\n",
      "2648/15000:\n",
      "Training Loss: 0.5346 Validation Loss: 0.5166\n",
      "2649/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5031\n",
      "2650/15000:\n",
      "Training Loss: 0.5242 Validation Loss: 0.5109\n",
      "2651/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5078\n",
      "2652/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5081\n",
      "2653/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5031\n",
      "2654/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5055\n",
      "2655/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5059\n",
      "2656/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5058\n",
      "2657/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.4965\n",
      "2658/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5015\n",
      "2659/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.4902\n",
      "2660/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.4936\n",
      "2661/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.4973\n",
      "2662/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4998\n",
      "2663/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4906\n",
      "2664/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.4952\n",
      "2665/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5074\n",
      "2666/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.4953\n",
      "2667/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4981\n",
      "2668/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4945\n",
      "2669/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4950\n",
      "2670/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4945\n",
      "2671/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4957\n",
      "2672/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5068\n",
      "2673/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5225\n",
      "2674/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5079\n",
      "2675/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.4911\n",
      "2676/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4949\n",
      "2677/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5128\n",
      "2678/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5021\n",
      "2679/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5215\n",
      "2680/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5214\n",
      "2681/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.4989\n",
      "2682/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4975\n",
      "2683/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5006\n",
      "2684/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5012\n",
      "2685/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5033\n",
      "2686/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5095\n",
      "2687/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5155\n",
      "2688/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5183\n",
      "2689/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5065\n",
      "2690/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5070\n",
      "2691/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5172\n",
      "2692/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4977\n",
      "2693/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.4965\n",
      "2694/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4969\n",
      "2695/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5091\n",
      "2696/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5098\n",
      "2697/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.4979\n",
      "2698/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.4948\n",
      "2699/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4952\n",
      "2700/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4927\n",
      "2701/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.4951\n",
      "2702/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5103\n",
      "2703/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5411\n",
      "2704/15000:\n",
      "Training Loss: 0.5332 Validation Loss: 0.4989\n",
      "2705/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5030\n",
      "2706/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.4947\n",
      "2707/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.4926\n",
      "2708/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.4925\n",
      "2709/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4911\n",
      "2710/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.4963\n",
      "2711/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.4981\n",
      "2712/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.4951\n",
      "2713/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.4980\n",
      "2714/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.4923\n",
      "2715/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4935\n",
      "2716/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.4961\n",
      "2717/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5041\n",
      "2718/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5053\n",
      "2719/15000:\n",
      "Training Loss: 0.5317 Validation Loss: 0.5059\n",
      "2720/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5297\n",
      "2721/15000:\n",
      "Training Loss: 0.5344 Validation Loss: 0.5656\n",
      "2722/15000:\n",
      "Training Loss: 0.5731 Validation Loss: 0.5605\n",
      "2723/15000:\n",
      "Training Loss: 0.6155 Validation Loss: 0.5276\n",
      "2724/15000:\n",
      "Training Loss: 0.5428 Validation Loss: 0.5119\n",
      "2725/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5073\n",
      "2726/15000:\n",
      "Training Loss: 0.5274 Validation Loss: 0.5030\n",
      "2727/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5100\n",
      "2728/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5105\n",
      "2729/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5116\n",
      "2730/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5050\n",
      "2731/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5082\n",
      "2732/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5121\n",
      "2733/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5008\n",
      "2734/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5054\n",
      "2735/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5085\n",
      "2736/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5026\n",
      "2737/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5335\n",
      "2738/15000:\n",
      "Training Loss: 0.5241 Validation Loss: 0.5093\n",
      "2739/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5061\n",
      "2740/15000:\n",
      "Training Loss: 0.5226 Validation Loss: 0.5448\n",
      "2741/15000:\n",
      "Training Loss: 0.5522 Validation Loss: 0.5225\n",
      "2742/15000:\n",
      "Training Loss: 0.5472 Validation Loss: 0.4991\n",
      "2743/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5009\n",
      "2744/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5055\n",
      "2745/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5040\n",
      "2746/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5402\n",
      "2747/15000:\n",
      "Training Loss: 0.5446 Validation Loss: 0.5141\n",
      "2748/15000:\n",
      "Training Loss: 0.5516 Validation Loss: 0.5102\n",
      "2749/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5027\n",
      "2750/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.5049\n",
      "2751/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5022\n",
      "2752/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5011\n",
      "2753/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.5017\n",
      "2754/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.4998\n",
      "2755/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5063\n",
      "2756/15000:\n",
      "Training Loss: 0.5366 Validation Loss: 0.5006\n",
      "2757/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5103\n",
      "2758/15000:\n",
      "Training Loss: 0.5247 Validation Loss: 0.5235\n",
      "2759/15000:\n",
      "Training Loss: 0.5620 Validation Loss: 0.5510\n",
      "2760/15000:\n",
      "Training Loss: 0.5571 Validation Loss: 0.6025\n",
      "2761/15000:\n",
      "Training Loss: 0.6456 Validation Loss: 0.5445\n",
      "2762/15000:\n",
      "Training Loss: 0.5614 Validation Loss: 0.5871\n",
      "2763/15000:\n",
      "Training Loss: 0.6134 Validation Loss: 0.5267\n",
      "2764/15000:\n",
      "Training Loss: 0.5339 Validation Loss: 0.5038\n",
      "2765/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4982\n",
      "2766/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5045\n",
      "2767/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5064\n",
      "2768/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5060\n",
      "2769/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5058\n",
      "2770/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5005\n",
      "2771/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4974\n",
      "2772/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5013\n",
      "2773/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.4970\n",
      "2774/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5096\n",
      "2775/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5051\n",
      "2776/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5069\n",
      "2777/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5006\n",
      "2778/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4969\n",
      "2779/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5039\n",
      "2780/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.4997\n",
      "2781/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5004\n",
      "2782/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5008\n",
      "2783/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5041\n",
      "2784/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.4922\n",
      "2785/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4939\n",
      "2786/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4976\n",
      "2787/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5095\n",
      "2788/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4966\n",
      "2789/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.4952\n",
      "2790/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5039\n",
      "2791/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4939\n",
      "2792/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5047\n",
      "2793/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5070\n",
      "2794/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4954\n",
      "2795/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.4972\n",
      "2796/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5077\n",
      "2797/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5085\n",
      "2798/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5007\n",
      "2799/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5037\n",
      "2800/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5024\n",
      "2801/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4953\n",
      "2802/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.4966\n",
      "2803/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5039\n",
      "2804/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.4964\n",
      "2805/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4915\n",
      "2806/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4995\n",
      "2807/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4933\n",
      "2808/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.4969\n",
      "2809/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4993\n",
      "2810/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4917\n",
      "2811/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4938\n",
      "2812/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4988\n",
      "2813/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5087\n",
      "2814/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.4963\n",
      "2815/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.4947\n",
      "2816/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.4978\n",
      "2817/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5315\n",
      "2818/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5441\n",
      "2819/15000:\n",
      "Training Loss: 0.5682 Validation Loss: 0.4977\n",
      "2820/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4954\n",
      "2821/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4954\n",
      "2822/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4943\n",
      "2823/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.4929\n",
      "2824/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.4941\n",
      "2825/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4941\n",
      "2826/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5067\n",
      "2827/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5005\n",
      "2828/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.4981\n",
      "2829/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5038\n",
      "2830/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5164\n",
      "2831/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5219\n",
      "2832/15000:\n",
      "Training Loss: 0.5292 Validation Loss: 0.5296\n",
      "2833/15000:\n",
      "Training Loss: 0.5387 Validation Loss: 0.5241\n",
      "2834/15000:\n",
      "Training Loss: 0.5249 Validation Loss: 0.5034\n",
      "2835/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4961\n",
      "2836/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5079\n",
      "2837/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4935\n",
      "2838/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.4908\n",
      "2839/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4921\n",
      "2840/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.4925\n",
      "2841/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5259\n",
      "2842/15000:\n",
      "Training Loss: 0.5264 Validation Loss: 0.5108\n",
      "2843/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.4996\n",
      "2844/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5065\n",
      "2845/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5011\n",
      "2846/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.4927\n",
      "2847/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.4923\n",
      "2848/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4999\n",
      "2849/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5021\n",
      "2850/15000:\n",
      "Training Loss: 0.5205 Validation Loss: 0.4917\n",
      "2851/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.4917\n",
      "2852/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.4923\n",
      "2853/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4934\n",
      "2854/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5016\n",
      "2855/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4921\n",
      "2856/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4882\n",
      "2857/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.4942\n",
      "2858/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.4908\n",
      "2859/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4907\n",
      "2860/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4921\n",
      "2861/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4932\n",
      "2862/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4973\n",
      "2863/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5097\n",
      "2864/15000:\n",
      "Training Loss: 0.5224 Validation Loss: 0.5059\n",
      "2865/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5155\n",
      "2866/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4904\n",
      "2867/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5149\n",
      "2868/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5170\n",
      "2869/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5172\n",
      "2870/15000:\n",
      "Training Loss: 0.5163 Validation Loss: 0.5572\n",
      "2871/15000:\n",
      "Training Loss: 0.5548 Validation Loss: 0.5945\n",
      "2872/15000:\n",
      "Training Loss: 0.6383 Validation Loss: 0.5770\n",
      "2873/15000:\n",
      "Training Loss: 0.5671 Validation Loss: 0.5205\n",
      "2874/15000:\n",
      "Training Loss: 0.5507 Validation Loss: 0.5165\n",
      "2875/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5065\n",
      "2876/15000:\n",
      "Training Loss: 0.5179 Validation Loss: 0.5066\n",
      "2877/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5070\n",
      "2878/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5081\n",
      "2879/15000:\n",
      "Training Loss: 0.5216 Validation Loss: 0.5045\n",
      "2880/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5093\n",
      "2881/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5022\n",
      "2882/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.4971\n",
      "2883/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5008\n",
      "2884/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.4979\n",
      "2885/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4954\n",
      "2886/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4935\n",
      "2887/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5001\n",
      "2888/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.4962\n",
      "2889/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4960\n",
      "2890/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5057\n",
      "2891/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4964\n",
      "2892/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5098\n",
      "2893/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5086\n",
      "2894/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4978\n",
      "2895/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5044\n",
      "2896/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4956\n",
      "2897/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5061\n",
      "2898/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5182\n",
      "2899/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.4962\n",
      "2900/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5030\n",
      "2901/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.4949\n",
      "2902/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4966\n",
      "2903/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5062\n",
      "2904/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5015\n",
      "2905/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5110\n",
      "2906/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4996\n",
      "2907/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4896\n",
      "2908/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5372\n",
      "2909/15000:\n",
      "Training Loss: 0.5283 Validation Loss: 0.5471\n",
      "2910/15000:\n",
      "Training Loss: 0.5485 Validation Loss: 0.8588\n",
      "2911/15000:\n",
      "Training Loss: 0.8594 Validation Loss: 0.5692\n",
      "2912/15000:\n",
      "Training Loss: 0.5522 Validation Loss: 0.5112\n",
      "2913/15000:\n",
      "Training Loss: 0.5410 Validation Loss: 0.5060\n",
      "2914/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5112\n",
      "2915/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5067\n",
      "2916/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5023\n",
      "2917/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4983\n",
      "2918/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.4963\n",
      "2919/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5003\n",
      "2920/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5033\n",
      "2921/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5036\n",
      "2922/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5006\n",
      "2923/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.4967\n",
      "2924/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4996\n",
      "2925/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4963\n",
      "2926/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5075\n",
      "2927/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5052\n",
      "2928/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5011\n",
      "2929/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.4991\n",
      "2930/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5006\n",
      "2931/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5055\n",
      "2932/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5054\n",
      "2933/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5076\n",
      "2934/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5118\n",
      "2935/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.4996\n",
      "2936/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5121\n",
      "2937/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5354\n",
      "2938/15000:\n",
      "Training Loss: 0.5276 Validation Loss: 0.4953\n",
      "2939/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.4925\n",
      "2940/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.4967\n",
      "2941/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5012\n",
      "2942/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4888\n",
      "2943/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4953\n",
      "2944/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4924\n",
      "2945/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4949\n",
      "2946/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5046\n",
      "2947/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5041\n",
      "2948/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5164\n",
      "2949/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5099\n",
      "2950/15000:\n",
      "Training Loss: 0.5190 Validation Loss: 0.5067\n",
      "2951/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5025\n",
      "2952/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5044\n",
      "2953/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4997\n",
      "2954/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.4941\n",
      "2955/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5018\n",
      "2956/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.4915\n",
      "2957/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.4938\n",
      "2958/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.4934\n",
      "2959/15000:\n",
      "Training Loss: 0.4717 Validation Loss: 0.5064\n",
      "2960/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5129\n",
      "2961/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.4978\n",
      "2962/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5084\n",
      "2963/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5003\n",
      "2964/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5063\n",
      "2965/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5067\n",
      "2966/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.4959\n",
      "2967/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5016\n",
      "2968/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.4954\n",
      "2969/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5089\n",
      "2970/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5043\n",
      "2971/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5073\n",
      "2972/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5130\n",
      "2973/15000:\n",
      "Training Loss: 0.5211 Validation Loss: 0.5017\n",
      "2974/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.4972\n",
      "2975/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.4943\n",
      "2976/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.4923\n",
      "2977/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5020\n",
      "2978/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.4954\n",
      "2979/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.4961\n",
      "2980/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5089\n",
      "2981/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5023\n",
      "2982/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.4936\n",
      "2983/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.4973\n",
      "2984/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.4944\n",
      "2985/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4913\n",
      "2986/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4957\n",
      "2987/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.4997\n",
      "2988/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5052\n",
      "2989/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5224\n",
      "2990/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5046\n",
      "2991/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5025\n",
      "2992/15000:\n",
      "Training Loss: 0.5195 Validation Loss: 0.4970\n",
      "2993/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5027\n",
      "2994/15000:\n",
      "Training Loss: 0.5252 Validation Loss: 0.5194\n",
      "2995/15000:\n",
      "Training Loss: 0.5285 Validation Loss: 0.5055\n",
      "2996/15000:\n",
      "Training Loss: 0.5167 Validation Loss: 0.4963\n",
      "2997/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5071\n",
      "2998/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4962\n",
      "2999/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5089\n",
      "3000/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5091\n",
      "3001/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5108\n",
      "3002/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4907\n",
      "3003/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4968\n",
      "3004/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5047\n",
      "3005/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5038\n",
      "3006/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.5082\n",
      "3007/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5104\n",
      "3008/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5007\n",
      "3009/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5041\n",
      "3010/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.4973\n",
      "3011/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5092\n",
      "3012/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5100\n",
      "3013/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5171\n",
      "3014/15000:\n",
      "Training Loss: 0.5292 Validation Loss: 0.5386\n",
      "3015/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5005\n",
      "3016/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.4976\n",
      "3017/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4912\n",
      "3018/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.4917\n",
      "3019/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5154\n",
      "3020/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5065\n",
      "3021/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.5190\n",
      "3022/15000:\n",
      "Training Loss: 0.5329 Validation Loss: 0.6141\n",
      "3023/15000:\n",
      "Training Loss: 0.5999 Validation Loss: 0.6307\n",
      "3024/15000:\n",
      "Training Loss: 0.6683 Validation Loss: 0.5766\n",
      "3025/15000:\n",
      "Training Loss: 0.5824 Validation Loss: 0.5217\n",
      "3026/15000:\n",
      "Training Loss: 0.5335 Validation Loss: 0.5106\n",
      "3027/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5082\n",
      "3028/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5103\n",
      "3029/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5078\n",
      "3030/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5092\n",
      "3031/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5232\n",
      "3032/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5126\n",
      "3033/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5038\n",
      "3034/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5027\n",
      "3035/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5009\n",
      "3036/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5033\n",
      "3037/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5015\n",
      "3038/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5015\n",
      "3039/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5040\n",
      "3040/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5074\n",
      "3041/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5205\n",
      "3042/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5266\n",
      "3043/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5095\n",
      "3044/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5136\n",
      "3045/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5042\n",
      "3046/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5069\n",
      "3047/15000:\n",
      "Training Loss: 0.5240 Validation Loss: 0.5153\n",
      "3048/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5179\n",
      "3049/15000:\n",
      "Training Loss: 0.5246 Validation Loss: 0.5058\n",
      "3050/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5024\n",
      "3051/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5041\n",
      "3052/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4976\n",
      "3053/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5087\n",
      "3054/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.4917\n",
      "3055/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5016\n",
      "3056/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.4912\n",
      "3057/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5029\n",
      "3058/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4949\n",
      "3059/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.4956\n",
      "3060/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4948\n",
      "3061/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5112\n",
      "3062/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5072\n",
      "3063/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4983\n",
      "3064/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4975\n",
      "3065/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5006\n",
      "3066/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.4964\n",
      "3067/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4972\n",
      "3068/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4953\n",
      "3069/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.4994\n",
      "3070/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5090\n",
      "3071/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.5109\n",
      "3072/15000:\n",
      "Training Loss: 0.5264 Validation Loss: 0.5028\n",
      "3073/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5072\n",
      "3074/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5022\n",
      "3075/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.4961\n",
      "3076/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.4906\n",
      "3077/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5012\n",
      "3078/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5008\n",
      "3079/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.4934\n",
      "3080/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4987\n",
      "3081/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5007\n",
      "3082/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.4952\n",
      "3083/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5017\n",
      "3084/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.5161\n",
      "3085/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4979\n",
      "3086/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5159\n",
      "3087/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.4967\n",
      "3088/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5083\n",
      "3089/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5048\n",
      "3090/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5096\n",
      "3091/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.4968\n",
      "3092/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5019\n",
      "3093/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5085\n",
      "3094/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5136\n",
      "3095/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5088\n",
      "3096/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5124\n",
      "3097/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5087\n",
      "3098/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5109\n",
      "3099/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5053\n",
      "3100/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5387\n",
      "3101/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5322\n",
      "3102/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.5315\n",
      "3103/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4959\n",
      "3104/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5091\n",
      "3105/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5070\n",
      "3106/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5052\n",
      "3107/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5018\n",
      "3108/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5019\n",
      "3109/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5039\n",
      "3110/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5012\n",
      "3111/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5046\n",
      "3112/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5024\n",
      "3113/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.4976\n",
      "3114/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4959\n",
      "3115/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4991\n",
      "3116/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5078\n",
      "3117/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5017\n",
      "3118/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5014\n",
      "3119/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4990\n",
      "3120/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.4971\n",
      "3121/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4948\n",
      "3122/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.4954\n",
      "3123/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.4908\n",
      "3124/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5044\n",
      "3125/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.4996\n",
      "3126/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4894\n",
      "3127/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.4934\n",
      "3128/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5021\n",
      "3129/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5054\n",
      "3130/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4967\n",
      "3131/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4985\n",
      "3132/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5210\n",
      "3133/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5129\n",
      "3134/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.4960\n",
      "3135/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.4995\n",
      "3136/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.4945\n",
      "3137/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4955\n",
      "3138/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4968\n",
      "3139/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5012\n",
      "3140/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5049\n",
      "3141/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5000\n",
      "3142/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4959\n",
      "3143/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4950\n",
      "3144/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4986\n",
      "3145/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.4998\n",
      "3146/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5142\n",
      "3147/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5044\n",
      "3148/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5016\n",
      "3149/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.4990\n",
      "3150/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5004\n",
      "3151/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4982\n",
      "3152/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.4903\n",
      "3153/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5042\n",
      "3154/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5065\n",
      "3155/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5156\n",
      "3156/15000:\n",
      "Training Loss: 0.5222 Validation Loss: 0.4997\n",
      "3157/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5253\n",
      "3158/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5415\n",
      "3159/15000:\n",
      "Training Loss: 0.5633 Validation Loss: 0.5399\n",
      "3160/15000:\n",
      "Training Loss: 0.5497 Validation Loss: 0.6718\n",
      "3161/15000:\n",
      "Training Loss: 0.6567 Validation Loss: 0.5061\n",
      "3162/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5064\n",
      "3163/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5113\n",
      "3164/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5054\n",
      "3165/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4922\n",
      "3166/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.4911\n",
      "3167/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4977\n",
      "3168/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4928\n",
      "3169/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4965\n",
      "3170/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4959\n",
      "3171/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5007\n",
      "3172/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4941\n",
      "3173/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5073\n",
      "3174/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4907\n",
      "3175/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4923\n",
      "3176/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4992\n",
      "3177/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5050\n",
      "3178/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5009\n",
      "3179/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4915\n",
      "3180/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.4951\n",
      "3181/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4947\n",
      "3182/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4947\n",
      "3183/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5074\n",
      "3184/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4960\n",
      "3185/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5008\n",
      "3186/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4989\n",
      "3187/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5267\n",
      "3188/15000:\n",
      "Training Loss: 0.5487 Validation Loss: 0.5457\n",
      "3189/15000:\n",
      "Training Loss: 0.5454 Validation Loss: 0.6011\n",
      "3190/15000:\n",
      "Training Loss: 0.5982 Validation Loss: 0.4971\n",
      "3191/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5057\n",
      "3192/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.5158\n",
      "3193/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5033\n",
      "3194/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.4954\n",
      "3195/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5020\n",
      "3196/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5007\n",
      "3197/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4927\n",
      "3198/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.4920\n",
      "3199/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4931\n",
      "3200/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.4920\n",
      "3201/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4934\n",
      "3202/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4921\n",
      "3203/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4978\n",
      "3204/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.4946\n",
      "3205/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4995\n",
      "3206/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5003\n",
      "3207/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5127\n",
      "3208/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4953\n",
      "3209/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4927\n",
      "3210/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.4939\n",
      "3211/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5032\n",
      "3212/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5040\n",
      "3213/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5148\n",
      "3214/15000:\n",
      "Training Loss: 0.5378 Validation Loss: 0.5347\n",
      "3215/15000:\n",
      "Training Loss: 0.5277 Validation Loss: 0.5023\n",
      "3216/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5097\n",
      "3217/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.4986\n",
      "3218/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5012\n",
      "3219/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4920\n",
      "3220/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4911\n",
      "3221/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.4932\n",
      "3222/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5006\n",
      "3223/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.4952\n",
      "3224/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5026\n",
      "3225/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4916\n",
      "3226/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4971\n",
      "3227/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4923\n",
      "3228/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5043\n",
      "3229/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5102\n",
      "3230/15000:\n",
      "Training Loss: 0.5206 Validation Loss: 0.4954\n",
      "3231/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5047\n",
      "3232/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4975\n",
      "3233/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5002\n",
      "3234/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5514\n",
      "3235/15000:\n",
      "Training Loss: 0.5544 Validation Loss: 0.5185\n",
      "3236/15000:\n",
      "Training Loss: 0.5376 Validation Loss: 0.5223\n",
      "3237/15000:\n",
      "Training Loss: 0.5433 Validation Loss: 0.5279\n",
      "3238/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5026\n",
      "3239/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.4955\n",
      "3240/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4933\n",
      "3241/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.4923\n",
      "3242/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.4934\n",
      "3243/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4955\n",
      "3244/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4931\n",
      "3245/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4953\n",
      "3246/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.4941\n",
      "3247/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5063\n",
      "3248/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5041\n",
      "3249/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4951\n",
      "3250/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.4958\n",
      "3251/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4940\n",
      "3252/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5022\n",
      "3253/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4993\n",
      "3254/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4986\n",
      "3255/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4984\n",
      "3256/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5247\n",
      "3257/15000:\n",
      "Training Loss: 0.5227 Validation Loss: 0.5169\n",
      "3258/15000:\n",
      "Training Loss: 0.5286 Validation Loss: 0.5132\n",
      "3259/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5449\n",
      "3260/15000:\n",
      "Training Loss: 0.5239 Validation Loss: 0.4961\n",
      "3261/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.4993\n",
      "3262/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5002\n",
      "3263/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4931\n",
      "3264/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.4971\n",
      "3265/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4984\n",
      "3266/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4962\n",
      "3267/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.4935\n",
      "3268/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4956\n",
      "3269/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5011\n",
      "3270/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5194\n",
      "3271/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5372\n",
      "3272/15000:\n",
      "Training Loss: 0.5214 Validation Loss: 0.5121\n",
      "3273/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5002\n",
      "3274/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.4953\n",
      "3275/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5077\n",
      "3276/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5012\n",
      "3277/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5017\n",
      "3278/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4973\n",
      "3279/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4960\n",
      "3280/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.4953\n",
      "3281/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4986\n",
      "3282/15000:\n",
      "Training Loss: 0.5255 Validation Loss: 0.5126\n",
      "3283/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5114\n",
      "3284/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5040\n",
      "3285/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5082\n",
      "3286/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5093\n",
      "3287/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.4948\n",
      "3288/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5058\n",
      "3289/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5088\n",
      "3290/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5170\n",
      "3291/15000:\n",
      "Training Loss: 0.5353 Validation Loss: 0.5093\n",
      "3292/15000:\n",
      "Training Loss: 0.5238 Validation Loss: 0.5291\n",
      "3293/15000:\n",
      "Training Loss: 0.5549 Validation Loss: 0.5176\n",
      "3294/15000:\n",
      "Training Loss: 0.5432 Validation Loss: 0.6305\n",
      "3295/15000:\n",
      "Training Loss: 0.6589 Validation Loss: 0.5184\n",
      "3296/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5150\n",
      "3297/15000:\n",
      "Training Loss: 0.5390 Validation Loss: 0.5017\n",
      "3298/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5043\n",
      "3299/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5031\n",
      "3300/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5036\n",
      "3301/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.4959\n",
      "3302/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4990\n",
      "3303/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4941\n",
      "3304/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4943\n",
      "3305/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4966\n",
      "3306/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5012\n",
      "3307/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.4979\n",
      "3308/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5052\n",
      "3309/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5066\n",
      "3310/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.4984\n",
      "3311/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5066\n",
      "3312/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5154\n",
      "3313/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5100\n",
      "3314/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.4958\n",
      "3315/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4970\n",
      "3316/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5020\n",
      "3317/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5082\n",
      "3318/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5106\n",
      "3319/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.4986\n",
      "3320/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5050\n",
      "3321/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5055\n",
      "3322/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5034\n",
      "3323/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5053\n",
      "3324/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5393\n",
      "3325/15000:\n",
      "Training Loss: 0.5259 Validation Loss: 0.5332\n",
      "3326/15000:\n",
      "Training Loss: 0.5525 Validation Loss: 0.5179\n",
      "3327/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.4954\n",
      "3328/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5002\n",
      "3329/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5024\n",
      "3330/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5027\n",
      "3331/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4979\n",
      "3332/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4996\n",
      "3333/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5027\n",
      "3334/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4949\n",
      "3335/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4981\n",
      "3336/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5175\n",
      "3337/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.4950\n",
      "3338/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5087\n",
      "3339/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5092\n",
      "3340/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5095\n",
      "3341/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5812\n",
      "3342/15000:\n",
      "Training Loss: 0.5555 Validation Loss: 0.4993\n",
      "3343/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.4976\n",
      "3344/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5027\n",
      "3345/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5011\n",
      "3346/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5018\n",
      "3347/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.4988\n",
      "3348/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.4932\n",
      "3349/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5005\n",
      "3350/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5061\n",
      "3351/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5086\n",
      "3352/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5017\n",
      "3353/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5126\n",
      "3354/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5116\n",
      "3355/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5069\n",
      "3356/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.4978\n",
      "3357/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4964\n",
      "3358/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5029\n",
      "3359/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.4961\n",
      "3360/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4935\n",
      "3361/15000:\n",
      "Training Loss: 0.5176 Validation Loss: 0.4987\n",
      "3362/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4924\n",
      "3363/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4991\n",
      "3364/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5061\n",
      "3365/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.4920\n",
      "3366/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.4976\n",
      "3367/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4996\n",
      "3368/15000:\n",
      "Training Loss: 0.5155 Validation Loss: 0.5017\n",
      "3369/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.4933\n",
      "3370/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.4903\n",
      "3371/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.4929\n",
      "3372/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4923\n",
      "3373/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4933\n",
      "3374/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4929\n",
      "3375/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4910\n",
      "3376/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5002\n",
      "3377/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5019\n",
      "3378/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.4999\n",
      "3379/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4998\n",
      "3380/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5058\n",
      "3381/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5618\n",
      "3382/15000:\n",
      "Training Loss: 0.5584 Validation Loss: 0.5535\n",
      "3383/15000:\n",
      "Training Loss: 0.5603 Validation Loss: 0.5557\n",
      "3384/15000:\n",
      "Training Loss: 0.5356 Validation Loss: 0.5479\n",
      "3385/15000:\n",
      "Training Loss: 0.5874 Validation Loss: 0.5545\n",
      "3386/15000:\n",
      "Training Loss: 0.5466 Validation Loss: 0.5615\n",
      "3387/15000:\n",
      "Training Loss: 0.5820 Validation Loss: 0.5160\n",
      "3388/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5038\n",
      "3389/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5158\n",
      "3390/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5042\n",
      "3391/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5037\n",
      "3392/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5022\n",
      "3393/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5011\n",
      "3394/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4981\n",
      "3395/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4990\n",
      "3396/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5033\n",
      "3397/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.4958\n",
      "3398/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.4989\n",
      "3399/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.4980\n",
      "3400/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5067\n",
      "3401/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5019\n",
      "3402/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5042\n",
      "3403/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5197\n",
      "3404/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5383\n",
      "3405/15000:\n",
      "Training Loss: 0.5353 Validation Loss: 0.5035\n",
      "3406/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5072\n",
      "3407/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5011\n",
      "3408/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5082\n",
      "3409/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5034\n",
      "3410/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5140\n",
      "3411/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5042\n",
      "3412/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5000\n",
      "3413/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5011\n",
      "3414/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5055\n",
      "3415/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5172\n",
      "3416/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5137\n",
      "3417/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5064\n",
      "3418/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5059\n",
      "3419/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5065\n",
      "3420/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5059\n",
      "3421/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5046\n",
      "3422/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5043\n",
      "3423/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5020\n",
      "3424/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5034\n",
      "3425/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.4988\n",
      "3426/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5029\n",
      "3427/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5069\n",
      "3428/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4948\n",
      "3429/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5027\n",
      "3430/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5100\n",
      "3431/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5191\n",
      "3432/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4975\n",
      "3433/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4960\n",
      "3434/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.4890\n",
      "3435/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4912\n",
      "3436/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.4934\n",
      "3437/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5062\n",
      "3438/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5111\n",
      "3439/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5055\n",
      "3440/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4983\n",
      "3441/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4948\n",
      "3442/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4992\n",
      "3443/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.4957\n",
      "3444/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4927\n",
      "3445/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4914\n",
      "3446/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4922\n",
      "3447/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.4966\n",
      "3448/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5093\n",
      "3449/15000:\n",
      "Training Loss: 0.5249 Validation Loss: 0.5078\n",
      "3450/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5095\n",
      "3451/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5162\n",
      "3452/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5160\n",
      "3453/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5209\n",
      "3454/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5171\n",
      "3455/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5108\n",
      "3456/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5005\n",
      "3457/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5095\n",
      "3458/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5028\n",
      "3459/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5005\n",
      "3460/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5125\n",
      "3461/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5193\n",
      "3462/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4938\n",
      "3463/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4934\n",
      "3464/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4940\n",
      "3465/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5008\n",
      "3466/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.4943\n",
      "3467/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5006\n",
      "3468/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5070\n",
      "3469/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4992\n",
      "3470/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.4965\n",
      "3471/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5075\n",
      "3472/15000:\n",
      "Training Loss: 0.5216 Validation Loss: 0.5047\n",
      "3473/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5062\n",
      "3474/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5274\n",
      "3475/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5090\n",
      "3476/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5179\n",
      "3477/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5173\n",
      "3478/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5024\n",
      "3479/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5151\n",
      "3480/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.4976\n",
      "3481/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5001\n",
      "3482/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5060\n",
      "3483/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.4997\n",
      "3484/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5130\n",
      "3485/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5159\n",
      "3486/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5111\n",
      "3487/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5037\n",
      "3488/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5045\n",
      "3489/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5122\n",
      "3490/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5407\n",
      "3491/15000:\n",
      "Training Loss: 0.5373 Validation Loss: 0.5836\n",
      "3492/15000:\n",
      "Training Loss: 0.6149 Validation Loss: 0.4989\n",
      "3493/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.4963\n",
      "3494/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4992\n",
      "3495/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4924\n",
      "3496/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4915\n",
      "3497/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4959\n",
      "3498/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.4937\n",
      "3499/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4935\n",
      "3500/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5015\n",
      "3501/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5016\n",
      "3502/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5043\n",
      "3503/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5021\n",
      "3504/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4946\n",
      "3505/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4984\n",
      "3506/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.4978\n",
      "3507/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5099\n",
      "3508/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5076\n",
      "3509/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5224\n",
      "3510/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5259\n",
      "3511/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5186\n",
      "3512/15000:\n",
      "Training Loss: 0.5242 Validation Loss: 0.5035\n",
      "3513/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5138\n",
      "3514/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5038\n",
      "3515/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5080\n",
      "3516/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5142\n",
      "3517/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5110\n",
      "3518/15000:\n",
      "Training Loss: 0.5214 Validation Loss: 0.5005\n",
      "3519/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5020\n",
      "3520/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5146\n",
      "3521/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5051\n",
      "3522/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.5048\n",
      "3523/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.4998\n",
      "3524/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5017\n",
      "3525/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4968\n",
      "3526/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5239\n",
      "3527/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5314\n",
      "3528/15000:\n",
      "Training Loss: 0.5299 Validation Loss: 0.5012\n",
      "3529/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.4952\n",
      "3530/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.4969\n",
      "3531/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4978\n",
      "3532/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5076\n",
      "3533/15000:\n",
      "Training Loss: 0.5206 Validation Loss: 0.5032\n",
      "3534/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5085\n",
      "3535/15000:\n",
      "Training Loss: 0.5342 Validation Loss: 0.5069\n",
      "3536/15000:\n",
      "Training Loss: 0.5267 Validation Loss: 0.5131\n",
      "3537/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5081\n",
      "3538/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5338\n",
      "3539/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.5053\n",
      "3540/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5080\n",
      "3541/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4973\n",
      "3542/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5068\n",
      "3543/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5048\n",
      "3544/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.5125\n",
      "3545/15000:\n",
      "Training Loss: 0.5285 Validation Loss: 0.5034\n",
      "3546/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5046\n",
      "3547/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5233\n",
      "3548/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.4973\n",
      "3549/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5042\n",
      "3550/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.4962\n",
      "3551/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5030\n",
      "3552/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5353\n",
      "3553/15000:\n",
      "Training Loss: 0.5363 Validation Loss: 0.5202\n",
      "3554/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5006\n",
      "3555/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4975\n",
      "3556/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5054\n",
      "3557/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5053\n",
      "3558/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5176\n",
      "3559/15000:\n",
      "Training Loss: 0.5462 Validation Loss: 0.5324\n",
      "3560/15000:\n",
      "Training Loss: 0.5253 Validation Loss: 0.5256\n",
      "3561/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.5119\n",
      "3562/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5060\n",
      "3563/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5013\n",
      "3564/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5023\n",
      "3565/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5124\n",
      "3566/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5279\n",
      "3567/15000:\n",
      "Training Loss: 0.5291 Validation Loss: 0.5248\n",
      "3568/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5087\n",
      "3569/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5078\n",
      "3570/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5047\n",
      "3571/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5017\n",
      "3572/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4966\n",
      "3573/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.4968\n",
      "3574/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5018\n",
      "3575/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4926\n",
      "3576/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5201\n",
      "3577/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5477\n",
      "3578/15000:\n",
      "Training Loss: 0.5417 Validation Loss: 0.5152\n",
      "3579/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5027\n",
      "3580/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5003\n",
      "3581/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5132\n",
      "3582/15000:\n",
      "Training Loss: 0.5214 Validation Loss: 0.4980\n",
      "3583/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5087\n",
      "3584/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4986\n",
      "3585/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.4964\n",
      "3586/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4966\n",
      "3587/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5034\n",
      "3588/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4948\n",
      "3589/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4989\n",
      "3590/15000:\n",
      "Training Loss: 0.5247 Validation Loss: 0.5073\n",
      "3591/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5019\n",
      "3592/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.4957\n",
      "3593/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4925\n",
      "3594/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4933\n",
      "3595/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.4926\n",
      "3596/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4988\n",
      "3597/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4937\n",
      "3598/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4948\n",
      "3599/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.4911\n",
      "3600/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.4957\n",
      "3601/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4966\n",
      "3602/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4926\n",
      "3603/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.4996\n",
      "3604/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4949\n",
      "3605/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5034\n",
      "3606/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5146\n",
      "3607/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5386\n",
      "3608/15000:\n",
      "Training Loss: 0.5381 Validation Loss: 0.5457\n",
      "3609/15000:\n",
      "Training Loss: 0.5456 Validation Loss: 0.5656\n",
      "3610/15000:\n",
      "Training Loss: 0.5901 Validation Loss: 0.5123\n",
      "3611/15000:\n",
      "Training Loss: 0.5262 Validation Loss: 0.4956\n",
      "3612/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4962\n",
      "3613/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.4987\n",
      "3614/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4920\n",
      "3615/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5061\n",
      "3616/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5070\n",
      "3617/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4999\n",
      "3618/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4943\n",
      "3619/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5053\n",
      "3620/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4997\n",
      "3621/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4971\n",
      "3622/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4966\n",
      "3623/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5102\n",
      "3624/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5134\n",
      "3625/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.5085\n",
      "3626/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5044\n",
      "3627/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5004\n",
      "3628/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5186\n",
      "3629/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5295\n",
      "3630/15000:\n",
      "Training Loss: 0.5367 Validation Loss: 0.5038\n",
      "3631/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.4961\n",
      "3632/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.4959\n",
      "3633/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4959\n",
      "3634/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.4970\n",
      "3635/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5092\n",
      "3636/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5011\n",
      "3637/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4981\n",
      "3638/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5025\n",
      "3639/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5012\n",
      "3640/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4924\n",
      "3641/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4932\n",
      "3642/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5008\n",
      "3643/15000:\n",
      "Training Loss: 0.5166 Validation Loss: 0.5059\n",
      "3644/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5093\n",
      "3645/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.5031\n",
      "3646/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5026\n",
      "3647/15000:\n",
      "Training Loss: 0.5203 Validation Loss: 0.5069\n",
      "3648/15000:\n",
      "Training Loss: 0.5260 Validation Loss: 0.5181\n",
      "3649/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5093\n",
      "3650/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5010\n",
      "3651/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5071\n",
      "3652/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.4990\n",
      "3653/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4959\n",
      "3654/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5103\n",
      "3655/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5111\n",
      "3656/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5082\n",
      "3657/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5070\n",
      "3658/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5067\n",
      "3659/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5093\n",
      "3660/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5123\n",
      "3661/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.4999\n",
      "3662/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4972\n",
      "3663/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5040\n",
      "3664/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.4985\n",
      "3665/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5017\n",
      "3666/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.4952\n",
      "3667/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5034\n",
      "3668/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4978\n",
      "3669/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.4995\n",
      "3670/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5009\n",
      "3671/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5110\n",
      "3672/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5201\n",
      "3673/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5083\n",
      "3674/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4990\n",
      "3675/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5220\n",
      "3676/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.4958\n",
      "3677/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.4924\n",
      "3678/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4906\n",
      "3679/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5023\n",
      "3680/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5003\n",
      "3681/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5011\n",
      "3682/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5100\n",
      "3683/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5084\n",
      "3684/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4978\n",
      "3685/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4943\n",
      "3686/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4942\n",
      "3687/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4930\n",
      "3688/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5191\n",
      "3689/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5089\n",
      "3690/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5057\n",
      "3691/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5214\n",
      "3692/15000:\n",
      "Training Loss: 0.5331 Validation Loss: 0.5262\n",
      "3693/15000:\n",
      "Training Loss: 0.5385 Validation Loss: 0.5066\n",
      "3694/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4962\n",
      "3695/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.4960\n",
      "3696/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5083\n",
      "3697/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5049\n",
      "3698/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5120\n",
      "3699/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5121\n",
      "3700/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5221\n",
      "3701/15000:\n",
      "Training Loss: 0.5398 Validation Loss: 0.5086\n",
      "3702/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5011\n",
      "3703/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5085\n",
      "3704/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5059\n",
      "3705/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5028\n",
      "3706/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5047\n",
      "3707/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5039\n",
      "3708/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.5080\n",
      "3709/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5099\n",
      "3710/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5075\n",
      "3711/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.5097\n",
      "3712/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5010\n",
      "3713/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5001\n",
      "3714/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5001\n",
      "3715/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5001\n",
      "3716/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5084\n",
      "3717/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5194\n",
      "3718/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.5146\n",
      "3719/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.5201\n",
      "3720/15000:\n",
      "Training Loss: 0.5309 Validation Loss: 0.5020\n",
      "3721/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5081\n",
      "3722/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5084\n",
      "3723/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5038\n",
      "3724/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5135\n",
      "3725/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5118\n",
      "3726/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5222\n",
      "3727/15000:\n",
      "Training Loss: 0.5214 Validation Loss: 0.5268\n",
      "3728/15000:\n",
      "Training Loss: 0.5354 Validation Loss: 0.5141\n",
      "3729/15000:\n",
      "Training Loss: 0.5259 Validation Loss: 0.5061\n",
      "3730/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5105\n",
      "3731/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5099\n",
      "3732/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5046\n",
      "3733/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5031\n",
      "3734/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5046\n",
      "3735/15000:\n",
      "Training Loss: 0.5177 Validation Loss: 0.5002\n",
      "3736/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4944\n",
      "3737/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.4993\n",
      "3738/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.4937\n",
      "3739/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4951\n",
      "3740/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4973\n",
      "3741/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4982\n",
      "3742/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5011\n",
      "3743/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5009\n",
      "3744/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.4972\n",
      "3745/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5009\n",
      "3746/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5072\n",
      "3747/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5207\n",
      "3748/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5077\n",
      "3749/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5183\n",
      "3750/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5249\n",
      "3751/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5257\n",
      "3752/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5004\n",
      "3753/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5101\n",
      "3754/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5274\n",
      "3755/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.5178\n",
      "3756/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.5098\n",
      "3757/15000:\n",
      "Training Loss: 0.5271 Validation Loss: 0.4987\n",
      "3758/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.4963\n",
      "3759/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5055\n",
      "3760/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4991\n",
      "3761/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4986\n",
      "3762/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5002\n",
      "3763/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5082\n",
      "3764/15000:\n",
      "Training Loss: 0.5195 Validation Loss: 0.5066\n",
      "3765/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5023\n",
      "3766/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5088\n",
      "3767/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5072\n",
      "3768/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5097\n",
      "3769/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5012\n",
      "3770/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4957\n",
      "3771/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5034\n",
      "3772/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5068\n",
      "3773/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5035\n",
      "3774/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5018\n",
      "3775/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5003\n",
      "3776/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5097\n",
      "3777/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5017\n",
      "3778/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5029\n",
      "3779/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4897\n",
      "3780/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5042\n",
      "3781/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5023\n",
      "3782/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.4941\n",
      "3783/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.4950\n",
      "3784/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5061\n",
      "3785/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5059\n",
      "3786/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5274\n",
      "3787/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5172\n",
      "3788/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5314\n",
      "3789/15000:\n",
      "Training Loss: 0.5466 Validation Loss: 0.5110\n",
      "3790/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.5111\n",
      "3791/15000:\n",
      "Training Loss: 0.5363 Validation Loss: 0.5371\n",
      "3792/15000:\n",
      "Training Loss: 0.5389 Validation Loss: 0.6078\n",
      "3793/15000:\n",
      "Training Loss: 0.6282 Validation Loss: 0.5149\n",
      "3794/15000:\n",
      "Training Loss: 0.5506 Validation Loss: 0.5322\n",
      "3795/15000:\n",
      "Training Loss: 0.5487 Validation Loss: 0.5052\n",
      "3796/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5046\n",
      "3797/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4998\n",
      "3798/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5023\n",
      "3799/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4993\n",
      "3800/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5034\n",
      "3801/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5015\n",
      "3802/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4972\n",
      "3803/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5137\n",
      "3804/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5126\n",
      "3805/15000:\n",
      "Training Loss: 0.5243 Validation Loss: 0.5051\n",
      "3806/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4983\n",
      "3807/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5095\n",
      "3808/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5057\n",
      "3809/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5108\n",
      "3810/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5125\n",
      "3811/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5035\n",
      "3812/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5034\n",
      "3813/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5071\n",
      "3814/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5062\n",
      "3815/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5082\n",
      "3816/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4984\n",
      "3817/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5029\n",
      "3818/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4985\n",
      "3819/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4942\n",
      "3820/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5117\n",
      "3821/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5155\n",
      "3822/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5219\n",
      "3823/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5238\n",
      "3824/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5055\n",
      "3825/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5019\n",
      "3826/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5010\n",
      "3827/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.4999\n",
      "3828/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.4969\n",
      "3829/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5058\n",
      "3830/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5009\n",
      "3831/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5068\n",
      "3832/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5015\n",
      "3833/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5069\n",
      "3834/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4992\n",
      "3835/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5071\n",
      "3836/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5336\n",
      "3837/15000:\n",
      "Training Loss: 0.5287 Validation Loss: 0.5210\n",
      "3838/15000:\n",
      "Training Loss: 0.5309 Validation Loss: 0.5258\n",
      "3839/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5234\n",
      "3840/15000:\n",
      "Training Loss: 0.5284 Validation Loss: 0.5137\n",
      "3841/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5075\n",
      "3842/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4977\n",
      "3843/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5111\n",
      "3844/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5072\n",
      "3845/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5007\n",
      "3846/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4993\n",
      "3847/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5092\n",
      "3848/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5130\n",
      "3849/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5161\n",
      "3850/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.4943\n",
      "3851/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4984\n",
      "3852/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5044\n",
      "3853/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.5095\n",
      "3854/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5105\n",
      "3855/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5113\n",
      "3856/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4943\n",
      "3857/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4985\n",
      "3858/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5034\n",
      "3859/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5100\n",
      "3860/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5098\n",
      "3861/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5217\n",
      "3862/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5044\n",
      "3863/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5016\n",
      "3864/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4984\n",
      "3865/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.4934\n",
      "3866/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4917\n",
      "3867/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5008\n",
      "3868/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5084\n",
      "3869/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5172\n",
      "3870/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5177\n",
      "3871/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5014\n",
      "3872/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5022\n",
      "3873/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5010\n",
      "3874/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5309\n",
      "3875/15000:\n",
      "Training Loss: 0.5505 Validation Loss: 0.5087\n",
      "3876/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5057\n",
      "3877/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5006\n",
      "3878/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.4961\n",
      "3879/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4954\n",
      "3880/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4994\n",
      "3881/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.4953\n",
      "3882/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4975\n",
      "3883/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5019\n",
      "3884/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5009\n",
      "3885/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5094\n",
      "3886/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5352\n",
      "3887/15000:\n",
      "Training Loss: 0.5535 Validation Loss: 0.5383\n",
      "3888/15000:\n",
      "Training Loss: 0.5243 Validation Loss: 0.5426\n",
      "3889/15000:\n",
      "Training Loss: 0.5618 Validation Loss: 0.5264\n",
      "3890/15000:\n",
      "Training Loss: 0.5406 Validation Loss: 0.6142\n",
      "3891/15000:\n",
      "Training Loss: 0.6230 Validation Loss: 0.5171\n",
      "3892/15000:\n",
      "Training Loss: 0.5297 Validation Loss: 0.5062\n",
      "3893/15000:\n",
      "Training Loss: 0.5156 Validation Loss: 0.5092\n",
      "3894/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.5057\n",
      "3895/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5115\n",
      "3896/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5105\n",
      "3897/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5134\n",
      "3898/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5156\n",
      "3899/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5084\n",
      "3900/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5080\n",
      "3901/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5121\n",
      "3902/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5039\n",
      "3903/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4983\n",
      "3904/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.5048\n",
      "3905/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5015\n",
      "3906/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5040\n",
      "3907/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.4950\n",
      "3908/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4989\n",
      "3909/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5037\n",
      "3910/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5055\n",
      "3911/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5019\n",
      "3912/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4959\n",
      "3913/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4958\n",
      "3914/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5045\n",
      "3915/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.4930\n",
      "3916/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.4925\n",
      "3917/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4947\n",
      "3918/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5038\n",
      "3919/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4963\n",
      "3920/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5028\n",
      "3921/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.4970\n",
      "3922/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5030\n",
      "3923/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.4953\n",
      "3924/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5116\n",
      "3925/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5110\n",
      "3926/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5015\n",
      "3927/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4986\n",
      "3928/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4966\n",
      "3929/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4991\n",
      "3930/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5071\n",
      "3931/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5008\n",
      "3932/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.5052\n",
      "3933/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4963\n",
      "3934/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.4955\n",
      "3935/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4977\n",
      "3936/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.4958\n",
      "3937/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4967\n",
      "3938/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5082\n",
      "3939/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5057\n",
      "3940/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5045\n",
      "3941/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5090\n",
      "3942/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5235\n",
      "3943/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5210\n",
      "3944/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5030\n",
      "3945/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5182\n",
      "3946/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5196\n",
      "3947/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5271\n",
      "3948/15000:\n",
      "Training Loss: 0.5365 Validation Loss: 0.5661\n",
      "3949/15000:\n",
      "Training Loss: 0.5921 Validation Loss: 0.5126\n",
      "3950/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5014\n",
      "3951/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5038\n",
      "3952/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4969\n",
      "3953/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5005\n",
      "3954/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.4974\n",
      "3955/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4961\n",
      "3956/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4982\n",
      "3957/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.4993\n",
      "3958/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5002\n",
      "3959/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5059\n",
      "3960/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.4925\n",
      "3961/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.4948\n",
      "3962/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.4940\n",
      "3963/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.4983\n",
      "3964/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4908\n",
      "3965/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5077\n",
      "3966/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.4963\n",
      "3967/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4927\n",
      "3968/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4943\n",
      "3969/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4970\n",
      "3970/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5235\n",
      "3971/15000:\n",
      "Training Loss: 0.5179 Validation Loss: 0.5092\n",
      "3972/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.4965\n",
      "3973/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4997\n",
      "3974/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5042\n",
      "3975/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5041\n",
      "3976/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.4985\n",
      "3977/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.4960\n",
      "3978/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4949\n",
      "3979/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.4943\n",
      "3980/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.4914\n",
      "3981/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.4895\n",
      "3982/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5018\n",
      "3983/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4969\n",
      "3984/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4993\n",
      "3985/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5042\n",
      "3986/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4999\n",
      "3987/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5114\n",
      "3988/15000:\n",
      "Training Loss: 0.5233 Validation Loss: 0.5004\n",
      "3989/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5130\n",
      "3990/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.4967\n",
      "3991/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5034\n",
      "3992/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.4976\n",
      "3993/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.4934\n",
      "3994/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.4944\n",
      "3995/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.4986\n",
      "3996/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4983\n",
      "3997/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4932\n",
      "3998/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.4996\n",
      "3999/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4935\n",
      "4000/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4988\n",
      "4001/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5021\n",
      "4002/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5007\n",
      "4003/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5167\n",
      "4004/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.5098\n",
      "4005/15000:\n",
      "Training Loss: 0.5187 Validation Loss: 0.4989\n",
      "4006/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5099\n",
      "4007/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4972\n",
      "4008/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.4976\n",
      "4009/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.4961\n",
      "4010/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.4881\n",
      "4011/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4988\n",
      "4012/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.4988\n",
      "4013/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4967\n",
      "4014/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5266\n",
      "4015/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.4954\n",
      "4016/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.4950\n",
      "4017/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.4976\n",
      "4018/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.4972\n",
      "4019/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5019\n",
      "4020/15000:\n",
      "Training Loss: 0.5179 Validation Loss: 0.5012\n",
      "4021/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5040\n",
      "4022/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5115\n",
      "4023/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.5148\n",
      "4024/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5146\n",
      "4025/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5194\n",
      "4026/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5017\n",
      "4027/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5102\n",
      "4028/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5050\n",
      "4029/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5094\n",
      "4030/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5053\n",
      "4031/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5184\n",
      "4032/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5067\n",
      "4033/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5060\n",
      "4034/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5023\n",
      "4035/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5043\n",
      "4036/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5001\n",
      "4037/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4966\n",
      "4038/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5040\n",
      "4039/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5103\n",
      "4040/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5023\n",
      "4041/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5024\n",
      "4042/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5051\n",
      "4043/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5172\n",
      "4044/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5380\n",
      "4045/15000:\n",
      "Training Loss: 0.5386 Validation Loss: 0.5668\n",
      "4046/15000:\n",
      "Training Loss: 0.5896 Validation Loss: 0.5048\n",
      "4047/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.4992\n",
      "4048/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5135\n",
      "4049/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5001\n",
      "4050/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.4963\n",
      "4051/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5034\n",
      "4052/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5040\n",
      "4053/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5071\n",
      "4054/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5107\n",
      "4055/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5125\n",
      "4056/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5048\n",
      "4057/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5112\n",
      "4058/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5056\n",
      "4059/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.4960\n",
      "4060/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5000\n",
      "4061/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.4996\n",
      "4062/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5001\n",
      "4063/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4976\n",
      "4064/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.4946\n",
      "4065/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4956\n",
      "4066/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4940\n",
      "4067/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4981\n",
      "4068/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5060\n",
      "4069/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5028\n",
      "4070/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5010\n",
      "4071/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.4966\n",
      "4072/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5061\n",
      "4073/15000:\n",
      "Training Loss: 0.4748 Validation Loss: 0.5024\n",
      "4074/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.4957\n",
      "4075/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5033\n",
      "4076/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.4964\n",
      "4077/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5016\n",
      "4078/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4991\n",
      "4079/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5010\n",
      "4080/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5089\n",
      "4081/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5070\n",
      "4082/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5049\n",
      "4083/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5129\n",
      "4084/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5064\n",
      "4085/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5102\n",
      "4086/15000:\n",
      "Training Loss: 0.5222 Validation Loss: 0.5124\n",
      "4087/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5181\n",
      "4088/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.4955\n",
      "4089/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5076\n",
      "4090/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5107\n",
      "4091/15000:\n",
      "Training Loss: 0.5295 Validation Loss: 0.5002\n",
      "4092/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4983\n",
      "4093/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4963\n",
      "4094/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4935\n",
      "4095/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4955\n",
      "4096/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.4958\n",
      "4097/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5019\n",
      "4098/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5127\n",
      "4099/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.4985\n",
      "4100/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.4982\n",
      "4101/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5009\n",
      "4102/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5052\n",
      "4103/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.4983\n",
      "4104/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5068\n",
      "4105/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5083\n",
      "4106/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4930\n",
      "4107/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.4972\n",
      "4108/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4969\n",
      "4109/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4988\n",
      "4110/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5044\n",
      "4111/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5065\n",
      "4112/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5082\n",
      "4113/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.4999\n",
      "4114/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5071\n",
      "4115/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4971\n",
      "4116/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4992\n",
      "4117/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4984\n",
      "4118/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5005\n",
      "4119/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4996\n",
      "4120/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5001\n",
      "4121/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5070\n",
      "4122/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5191\n",
      "4123/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5073\n",
      "4124/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5059\n",
      "4125/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5042\n",
      "4126/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5028\n",
      "4127/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5156\n",
      "4128/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5025\n",
      "4129/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5089\n",
      "4130/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4905\n",
      "4131/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.4921\n",
      "4132/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5035\n",
      "4133/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5146\n",
      "4134/15000:\n",
      "Training Loss: 0.5285 Validation Loss: 0.5558\n",
      "4135/15000:\n",
      "Training Loss: 0.5305 Validation Loss: 0.5844\n",
      "4136/15000:\n",
      "Training Loss: 0.5711 Validation Loss: 0.5486\n",
      "4137/15000:\n",
      "Training Loss: 0.5324 Validation Loss: 0.6080\n",
      "4138/15000:\n",
      "Training Loss: 0.6343 Validation Loss: 0.5603\n",
      "4139/15000:\n",
      "Training Loss: 0.5646 Validation Loss: 0.5300\n",
      "4140/15000:\n",
      "Training Loss: 0.5572 Validation Loss: 0.5059\n",
      "4141/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5048\n",
      "4142/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5035\n",
      "4143/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5011\n",
      "4144/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4972\n",
      "4145/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4985\n",
      "4146/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5111\n",
      "4147/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4986\n",
      "4148/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5032\n",
      "4149/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5031\n",
      "4150/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5016\n",
      "4151/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5012\n",
      "4152/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4975\n",
      "4153/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5010\n",
      "4154/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5040\n",
      "4155/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5107\n",
      "4156/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5011\n",
      "4157/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4985\n",
      "4158/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5038\n",
      "4159/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5011\n",
      "4160/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4950\n",
      "4161/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4946\n",
      "4162/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4969\n",
      "4163/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5031\n",
      "4164/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4989\n",
      "4165/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5021\n",
      "4166/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5132\n",
      "4167/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5150\n",
      "4168/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5101\n",
      "4169/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5163\n",
      "4170/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5046\n",
      "4171/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.4993\n",
      "4172/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.4931\n",
      "4173/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4934\n",
      "4174/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4993\n",
      "4175/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5067\n",
      "4176/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5040\n",
      "4177/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5076\n",
      "4178/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5023\n",
      "4179/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5103\n",
      "4180/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5246\n",
      "4181/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5099\n",
      "4182/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5181\n",
      "4183/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5215\n",
      "4184/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.5099\n",
      "4185/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4954\n",
      "4186/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4936\n",
      "4187/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.4929\n",
      "4188/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.4938\n",
      "4189/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4920\n",
      "4190/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4928\n",
      "4191/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4928\n",
      "4192/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4997\n",
      "4193/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4955\n",
      "4194/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5026\n",
      "4195/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5111\n",
      "4196/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4992\n",
      "4197/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4973\n",
      "4198/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5358\n",
      "4199/15000:\n",
      "Training Loss: 0.5254 Validation Loss: 0.4998\n",
      "4200/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.4996\n",
      "4201/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5039\n",
      "4202/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5072\n",
      "4203/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5070\n",
      "4204/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5077\n",
      "4205/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.4962\n",
      "4206/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.4952\n",
      "4207/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.4964\n",
      "4208/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4915\n",
      "4209/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.4958\n",
      "4210/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4915\n",
      "4211/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4935\n",
      "4212/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.4977\n",
      "4213/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5020\n",
      "4214/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.4989\n",
      "4215/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.4991\n",
      "4216/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4970\n",
      "4217/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5053\n",
      "4218/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4951\n",
      "4219/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5070\n",
      "4220/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5131\n",
      "4221/15000:\n",
      "Training Loss: 0.5271 Validation Loss: 0.5089\n",
      "4222/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.4969\n",
      "4223/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5109\n",
      "4224/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5023\n",
      "4225/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5161\n",
      "4226/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5078\n",
      "4227/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5147\n",
      "4228/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5068\n",
      "4229/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5261\n",
      "4230/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5354\n",
      "4231/15000:\n",
      "Training Loss: 0.5304 Validation Loss: 0.4955\n",
      "4232/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4919\n",
      "4233/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4922\n",
      "4234/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4954\n",
      "4235/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4946\n",
      "4236/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4935\n",
      "4237/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5006\n",
      "4238/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4958\n",
      "4239/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.4938\n",
      "4240/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4944\n",
      "4241/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5023\n",
      "4242/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5088\n",
      "4243/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5215\n",
      "4244/15000:\n",
      "Training Loss: 0.5313 Validation Loss: 0.5151\n",
      "4245/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.4967\n",
      "4246/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4955\n",
      "4247/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5024\n",
      "4248/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.4956\n",
      "4249/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4946\n",
      "4250/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.4935\n",
      "4251/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5012\n",
      "4252/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5022\n",
      "4253/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5021\n",
      "4254/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5240\n",
      "4255/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5078\n",
      "4256/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5047\n",
      "4257/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5095\n",
      "4258/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5198\n",
      "4259/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5176\n",
      "4260/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5213\n",
      "4261/15000:\n",
      "Training Loss: 0.5312 Validation Loss: 0.5129\n",
      "4262/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5122\n",
      "4263/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5312\n",
      "4264/15000:\n",
      "Training Loss: 0.5365 Validation Loss: 0.5377\n",
      "4265/15000:\n",
      "Training Loss: 0.5565 Validation Loss: 0.5289\n",
      "4266/15000:\n",
      "Training Loss: 0.5520 Validation Loss: 0.5021\n",
      "4267/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.4953\n",
      "4268/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5007\n",
      "4269/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.4961\n",
      "4270/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5022\n",
      "4271/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5009\n",
      "4272/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5001\n",
      "4273/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.4958\n",
      "4274/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.4997\n",
      "4275/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4947\n",
      "4276/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.4985\n",
      "4277/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5004\n",
      "4278/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5021\n",
      "4279/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5018\n",
      "4280/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4987\n",
      "4281/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5143\n",
      "4282/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5479\n",
      "4283/15000:\n",
      "Training Loss: 0.5262 Validation Loss: 0.5106\n",
      "4284/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5469\n",
      "4285/15000:\n",
      "Training Loss: 0.5353 Validation Loss: 0.5172\n",
      "4286/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5081\n",
      "4287/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5006\n",
      "4288/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.4980\n",
      "4289/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5001\n",
      "4290/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.4993\n",
      "4291/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5039\n",
      "4292/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4982\n",
      "4293/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.4956\n",
      "4294/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4953\n",
      "4295/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5116\n",
      "4296/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5102\n",
      "4297/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5031\n",
      "4298/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4946\n",
      "4299/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4909\n",
      "4300/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.4993\n",
      "4301/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.4896\n",
      "4302/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.4970\n",
      "4303/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4953\n",
      "4304/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4915\n",
      "4305/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.4993\n",
      "4306/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4934\n",
      "4307/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5009\n",
      "4308/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5019\n",
      "4309/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5051\n",
      "4310/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5056\n",
      "4311/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5078\n",
      "4312/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5029\n",
      "4313/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5008\n",
      "4314/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.4964\n",
      "4315/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4985\n",
      "4316/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4933\n",
      "4317/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4958\n",
      "4318/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5030\n",
      "4319/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5048\n",
      "4320/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5042\n",
      "4321/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5031\n",
      "4322/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5101\n",
      "4323/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.4950\n",
      "4324/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4932\n",
      "4325/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.4995\n",
      "4326/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5045\n",
      "4327/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4985\n",
      "4328/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5101\n",
      "4329/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5085\n",
      "4330/15000:\n",
      "Training Loss: 0.5230 Validation Loss: 0.4991\n",
      "4331/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4938\n",
      "4332/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.4975\n",
      "4333/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5065\n",
      "4334/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.4992\n",
      "4335/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5132\n",
      "4336/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5087\n",
      "4337/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5053\n",
      "4338/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5106\n",
      "4339/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5329\n",
      "4340/15000:\n",
      "Training Loss: 0.5332 Validation Loss: 0.5401\n",
      "4341/15000:\n",
      "Training Loss: 0.5586 Validation Loss: 0.5560\n",
      "4342/15000:\n",
      "Training Loss: 0.5444 Validation Loss: 0.5402\n",
      "4343/15000:\n",
      "Training Loss: 0.5735 Validation Loss: 0.5252\n",
      "4344/15000:\n",
      "Training Loss: 0.5423 Validation Loss: 0.5181\n",
      "4345/15000:\n",
      "Training Loss: 0.5214 Validation Loss: 0.5016\n",
      "4346/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.4986\n",
      "4347/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5035\n",
      "4348/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5025\n",
      "4349/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5059\n",
      "4350/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5060\n",
      "4351/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.4977\n",
      "4352/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.4969\n",
      "4353/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.4930\n",
      "4354/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.4998\n",
      "4355/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4936\n",
      "4356/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4932\n",
      "4357/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.4931\n",
      "4358/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5027\n",
      "4359/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5016\n",
      "4360/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4974\n",
      "4361/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5075\n",
      "4362/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5206\n",
      "4363/15000:\n",
      "Training Loss: 0.5243 Validation Loss: 0.5128\n",
      "4364/15000:\n",
      "Training Loss: 0.5230 Validation Loss: 0.5011\n",
      "4365/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4991\n",
      "4366/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4925\n",
      "4367/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.4997\n",
      "4368/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4933\n",
      "4369/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.4943\n",
      "4370/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5003\n",
      "4371/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5077\n",
      "4372/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5106\n",
      "4373/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5270\n",
      "4374/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5068\n",
      "4375/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5119\n",
      "4376/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5043\n",
      "4377/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5084\n",
      "4378/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5010\n",
      "4379/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4944\n",
      "4380/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4963\n",
      "4381/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.4965\n",
      "4382/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4936\n",
      "4383/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.4955\n",
      "4384/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4965\n",
      "4385/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.4903\n",
      "4386/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4911\n",
      "4387/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4882\n",
      "4388/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5003\n",
      "4389/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5157\n",
      "4390/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.5084\n",
      "4391/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5037\n",
      "4392/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5082\n",
      "4393/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.4942\n",
      "4394/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.4919\n",
      "4395/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.4926\n",
      "4396/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4972\n",
      "4397/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4943\n",
      "4398/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4967\n",
      "4399/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5038\n",
      "4400/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.4942\n",
      "4401/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5014\n",
      "4402/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5099\n",
      "4403/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4966\n",
      "4404/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4991\n",
      "4405/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.4973\n",
      "4406/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.4931\n",
      "4407/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.4903\n",
      "4408/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5014\n",
      "4409/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5075\n",
      "4410/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5094\n",
      "4411/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5094\n",
      "4412/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.4979\n",
      "4413/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5118\n",
      "4414/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5182\n",
      "4415/15000:\n",
      "Training Loss: 0.5302 Validation Loss: 0.5101\n",
      "4416/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5160\n",
      "4417/15000:\n",
      "Training Loss: 0.5397 Validation Loss: 0.5235\n",
      "4418/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.5361\n",
      "4419/15000:\n",
      "Training Loss: 0.5401 Validation Loss: 0.5398\n",
      "4420/15000:\n",
      "Training Loss: 0.5395 Validation Loss: 0.5648\n",
      "4421/15000:\n",
      "Training Loss: 0.6003 Validation Loss: 0.5148\n",
      "4422/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.4988\n",
      "4423/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5021\n",
      "4424/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4977\n",
      "4425/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.4992\n",
      "4426/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5048\n",
      "4427/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5001\n",
      "4428/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5019\n",
      "4429/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5000\n",
      "4430/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4969\n",
      "4431/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5011\n",
      "4432/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5144\n",
      "4433/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5222\n",
      "4434/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5038\n",
      "4435/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4995\n",
      "4436/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4968\n",
      "4437/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4978\n",
      "4438/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5027\n",
      "4439/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5035\n",
      "4440/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5015\n",
      "4441/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5017\n",
      "4442/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4966\n",
      "4443/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.4925\n",
      "4444/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.4955\n",
      "4445/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4999\n",
      "4446/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5115\n",
      "4447/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5083\n",
      "4448/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5001\n",
      "4449/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4929\n",
      "4450/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.4937\n",
      "4451/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4963\n",
      "4452/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.4999\n",
      "4453/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4994\n",
      "4454/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5008\n",
      "4455/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5158\n",
      "4456/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5138\n",
      "4457/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5325\n",
      "4458/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5037\n",
      "4459/15000:\n",
      "Training Loss: 0.5222 Validation Loss: 0.5272\n",
      "4460/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5073\n",
      "4461/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5050\n",
      "4462/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5074\n",
      "4463/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5126\n",
      "4464/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5066\n",
      "4465/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5029\n",
      "4466/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5004\n",
      "4467/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5103\n",
      "4468/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5260\n",
      "4469/15000:\n",
      "Training Loss: 0.5372 Validation Loss: 0.5500\n",
      "4470/15000:\n",
      "Training Loss: 0.5479 Validation Loss: 0.4956\n",
      "4471/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5011\n",
      "4472/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5067\n",
      "4473/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5063\n",
      "4474/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5029\n",
      "4475/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5041\n",
      "4476/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.4999\n",
      "4477/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5022\n",
      "4478/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5084\n",
      "4479/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5103\n",
      "4480/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5081\n",
      "4481/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5179\n",
      "4482/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5174\n",
      "4483/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5189\n",
      "4484/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5157\n",
      "4485/15000:\n",
      "Training Loss: 0.5291 Validation Loss: 0.5276\n",
      "4486/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5153\n",
      "4487/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5074\n",
      "4488/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5116\n",
      "4489/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5087\n",
      "4490/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5037\n",
      "4491/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.4985\n",
      "4492/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5034\n",
      "4493/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5141\n",
      "4494/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5084\n",
      "4495/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5189\n",
      "4496/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5168\n",
      "4497/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5028\n",
      "4498/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5056\n",
      "4499/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5039\n",
      "4500/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5086\n",
      "4501/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5176\n",
      "4502/15000:\n",
      "Training Loss: 0.5167 Validation Loss: 0.5010\n",
      "4503/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4943\n",
      "4504/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4962\n",
      "4505/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.4957\n",
      "4506/15000:\n",
      "Training Loss: 0.4624 Validation Loss: 0.4941\n",
      "4507/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.4960\n",
      "4508/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4950\n",
      "4509/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4900\n",
      "4510/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5053\n",
      "4511/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5059\n",
      "4512/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.4981\n",
      "4513/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.4923\n",
      "4514/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4995\n",
      "4515/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4992\n",
      "4516/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4961\n",
      "4517/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5013\n",
      "4518/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5268\n",
      "4519/15000:\n",
      "Training Loss: 0.5284 Validation Loss: 0.5123\n",
      "4520/15000:\n",
      "Training Loss: 0.5306 Validation Loss: 0.5111\n",
      "4521/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.4983\n",
      "4522/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5009\n",
      "4523/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5007\n",
      "4524/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5020\n",
      "4525/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5042\n",
      "4526/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5052\n",
      "4527/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5077\n",
      "4528/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4973\n",
      "4529/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.4999\n",
      "4530/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5004\n",
      "4531/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5059\n",
      "4532/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5058\n",
      "4533/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5020\n",
      "4534/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5002\n",
      "4535/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4974\n",
      "4536/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4943\n",
      "4537/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4941\n",
      "4538/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.4955\n",
      "4539/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.4943\n",
      "4540/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.4967\n",
      "4541/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5065\n",
      "4542/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5122\n",
      "4543/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5325\n",
      "4544/15000:\n",
      "Training Loss: 0.5216 Validation Loss: 0.5095\n",
      "4545/15000:\n",
      "Training Loss: 0.5308 Validation Loss: 0.5102\n",
      "4546/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.4992\n",
      "4547/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5031\n",
      "4548/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4973\n",
      "4549/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.4959\n",
      "4550/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4947\n",
      "4551/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4957\n",
      "4552/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.4919\n",
      "4553/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4917\n",
      "4554/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.4983\n",
      "4555/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4934\n",
      "4556/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4926\n",
      "4557/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4977\n",
      "4558/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4960\n",
      "4559/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5049\n",
      "4560/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5154\n",
      "4561/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5117\n",
      "4562/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5049\n",
      "4563/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5043\n",
      "4564/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4984\n",
      "4565/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.4982\n",
      "4566/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.4955\n",
      "4567/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5046\n",
      "4568/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5159\n",
      "4569/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5023\n",
      "4570/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5292\n",
      "4571/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.4946\n",
      "4572/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.4899\n",
      "4573/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4918\n",
      "4574/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.4934\n",
      "4575/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5016\n",
      "4576/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.4933\n",
      "4577/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4946\n",
      "4578/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.4974\n",
      "4579/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5239\n",
      "4580/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5098\n",
      "4581/15000:\n",
      "Training Loss: 0.5222 Validation Loss: 0.5260\n",
      "4582/15000:\n",
      "Training Loss: 0.5359 Validation Loss: 0.5084\n",
      "4583/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5079\n",
      "4584/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5060\n",
      "4585/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5203\n",
      "4586/15000:\n",
      "Training Loss: 0.5310 Validation Loss: 0.5002\n",
      "4587/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5017\n",
      "4588/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4934\n",
      "4589/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.4989\n",
      "4590/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5142\n",
      "4591/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5256\n",
      "4592/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5555\n",
      "4593/15000:\n",
      "Training Loss: 0.5573 Validation Loss: 0.5176\n",
      "4594/15000:\n",
      "Training Loss: 0.5344 Validation Loss: 0.5006\n",
      "4595/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5026\n",
      "4596/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4962\n",
      "4597/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4948\n",
      "4598/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.4931\n",
      "4599/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4977\n",
      "4600/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5003\n",
      "4601/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4992\n",
      "4602/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5000\n",
      "4603/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4944\n",
      "4604/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.4944\n",
      "4605/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.4960\n",
      "4606/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4946\n",
      "4607/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4940\n",
      "4608/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4973\n",
      "4609/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5046\n",
      "4610/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5009\n",
      "4611/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5192\n",
      "4612/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5153\n",
      "4613/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.4918\n",
      "4614/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4946\n",
      "4615/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.4976\n",
      "4616/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.4934\n",
      "4617/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5016\n",
      "4618/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5120\n",
      "4619/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4995\n",
      "4620/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5001\n",
      "4621/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.4983\n",
      "4622/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4962\n",
      "4623/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4979\n",
      "4624/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4980\n",
      "4625/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5049\n",
      "4626/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5029\n",
      "4627/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5015\n",
      "4628/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4979\n",
      "4629/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4997\n",
      "4630/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5020\n",
      "4631/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5070\n",
      "4632/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5249\n",
      "4633/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5170\n",
      "4634/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5295\n",
      "4635/15000:\n",
      "Training Loss: 0.5298 Validation Loss: 0.5040\n",
      "4636/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5042\n",
      "4637/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5052\n",
      "4638/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5110\n",
      "4639/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5027\n",
      "4640/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5085\n",
      "4641/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5110\n",
      "4642/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5206\n",
      "4643/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5003\n",
      "4644/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.4955\n",
      "4645/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5030\n",
      "4646/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5010\n",
      "4647/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4927\n",
      "4648/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.4926\n",
      "4649/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.4975\n",
      "4650/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4992\n",
      "4651/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5058\n",
      "4652/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5031\n",
      "4653/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5006\n",
      "4654/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.4989\n",
      "4655/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4962\n",
      "4656/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.4903\n",
      "4657/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.5037\n",
      "4658/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5016\n",
      "4659/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5049\n",
      "4660/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5039\n",
      "4661/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.4973\n",
      "4662/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5016\n",
      "4663/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4957\n",
      "4664/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5026\n",
      "4665/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4957\n",
      "4666/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5032\n",
      "4667/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5288\n",
      "4668/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.4985\n",
      "4669/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.4934\n",
      "4670/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.4922\n",
      "4671/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4904\n",
      "4672/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5060\n",
      "4673/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5056\n",
      "4674/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.4947\n",
      "4675/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4895\n",
      "4676/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.4873\n",
      "4677/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4910\n",
      "4678/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4947\n",
      "4679/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.4951\n",
      "4680/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4964\n",
      "4681/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.4893\n",
      "4682/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4941\n",
      "4683/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4903\n",
      "4684/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5095\n",
      "4685/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5053\n",
      "4686/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4970\n",
      "4687/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4959\n",
      "4688/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4980\n",
      "4689/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4991\n",
      "4690/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5093\n",
      "4691/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4926\n",
      "4692/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5094\n",
      "4693/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5122\n",
      "4694/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5092\n",
      "4695/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5102\n",
      "4696/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.4951\n",
      "4697/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4956\n",
      "4698/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4950\n",
      "4699/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.4903\n",
      "4700/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5020\n",
      "4701/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.4986\n",
      "4702/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4969\n",
      "4703/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5076\n",
      "4704/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5274\n",
      "4705/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5741\n",
      "4706/15000:\n",
      "Training Loss: 0.5594 Validation Loss: 0.5508\n",
      "4707/15000:\n",
      "Training Loss: 0.5771 Validation Loss: 0.5268\n",
      "4708/15000:\n",
      "Training Loss: 0.5208 Validation Loss: 0.4999\n",
      "4709/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.4997\n",
      "4710/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5086\n",
      "4711/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5011\n",
      "4712/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5000\n",
      "4713/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5078\n",
      "4714/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5009\n",
      "4715/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5339\n",
      "4716/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.4953\n",
      "4717/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5023\n",
      "4718/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.4943\n",
      "4719/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5023\n",
      "4720/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.4967\n",
      "4721/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4922\n",
      "4722/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5044\n",
      "4723/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5054\n",
      "4724/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5340\n",
      "4725/15000:\n",
      "Training Loss: 0.5335 Validation Loss: 0.5155\n",
      "4726/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5055\n",
      "4727/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5021\n",
      "4728/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.4949\n",
      "4729/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4920\n",
      "4730/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.4995\n",
      "4731/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5002\n",
      "4732/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5093\n",
      "4733/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5010\n",
      "4734/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5282\n",
      "4735/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5058\n",
      "4736/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5015\n",
      "4737/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5088\n",
      "4738/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5279\n",
      "4739/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5032\n",
      "4740/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.4920\n",
      "4741/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5035\n",
      "4742/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4973\n",
      "4743/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5025\n",
      "4744/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.4967\n",
      "4745/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.4964\n",
      "4746/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4953\n",
      "4747/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.4980\n",
      "4748/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4968\n",
      "4749/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.4984\n",
      "4750/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5029\n",
      "4751/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5094\n",
      "4752/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5019\n",
      "4753/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4991\n",
      "4754/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5168\n",
      "4755/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5521\n",
      "4756/15000:\n",
      "Training Loss: 0.5290 Validation Loss: 0.5552\n",
      "4757/15000:\n",
      "Training Loss: 0.5776 Validation Loss: 0.5184\n",
      "4758/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5082\n",
      "4759/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5138\n",
      "4760/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.4999\n",
      "4761/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.5010\n",
      "4762/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5011\n",
      "4763/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4957\n",
      "4764/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4950\n",
      "4765/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.4946\n",
      "4766/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5011\n",
      "4767/15000:\n",
      "Training Loss: 0.4696 Validation Loss: 0.5029\n",
      "4768/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5094\n",
      "4769/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5084\n",
      "4770/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5059\n",
      "4771/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5123\n",
      "4772/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5214\n",
      "4773/15000:\n",
      "Training Loss: 0.5185 Validation Loss: 0.5062\n",
      "4774/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5463\n",
      "4775/15000:\n",
      "Training Loss: 0.5213 Validation Loss: 0.5383\n",
      "4776/15000:\n",
      "Training Loss: 0.5228 Validation Loss: 0.5572\n",
      "4777/15000:\n",
      "Training Loss: 0.5406 Validation Loss: 0.5156\n",
      "4778/15000:\n",
      "Training Loss: 0.5545 Validation Loss: 0.5213\n",
      "4779/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5027\n",
      "4780/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5081\n",
      "4781/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4995\n",
      "4782/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.4996\n",
      "4783/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5000\n",
      "4784/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5000\n",
      "4785/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5049\n",
      "4786/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5024\n",
      "4787/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.4984\n",
      "4788/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.4995\n",
      "4789/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4938\n",
      "4790/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.4972\n",
      "4791/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.4979\n",
      "4792/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.4963\n",
      "4793/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4998\n",
      "4794/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5028\n",
      "4795/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5006\n",
      "4796/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5151\n",
      "4797/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.4956\n",
      "4798/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.4976\n",
      "4799/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5096\n",
      "4800/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5132\n",
      "4801/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5061\n",
      "4802/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5130\n",
      "4803/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5011\n",
      "4804/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4938\n",
      "4805/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.4922\n",
      "4806/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4915\n",
      "4807/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4997\n",
      "4808/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4896\n",
      "4809/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4998\n",
      "4810/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.4992\n",
      "4811/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5056\n",
      "4812/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4969\n",
      "4813/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5066\n",
      "4814/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5070\n",
      "4815/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5258\n",
      "4816/15000:\n",
      "Training Loss: 0.5517 Validation Loss: 0.5368\n",
      "4817/15000:\n",
      "Training Loss: 0.5363 Validation Loss: 0.5177\n",
      "4818/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5037\n",
      "4819/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.4969\n",
      "4820/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5112\n",
      "4821/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5038\n",
      "4822/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5211\n",
      "4823/15000:\n",
      "Training Loss: 0.5239 Validation Loss: 0.4998\n",
      "4824/15000:\n",
      "Training Loss: 0.5291 Validation Loss: 0.5022\n",
      "4825/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5063\n",
      "4826/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5002\n",
      "4827/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4979\n",
      "4828/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.4965\n",
      "4829/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.4968\n",
      "4830/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5052\n",
      "4831/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4995\n",
      "4832/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4970\n",
      "4833/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.4981\n",
      "4834/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4939\n",
      "4835/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5041\n",
      "4836/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5110\n",
      "4837/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.4986\n",
      "4838/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4937\n",
      "4839/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.4949\n",
      "4840/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.4988\n",
      "4841/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5115\n",
      "4842/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5162\n",
      "4843/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4998\n",
      "4844/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.4980\n",
      "4845/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5028\n",
      "4846/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5031\n",
      "4847/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5274\n",
      "4848/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5144\n",
      "4849/15000:\n",
      "Training Loss: 0.5238 Validation Loss: 0.5526\n",
      "4850/15000:\n",
      "Training Loss: 0.5414 Validation Loss: 0.5467\n",
      "4851/15000:\n",
      "Training Loss: 0.5708 Validation Loss: 0.5440\n",
      "4852/15000:\n",
      "Training Loss: 0.5439 Validation Loss: 0.5035\n",
      "4853/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5131\n",
      "4854/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5007\n",
      "4855/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4983\n",
      "4856/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5006\n",
      "4857/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5038\n",
      "4858/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5033\n",
      "4859/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5071\n",
      "4860/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4973\n",
      "4861/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4988\n",
      "4862/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5035\n",
      "4863/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.4983\n",
      "4864/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.4969\n",
      "4865/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5053\n",
      "4866/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5069\n",
      "4867/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5013\n",
      "4868/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.4975\n",
      "4869/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5008\n",
      "4870/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.4969\n",
      "4871/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4984\n",
      "4872/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5179\n",
      "4873/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5432\n",
      "4874/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5385\n",
      "4875/15000:\n",
      "Training Loss: 0.5387 Validation Loss: 0.5134\n",
      "4876/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5042\n",
      "4877/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5028\n",
      "4878/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5007\n",
      "4879/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5021\n",
      "4880/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5057\n",
      "4881/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5081\n",
      "4882/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5302\n",
      "4883/15000:\n",
      "Training Loss: 0.5155 Validation Loss: 0.5029\n",
      "4884/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5030\n",
      "4885/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5027\n",
      "4886/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5022\n",
      "4887/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5062\n",
      "4888/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5350\n",
      "4889/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5179\n",
      "4890/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5256\n",
      "4891/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5036\n",
      "4892/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5030\n",
      "4893/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5213\n",
      "4894/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5209\n",
      "4895/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5022\n",
      "4896/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5064\n",
      "4897/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.4990\n",
      "4898/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4990\n",
      "4899/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5020\n",
      "4900/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5062\n",
      "4901/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.4970\n",
      "4902/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5015\n",
      "4903/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5029\n",
      "4904/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5040\n",
      "4905/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5033\n",
      "4906/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.4952\n",
      "4907/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.4987\n",
      "4908/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5016\n",
      "4909/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.4941\n",
      "4910/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4978\n",
      "4911/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.4934\n",
      "4912/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.4998\n",
      "4913/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5054\n",
      "4914/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4992\n",
      "4915/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5043\n",
      "4916/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5055\n",
      "4917/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5048\n",
      "4918/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5108\n",
      "4919/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5159\n",
      "4920/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5163\n",
      "4921/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5090\n",
      "4922/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.4993\n",
      "4923/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4966\n",
      "4924/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4946\n",
      "4925/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4957\n",
      "4926/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5055\n",
      "4927/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5036\n",
      "4928/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5247\n",
      "4929/15000:\n",
      "Training Loss: 0.5208 Validation Loss: 0.5243\n",
      "4930/15000:\n",
      "Training Loss: 0.5374 Validation Loss: 0.5182\n",
      "4931/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5097\n",
      "4932/15000:\n",
      "Training Loss: 0.5340 Validation Loss: 0.5015\n",
      "4933/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.4970\n",
      "4934/15000:\n",
      "Training Loss: 0.5182 Validation Loss: 0.5068\n",
      "4935/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4952\n",
      "4936/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5009\n",
      "4937/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.4971\n",
      "4938/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.4964\n",
      "4939/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5050\n",
      "4940/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5150\n",
      "4941/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.4980\n",
      "4942/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5087\n",
      "4943/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.4989\n",
      "4944/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.4969\n",
      "4945/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5079\n",
      "4946/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.4979\n",
      "4947/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.4985\n",
      "4948/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5010\n",
      "4949/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5219\n",
      "4950/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5514\n",
      "4951/15000:\n",
      "Training Loss: 0.5386 Validation Loss: 0.5120\n",
      "4952/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5241\n",
      "4953/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.5045\n",
      "4954/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5065\n",
      "4955/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4962\n",
      "4956/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4919\n",
      "4957/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5126\n",
      "4958/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5114\n",
      "4959/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5091\n",
      "4960/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5077\n",
      "4961/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5067\n",
      "4962/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5096\n",
      "4963/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5046\n",
      "4964/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4967\n",
      "4965/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4999\n",
      "4966/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.4963\n",
      "4967/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4967\n",
      "4968/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4979\n",
      "4969/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5033\n",
      "4970/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5082\n",
      "4971/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4934\n",
      "4972/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5046\n",
      "4973/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4961\n",
      "4974/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.4963\n",
      "4975/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.4962\n",
      "4976/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4997\n",
      "4977/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5019\n",
      "4978/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.4961\n",
      "4979/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4973\n",
      "4980/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5069\n",
      "4981/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5074\n",
      "4982/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5007\n",
      "4983/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5077\n",
      "4984/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5065\n",
      "4985/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5340\n",
      "4986/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.5181\n",
      "4987/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.4961\n",
      "4988/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5037\n",
      "4989/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5034\n",
      "4990/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5184\n",
      "4991/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5065\n",
      "4992/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4986\n",
      "4993/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.4986\n",
      "4994/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4972\n",
      "4995/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5268\n",
      "4996/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.5975\n",
      "4997/15000:\n",
      "Training Loss: 0.6100 Validation Loss: 0.5268\n",
      "4998/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5402\n",
      "4999/15000:\n",
      "Training Loss: 0.5416 Validation Loss: 0.5254\n",
      "5000/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5031\n",
      "5001/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5128\n",
      "5002/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5021\n",
      "5003/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5070\n",
      "5004/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.4977\n",
      "5005/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4950\n",
      "5006/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5017\n",
      "5007/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4967\n",
      "5008/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.4978\n",
      "5009/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5093\n",
      "5010/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5010\n",
      "5011/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5103\n",
      "5012/15000:\n",
      "Training Loss: 0.5260 Validation Loss: 0.5009\n",
      "5013/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4975\n",
      "5014/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5038\n",
      "5015/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5071\n",
      "5016/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5028\n",
      "5017/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5039\n",
      "5018/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4998\n",
      "5019/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5055\n",
      "5020/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5140\n",
      "5021/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5191\n",
      "5022/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5102\n",
      "5023/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5065\n",
      "5024/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4972\n",
      "5025/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5052\n",
      "5026/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5024\n",
      "5027/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5184\n",
      "5028/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.4992\n",
      "5029/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.5290\n",
      "5030/15000:\n",
      "Training Loss: 0.5325 Validation Loss: 0.5329\n",
      "5031/15000:\n",
      "Training Loss: 0.5212 Validation Loss: 0.5139\n",
      "5032/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4961\n",
      "5033/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4990\n",
      "5034/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5008\n",
      "5035/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4946\n",
      "5036/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4941\n",
      "5037/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4938\n",
      "5038/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5071\n",
      "5039/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5028\n",
      "5040/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5008\n",
      "5041/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.4992\n",
      "5042/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5022\n",
      "5043/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5101\n",
      "5044/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5048\n",
      "5045/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.5225\n",
      "5046/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5037\n",
      "5047/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5018\n",
      "5048/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5118\n",
      "5049/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5041\n",
      "5050/15000:\n",
      "Training Loss: 0.5344 Validation Loss: 0.5103\n",
      "5051/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5002\n",
      "5052/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4995\n",
      "5053/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5016\n",
      "5054/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.4943\n",
      "5055/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5002\n",
      "5056/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.4987\n",
      "5057/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4982\n",
      "5058/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4993\n",
      "5059/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5005\n",
      "5060/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5114\n",
      "5061/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5009\n",
      "5062/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5048\n",
      "5063/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5084\n",
      "5064/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.4961\n",
      "5065/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4926\n",
      "5066/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4929\n",
      "5067/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5040\n",
      "5068/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4975\n",
      "5069/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.4948\n",
      "5070/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5039\n",
      "5071/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5019\n",
      "5072/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5076\n",
      "5073/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5133\n",
      "5074/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5119\n",
      "5075/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5043\n",
      "5076/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4927\n",
      "5077/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5020\n",
      "5078/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.4996\n",
      "5079/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.4950\n",
      "5080/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5032\n",
      "5081/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5097\n",
      "5082/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5049\n",
      "5083/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5045\n",
      "5084/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5012\n",
      "5085/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4920\n",
      "5086/15000:\n",
      "Training Loss: 0.4707 Validation Loss: 0.4932\n",
      "5087/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.4916\n",
      "5088/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.4990\n",
      "5089/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5118\n",
      "5090/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4954\n",
      "5091/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5055\n",
      "5092/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5176\n",
      "5093/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5038\n",
      "5094/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4993\n",
      "5095/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.4967\n",
      "5096/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4997\n",
      "5097/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.4915\n",
      "5098/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4909\n",
      "5099/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4963\n",
      "5100/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.4963\n",
      "5101/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.4960\n",
      "5102/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5059\n",
      "5103/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5014\n",
      "5104/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5073\n",
      "5105/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5396\n",
      "5106/15000:\n",
      "Training Loss: 0.5359 Validation Loss: 0.5486\n",
      "5107/15000:\n",
      "Training Loss: 0.5502 Validation Loss: 0.5666\n",
      "5108/15000:\n",
      "Training Loss: 0.5753 Validation Loss: 0.6346\n",
      "5109/15000:\n",
      "Training Loss: 0.6413 Validation Loss: 0.5388\n",
      "5110/15000:\n",
      "Training Loss: 0.5260 Validation Loss: 0.5107\n",
      "5111/15000:\n",
      "Training Loss: 0.5187 Validation Loss: 0.5094\n",
      "5112/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5017\n",
      "5113/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5022\n",
      "5114/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5021\n",
      "5115/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5054\n",
      "5116/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5021\n",
      "5117/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5027\n",
      "5118/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5047\n",
      "5119/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5075\n",
      "5120/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5023\n",
      "5121/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5116\n",
      "5122/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.4990\n",
      "5123/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5065\n",
      "5124/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5052\n",
      "5125/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5068\n",
      "5126/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5088\n",
      "5127/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5019\n",
      "5128/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4995\n",
      "5129/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4995\n",
      "5130/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5038\n",
      "5131/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5038\n",
      "5132/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4987\n",
      "5133/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5001\n",
      "5134/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5073\n",
      "5135/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5129\n",
      "5136/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5395\n",
      "5137/15000:\n",
      "Training Loss: 0.5435 Validation Loss: 0.5023\n",
      "5138/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5129\n",
      "5139/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5052\n",
      "5140/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5013\n",
      "5141/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.4956\n",
      "5142/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5044\n",
      "5143/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5171\n",
      "5144/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5288\n",
      "5145/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.5060\n",
      "5146/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4991\n",
      "5147/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5079\n",
      "5148/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5001\n",
      "5149/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5117\n",
      "5150/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5126\n",
      "5151/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4948\n",
      "5152/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4919\n",
      "5153/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5005\n",
      "5154/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5185\n",
      "5155/15000:\n",
      "Training Loss: 0.5320 Validation Loss: 0.5231\n",
      "5156/15000:\n",
      "Training Loss: 0.5360 Validation Loss: 0.5331\n",
      "5157/15000:\n",
      "Training Loss: 0.5224 Validation Loss: 0.5059\n",
      "5158/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.5170\n",
      "5159/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5005\n",
      "5160/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5014\n",
      "5161/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5055\n",
      "5162/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5061\n",
      "5163/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5064\n",
      "5164/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5152\n",
      "5165/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5015\n",
      "5166/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5074\n",
      "5167/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5029\n",
      "5168/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5070\n",
      "5169/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5079\n",
      "5170/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5122\n",
      "5171/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5040\n",
      "5172/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5045\n",
      "5173/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.4975\n",
      "5174/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.4984\n",
      "5175/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5071\n",
      "5176/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5069\n",
      "5177/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5009\n",
      "5178/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5020\n",
      "5179/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5049\n",
      "5180/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5028\n",
      "5181/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5060\n",
      "5182/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5057\n",
      "5183/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5096\n",
      "5184/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5063\n",
      "5185/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5098\n",
      "5186/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5175\n",
      "5187/15000:\n",
      "Training Loss: 0.5155 Validation Loss: 0.5499\n",
      "5188/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5188\n",
      "5189/15000:\n",
      "Training Loss: 0.5271 Validation Loss: 0.5141\n",
      "5190/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.4987\n",
      "5191/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5234\n",
      "5192/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.5027\n",
      "5193/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4947\n",
      "5194/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4985\n",
      "5195/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5001\n",
      "5196/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.4978\n",
      "5197/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.4967\n",
      "5198/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5086\n",
      "5199/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4993\n",
      "5200/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5010\n",
      "5201/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.4976\n",
      "5202/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4985\n",
      "5203/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5066\n",
      "5204/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5008\n",
      "5205/15000:\n",
      "Training Loss: 0.4667 Validation Loss: 0.5282\n",
      "5206/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5029\n",
      "5207/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5002\n",
      "5208/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5028\n",
      "5209/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.4993\n",
      "5210/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4979\n",
      "5211/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5044\n",
      "5212/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5294\n",
      "5213/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5384\n",
      "5214/15000:\n",
      "Training Loss: 0.5375 Validation Loss: 0.6339\n",
      "5215/15000:\n",
      "Training Loss: 0.6351 Validation Loss: 0.5173\n",
      "5216/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5061\n",
      "5217/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5101\n",
      "5218/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5084\n",
      "5219/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5051\n",
      "5220/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5046\n",
      "5221/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5034\n",
      "5222/15000:\n",
      "Training Loss: 0.4674 Validation Loss: 0.5007\n",
      "5223/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4985\n",
      "5224/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5049\n",
      "5225/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4979\n",
      "5226/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5005\n",
      "5227/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5180\n",
      "5228/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5038\n",
      "5229/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5056\n",
      "5230/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5545\n",
      "5231/15000:\n",
      "Training Loss: 0.5327 Validation Loss: 0.5074\n",
      "5232/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5131\n",
      "5233/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4990\n",
      "5234/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5013\n",
      "5235/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.4987\n",
      "5236/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5014\n",
      "5237/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5037\n",
      "5238/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.4971\n",
      "5239/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.4990\n",
      "5240/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5084\n",
      "5241/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5193\n",
      "5242/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4989\n",
      "5243/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5005\n",
      "5244/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4942\n",
      "5245/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5059\n",
      "5246/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5013\n",
      "5247/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4938\n",
      "5248/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4976\n",
      "5249/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5046\n",
      "5250/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5105\n",
      "5251/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5265\n",
      "5252/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.5345\n",
      "5253/15000:\n",
      "Training Loss: 0.5499 Validation Loss: 0.5303\n",
      "5254/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.5773\n",
      "5255/15000:\n",
      "Training Loss: 0.6118 Validation Loss: 0.5159\n",
      "5256/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5102\n",
      "5257/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5119\n",
      "5258/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5099\n",
      "5259/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5086\n",
      "5260/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5173\n",
      "5261/15000:\n",
      "Training Loss: 0.5176 Validation Loss: 0.5039\n",
      "5262/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5014\n",
      "5263/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5092\n",
      "5264/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5055\n",
      "5265/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5150\n",
      "5266/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5182\n",
      "5267/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5055\n",
      "5268/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5115\n",
      "5269/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5138\n",
      "5270/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5093\n",
      "5271/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5063\n",
      "5272/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5040\n",
      "5273/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5022\n",
      "5274/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5045\n",
      "5275/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5021\n",
      "5276/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5027\n",
      "5277/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5010\n",
      "5278/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5277\n",
      "5279/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5142\n",
      "5280/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5034\n",
      "5281/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.5254\n",
      "5282/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5276\n",
      "5283/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5029\n",
      "5284/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4967\n",
      "5285/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5033\n",
      "5286/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5008\n",
      "5287/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5031\n",
      "5288/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5105\n",
      "5289/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5055\n",
      "5290/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5119\n",
      "5291/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5068\n",
      "5292/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.4979\n",
      "5293/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4971\n",
      "5294/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5001\n",
      "5295/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5078\n",
      "5296/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5070\n",
      "5297/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5035\n",
      "5298/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5071\n",
      "5299/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5039\n",
      "5300/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5097\n",
      "5301/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.4996\n",
      "5302/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5093\n",
      "5303/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5146\n",
      "5304/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5220\n",
      "5305/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5087\n",
      "5306/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5041\n",
      "5307/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4962\n",
      "5308/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.4997\n",
      "5309/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5007\n",
      "5310/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5047\n",
      "5311/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.4959\n",
      "5312/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5112\n",
      "5313/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5115\n",
      "5314/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5098\n",
      "5315/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5129\n",
      "5316/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5075\n",
      "5317/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5055\n",
      "5318/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5045\n",
      "5319/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4979\n",
      "5320/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5010\n",
      "5321/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5133\n",
      "5322/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5008\n",
      "5323/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5066\n",
      "5324/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5024\n",
      "5325/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5067\n",
      "5326/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.4981\n",
      "5327/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5030\n",
      "5328/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5041\n",
      "5329/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5131\n",
      "5330/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5044\n",
      "5331/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5063\n",
      "5332/15000:\n",
      "Training Loss: 0.5156 Validation Loss: 0.5355\n",
      "5333/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5044\n",
      "5334/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5207\n",
      "5335/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5085\n",
      "5336/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5361\n",
      "5337/15000:\n",
      "Training Loss: 0.5300 Validation Loss: 0.5061\n",
      "5338/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5088\n",
      "5339/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5028\n",
      "5340/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5009\n",
      "5341/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5007\n",
      "5342/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5025\n",
      "5343/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5028\n",
      "5344/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5188\n",
      "5345/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5395\n",
      "5346/15000:\n",
      "Training Loss: 0.5300 Validation Loss: 0.5496\n",
      "5347/15000:\n",
      "Training Loss: 0.5716 Validation Loss: 0.5206\n",
      "5348/15000:\n",
      "Training Loss: 0.5167 Validation Loss: 0.5059\n",
      "5349/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5093\n",
      "5350/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5030\n",
      "5351/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5018\n",
      "5352/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5014\n",
      "5353/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.4970\n",
      "5354/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5036\n",
      "5355/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5118\n",
      "5356/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5082\n",
      "5357/15000:\n",
      "Training Loss: 0.5203 Validation Loss: 0.4997\n",
      "5358/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4974\n",
      "5359/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4998\n",
      "5360/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5002\n",
      "5361/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4970\n",
      "5362/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5050\n",
      "5363/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5043\n",
      "5364/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5057\n",
      "5365/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5040\n",
      "5366/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5007\n",
      "5367/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5074\n",
      "5368/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5001\n",
      "5369/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5086\n",
      "5370/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5081\n",
      "5371/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.4952\n",
      "5372/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4910\n",
      "5373/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.4986\n",
      "5374/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5019\n",
      "5375/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5041\n",
      "5376/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5229\n",
      "5377/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5090\n",
      "5378/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.4987\n",
      "5379/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5041\n",
      "5380/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5063\n",
      "5381/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.4986\n",
      "5382/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5059\n",
      "5383/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5194\n",
      "5384/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5977\n",
      "5385/15000:\n",
      "Training Loss: 0.5907 Validation Loss: 0.5180\n",
      "5386/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5100\n",
      "5387/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5042\n",
      "5388/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.4976\n",
      "5389/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5017\n",
      "5390/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4980\n",
      "5391/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5012\n",
      "5392/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5345\n",
      "5393/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.5141\n",
      "5394/15000:\n",
      "Training Loss: 0.5402 Validation Loss: 0.5024\n",
      "5395/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5047\n",
      "5396/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5085\n",
      "5397/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5044\n",
      "5398/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5045\n",
      "5399/15000:\n",
      "Training Loss: 0.4701 Validation Loss: 0.5066\n",
      "5400/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5029\n",
      "5401/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5138\n",
      "5402/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5081\n",
      "5403/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5084\n",
      "5404/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4959\n",
      "5405/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.4970\n",
      "5406/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.4990\n",
      "5407/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5033\n",
      "5408/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5010\n",
      "5409/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5039\n",
      "5410/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5029\n",
      "5411/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5055\n",
      "5412/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5028\n",
      "5413/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4981\n",
      "5414/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5095\n",
      "5415/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5129\n",
      "5416/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5021\n",
      "5417/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5241\n",
      "5418/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5017\n",
      "5419/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5015\n",
      "5420/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.4969\n",
      "5421/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5129\n",
      "5422/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.4980\n",
      "5423/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4984\n",
      "5424/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5018\n",
      "5425/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5029\n",
      "5426/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5125\n",
      "5427/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5188\n",
      "5428/15000:\n",
      "Training Loss: 0.5208 Validation Loss: 0.5120\n",
      "5429/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5002\n",
      "5430/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5043\n",
      "5431/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5012\n",
      "5432/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.4991\n",
      "5433/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5080\n",
      "5434/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4943\n",
      "5435/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.4962\n",
      "5436/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.4946\n",
      "5437/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4983\n",
      "5438/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5024\n",
      "5439/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4953\n",
      "5440/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5007\n",
      "5441/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4985\n",
      "5442/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5027\n",
      "5443/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5238\n",
      "5444/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5648\n",
      "5445/15000:\n",
      "Training Loss: 0.5305 Validation Loss: 0.5129\n",
      "5446/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5057\n",
      "5447/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5009\n",
      "5448/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.4996\n",
      "5449/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4983\n",
      "5450/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5022\n",
      "5451/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5015\n",
      "5452/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5106\n",
      "5453/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5046\n",
      "5454/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5070\n",
      "5455/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5059\n",
      "5456/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5075\n",
      "5457/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5192\n",
      "5458/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5126\n",
      "5459/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5034\n",
      "5460/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5049\n",
      "5461/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5032\n",
      "5462/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5021\n",
      "5463/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5096\n",
      "5464/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.4956\n",
      "5465/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5033\n",
      "5466/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5066\n",
      "5467/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5209\n",
      "5468/15000:\n",
      "Training Loss: 0.5235 Validation Loss: 0.5424\n",
      "5469/15000:\n",
      "Training Loss: 0.5275 Validation Loss: 0.5757\n",
      "5470/15000:\n",
      "Training Loss: 0.5803 Validation Loss: 0.5172\n",
      "5471/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5082\n",
      "5472/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5107\n",
      "5473/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5039\n",
      "5474/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5031\n",
      "5475/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5009\n",
      "5476/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5015\n",
      "5477/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5036\n",
      "5478/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5067\n",
      "5479/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5138\n",
      "5480/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5230\n",
      "5481/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5305\n",
      "5482/15000:\n",
      "Training Loss: 0.5254 Validation Loss: 0.5286\n",
      "5483/15000:\n",
      "Training Loss: 0.5351 Validation Loss: 0.5123\n",
      "5484/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5084\n",
      "5485/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5088\n",
      "5486/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5087\n",
      "5487/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5049\n",
      "5488/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5123\n",
      "5489/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5157\n",
      "5490/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5059\n",
      "5491/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5036\n",
      "5492/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.5018\n",
      "5493/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5014\n",
      "5494/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5055\n",
      "5495/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5124\n",
      "5496/15000:\n",
      "Training Loss: 0.5238 Validation Loss: 0.5569\n",
      "5497/15000:\n",
      "Training Loss: 0.5594 Validation Loss: 0.5755\n",
      "5498/15000:\n",
      "Training Loss: 0.5915 Validation Loss: 0.5203\n",
      "5499/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5142\n",
      "5500/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5108\n",
      "5501/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5080\n",
      "5502/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5082\n",
      "5503/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5163\n",
      "5504/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5113\n",
      "5505/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5092\n",
      "5506/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5069\n",
      "5507/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5024\n",
      "5508/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5017\n",
      "5509/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5074\n",
      "5510/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5033\n",
      "5511/15000:\n",
      "Training Loss: 0.4670 Validation Loss: 0.5052\n",
      "5512/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5037\n",
      "5513/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5042\n",
      "5514/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5082\n",
      "5515/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5057\n",
      "5516/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5298\n",
      "5517/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5006\n",
      "5518/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4999\n",
      "5519/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4995\n",
      "5520/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4964\n",
      "5521/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.4995\n",
      "5522/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5090\n",
      "5523/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5151\n",
      "5524/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5213\n",
      "5525/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5381\n",
      "5526/15000:\n",
      "Training Loss: 0.5365 Validation Loss: 0.5419\n",
      "5527/15000:\n",
      "Training Loss: 0.5402 Validation Loss: 0.5154\n",
      "5528/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5006\n",
      "5529/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5029\n",
      "5530/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5001\n",
      "5531/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5020\n",
      "5532/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.4979\n",
      "5533/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5008\n",
      "5534/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5000\n",
      "5535/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5109\n",
      "5536/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5009\n",
      "5537/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5130\n",
      "5538/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.4990\n",
      "5539/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5073\n",
      "5540/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5001\n",
      "5541/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5007\n",
      "5542/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5030\n",
      "5543/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5075\n",
      "5544/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5177\n",
      "5545/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.4998\n",
      "5546/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.4976\n",
      "5547/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4986\n",
      "5548/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5036\n",
      "5549/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4988\n",
      "5550/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5010\n",
      "5551/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4945\n",
      "5552/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.4952\n",
      "5553/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4975\n",
      "5554/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.5008\n",
      "5555/15000:\n",
      "Training Loss: 0.5225 Validation Loss: 0.5087\n",
      "5556/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.4993\n",
      "5557/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5027\n",
      "5558/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5093\n",
      "5559/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5038\n",
      "5560/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5057\n",
      "5561/15000:\n",
      "Training Loss: 0.4707 Validation Loss: 0.5075\n",
      "5562/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5058\n",
      "5563/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5081\n",
      "5564/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5002\n",
      "5565/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5001\n",
      "5566/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.4981\n",
      "5567/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.5097\n",
      "5568/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5073\n",
      "5569/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.4999\n",
      "5570/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5023\n",
      "5571/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5092\n",
      "5572/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5127\n",
      "5573/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.4990\n",
      "5574/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5048\n",
      "5575/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5048\n",
      "5576/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5119\n",
      "5577/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5050\n",
      "5578/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5026\n",
      "5579/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5124\n",
      "5580/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5112\n",
      "5581/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5103\n",
      "5582/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5115\n",
      "5583/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5131\n",
      "5584/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5073\n",
      "5585/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5043\n",
      "5586/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5114\n",
      "5587/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5053\n",
      "5588/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4958\n",
      "5589/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.4941\n",
      "5590/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4972\n",
      "5591/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5037\n",
      "5592/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.4985\n",
      "5593/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4953\n",
      "5594/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4974\n",
      "5595/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5195\n",
      "5596/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.4960\n",
      "5597/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4988\n",
      "5598/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.4981\n",
      "5599/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5009\n",
      "5600/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5118\n",
      "5601/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5334\n",
      "5602/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5025\n",
      "5603/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5065\n",
      "5604/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5044\n",
      "5605/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5181\n",
      "5606/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5377\n",
      "5607/15000:\n",
      "Training Loss: 0.5179 Validation Loss: 0.5362\n",
      "5608/15000:\n",
      "Training Loss: 0.5288 Validation Loss: 0.5529\n",
      "5609/15000:\n",
      "Training Loss: 0.5439 Validation Loss: 0.5092\n",
      "5610/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5054\n",
      "5611/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5018\n",
      "5612/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5035\n",
      "5613/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5000\n",
      "5614/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4962\n",
      "5615/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5043\n",
      "5616/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5038\n",
      "5617/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5031\n",
      "5618/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5069\n",
      "5619/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5229\n",
      "5620/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5181\n",
      "5621/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.4988\n",
      "5622/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5052\n",
      "5623/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5006\n",
      "5624/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4991\n",
      "5625/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5050\n",
      "5626/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5036\n",
      "5627/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5130\n",
      "5628/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.4964\n",
      "5629/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5000\n",
      "5630/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5080\n",
      "5631/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5202\n",
      "5632/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5030\n",
      "5633/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5208\n",
      "5634/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5219\n",
      "5635/15000:\n",
      "Training Loss: 0.5206 Validation Loss: 0.5275\n",
      "5636/15000:\n",
      "Training Loss: 0.5465 Validation Loss: 0.5519\n",
      "5637/15000:\n",
      "Training Loss: 0.5221 Validation Loss: 0.5218\n",
      "5638/15000:\n",
      "Training Loss: 0.5243 Validation Loss: 0.5203\n",
      "5639/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5037\n",
      "5640/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5055\n",
      "5641/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4949\n",
      "5642/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5037\n",
      "5643/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5057\n",
      "5644/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5080\n",
      "5645/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5033\n",
      "5646/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.4985\n",
      "5647/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5064\n",
      "5648/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5027\n",
      "5649/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4994\n",
      "5650/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5020\n",
      "5651/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5010\n",
      "5652/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5013\n",
      "5653/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5088\n",
      "5654/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4992\n",
      "5655/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5071\n",
      "5656/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5015\n",
      "5657/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5080\n",
      "5658/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5051\n",
      "5659/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5016\n",
      "5660/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5014\n",
      "5661/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5059\n",
      "5662/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5177\n",
      "5663/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5015\n",
      "5664/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5063\n",
      "5665/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5041\n",
      "5666/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5030\n",
      "5667/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5003\n",
      "5668/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5155\n",
      "5669/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4983\n",
      "5670/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5067\n",
      "5671/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5050\n",
      "5672/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.4947\n",
      "5673/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.4995\n",
      "5674/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4987\n",
      "5675/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5049\n",
      "5676/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5018\n",
      "5677/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5140\n",
      "5678/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5006\n",
      "5679/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5081\n",
      "5680/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5724\n",
      "5681/15000:\n",
      "Training Loss: 0.5501 Validation Loss: 0.5675\n",
      "5682/15000:\n",
      "Training Loss: 0.5860 Validation Loss: 0.5597\n",
      "5683/15000:\n",
      "Training Loss: 0.5401 Validation Loss: 0.5044\n",
      "5684/15000:\n",
      "Training Loss: 0.5195 Validation Loss: 0.5021\n",
      "5685/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5070\n",
      "5686/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5049\n",
      "5687/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5010\n",
      "5688/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5025\n",
      "5689/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5010\n",
      "5690/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5126\n",
      "5691/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5167\n",
      "5692/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5021\n",
      "5693/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5049\n",
      "5694/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5009\n",
      "5695/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5016\n",
      "5696/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5030\n",
      "5697/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5023\n",
      "5698/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4933\n",
      "5699/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5045\n",
      "5700/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5115\n",
      "5701/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5078\n",
      "5702/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5049\n",
      "5703/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5136\n",
      "5704/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4969\n",
      "5705/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5047\n",
      "5706/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4990\n",
      "5707/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5015\n",
      "5708/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5006\n",
      "5709/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5048\n",
      "5710/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.4969\n",
      "5711/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5146\n",
      "5712/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5280\n",
      "5713/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5239\n",
      "5714/15000:\n",
      "Training Loss: 0.5376 Validation Loss: 0.5133\n",
      "5715/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5065\n",
      "5716/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4999\n",
      "5717/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5113\n",
      "5718/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5369\n",
      "5719/15000:\n",
      "Training Loss: 0.5242 Validation Loss: 0.5102\n",
      "5720/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5105\n",
      "5721/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5140\n",
      "5722/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5110\n",
      "5723/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4960\n",
      "5724/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4989\n",
      "5725/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5047\n",
      "5726/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5035\n",
      "5727/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5074\n",
      "5728/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4993\n",
      "5729/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5072\n",
      "5730/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4947\n",
      "5731/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4998\n",
      "5732/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5036\n",
      "5733/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5325\n",
      "5734/15000:\n",
      "Training Loss: 0.5212 Validation Loss: 0.5438\n",
      "5735/15000:\n",
      "Training Loss: 0.5216 Validation Loss: 0.5735\n",
      "5736/15000:\n",
      "Training Loss: 0.5814 Validation Loss: 0.5633\n",
      "5737/15000:\n",
      "Training Loss: 0.5589 Validation Loss: 0.5203\n",
      "5738/15000:\n",
      "Training Loss: 0.5427 Validation Loss: 0.5119\n",
      "5739/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5080\n",
      "5740/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5065\n",
      "5741/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5010\n",
      "5742/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5062\n",
      "5743/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5021\n",
      "5744/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5091\n",
      "5745/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4960\n",
      "5746/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5017\n",
      "5747/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5105\n",
      "5748/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5008\n",
      "5749/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4996\n",
      "5750/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5020\n",
      "5751/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5018\n",
      "5752/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5003\n",
      "5753/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5038\n",
      "5754/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5030\n",
      "5755/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.4987\n",
      "5756/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5018\n",
      "5757/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.4999\n",
      "5758/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5063\n",
      "5759/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5007\n",
      "5760/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5018\n",
      "5761/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5007\n",
      "5762/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5095\n",
      "5763/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5075\n",
      "5764/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4971\n",
      "5765/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5021\n",
      "5766/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5007\n",
      "5767/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5129\n",
      "5768/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5093\n",
      "5769/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5041\n",
      "5770/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4998\n",
      "5771/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5040\n",
      "5772/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.4942\n",
      "5773/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4919\n",
      "5774/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.4907\n",
      "5775/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.4967\n",
      "5776/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5081\n",
      "5777/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5394\n",
      "5778/15000:\n",
      "Training Loss: 0.5253 Validation Loss: 0.5153\n",
      "5779/15000:\n",
      "Training Loss: 0.5417 Validation Loss: 0.5108\n",
      "5780/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5317\n",
      "5781/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5172\n",
      "5782/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5068\n",
      "5783/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5168\n",
      "5784/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5019\n",
      "5785/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5025\n",
      "5786/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5087\n",
      "5787/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5153\n",
      "5788/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5030\n",
      "5789/15000:\n",
      "Training Loss: 0.4748 Validation Loss: 0.4933\n",
      "5790/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.4932\n",
      "5791/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.4980\n",
      "5792/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5062\n",
      "5793/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5040\n",
      "5794/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.4997\n",
      "5795/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5061\n",
      "5796/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4925\n",
      "5797/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4960\n",
      "5798/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5363\n",
      "5799/15000:\n",
      "Training Loss: 0.5262 Validation Loss: 0.5308\n",
      "5800/15000:\n",
      "Training Loss: 0.5419 Validation Loss: 0.5265\n",
      "5801/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.5020\n",
      "5802/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5068\n",
      "5803/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4996\n",
      "5804/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5031\n",
      "5805/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5030\n",
      "5806/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5109\n",
      "5807/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5031\n",
      "5808/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5096\n",
      "5809/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5053\n",
      "5810/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4995\n",
      "5811/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4955\n",
      "5812/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5066\n",
      "5813/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.4943\n",
      "5814/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4922\n",
      "5815/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.4975\n",
      "5816/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5043\n",
      "5817/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5136\n",
      "5818/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5137\n",
      "5819/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5317\n",
      "5820/15000:\n",
      "Training Loss: 0.5470 Validation Loss: 0.5308\n",
      "5821/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.5699\n",
      "5822/15000:\n",
      "Training Loss: 0.5616 Validation Loss: 0.4942\n",
      "5823/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5026\n",
      "5824/15000:\n",
      "Training Loss: 0.4639 Validation Loss: 0.4954\n",
      "5825/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4976\n",
      "5826/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5010\n",
      "5827/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4988\n",
      "5828/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5012\n",
      "5829/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5000\n",
      "5830/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5013\n",
      "5831/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5045\n",
      "5832/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5217\n",
      "5833/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5153\n",
      "5834/15000:\n",
      "Training Loss: 0.5308 Validation Loss: 0.5251\n",
      "5835/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5092\n",
      "5836/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5218\n",
      "5837/15000:\n",
      "Training Loss: 0.5247 Validation Loss: 0.5038\n",
      "5838/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5032\n",
      "5839/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5037\n",
      "5840/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5043\n",
      "5841/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5102\n",
      "5842/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5051\n",
      "5843/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5164\n",
      "5844/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4953\n",
      "5845/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4970\n",
      "5846/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4986\n",
      "5847/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.4998\n",
      "5848/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.4955\n",
      "5849/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5040\n",
      "5850/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5077\n",
      "5851/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5045\n",
      "5852/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4937\n",
      "5853/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5054\n",
      "5854/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5161\n",
      "5855/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5081\n",
      "5856/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5004\n",
      "5857/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.4974\n",
      "5858/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4968\n",
      "5859/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5014\n",
      "5860/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5107\n",
      "5861/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5074\n",
      "5862/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4962\n",
      "5863/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5018\n",
      "5864/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.4948\n",
      "5865/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4951\n",
      "5866/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5011\n",
      "5867/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5003\n",
      "5868/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5096\n",
      "5869/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5002\n",
      "5870/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5015\n",
      "5871/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5109\n",
      "5872/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5009\n",
      "5873/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5118\n",
      "5874/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.4993\n",
      "5875/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5026\n",
      "5876/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.4963\n",
      "5877/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5080\n",
      "5878/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5731\n",
      "5879/15000:\n",
      "Training Loss: 0.5491 Validation Loss: 0.5435\n",
      "5880/15000:\n",
      "Training Loss: 0.5816 Validation Loss: 0.5233\n",
      "5881/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.5065\n",
      "5882/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5259\n",
      "5883/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.4983\n",
      "5884/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5014\n",
      "5885/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5013\n",
      "5886/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.4966\n",
      "5887/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4921\n",
      "5888/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.4966\n",
      "5889/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5072\n",
      "5890/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5144\n",
      "5891/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5011\n",
      "5892/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5118\n",
      "5893/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5145\n",
      "5894/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5052\n",
      "5895/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4970\n",
      "5896/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4938\n",
      "5897/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5004\n",
      "5898/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5095\n",
      "5899/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5002\n",
      "5900/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5144\n",
      "5901/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4979\n",
      "5902/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.4990\n",
      "5903/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.4990\n",
      "5904/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4970\n",
      "5905/15000:\n",
      "Training Loss: 0.4664 Validation Loss: 0.5004\n",
      "5906/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5004\n",
      "5907/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4951\n",
      "5908/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5010\n",
      "5909/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5052\n",
      "5910/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5140\n",
      "5911/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5050\n",
      "5912/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5134\n",
      "5913/15000:\n",
      "Training Loss: 0.5243 Validation Loss: 0.5045\n",
      "5914/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4997\n",
      "5915/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5124\n",
      "5916/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5066\n",
      "5917/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5009\n",
      "5918/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5008\n",
      "5919/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.4997\n",
      "5920/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5084\n",
      "5921/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5031\n",
      "5922/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5038\n",
      "5923/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5064\n",
      "5924/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5070\n",
      "5925/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5133\n",
      "5926/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5062\n",
      "5927/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5058\n",
      "5928/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5093\n",
      "5929/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5126\n",
      "5930/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4929\n",
      "5931/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.4886\n",
      "5932/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4978\n",
      "5933/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4978\n",
      "5934/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4948\n",
      "5935/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4893\n",
      "5936/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5006\n",
      "5937/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.4931\n",
      "5938/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.4915\n",
      "5939/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5040\n",
      "5940/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4970\n",
      "5941/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4995\n",
      "5942/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5051\n",
      "5943/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5095\n",
      "5944/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5085\n",
      "5945/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5027\n",
      "5946/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5170\n",
      "5947/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5284\n",
      "5948/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5135\n",
      "5949/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5095\n",
      "5950/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4983\n",
      "5951/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5011\n",
      "5952/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5083\n",
      "5953/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5069\n",
      "5954/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5393\n",
      "5955/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5538\n",
      "5956/15000:\n",
      "Training Loss: 0.5755 Validation Loss: 0.5122\n",
      "5957/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5024\n",
      "5958/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.4967\n",
      "5959/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4994\n",
      "5960/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.4988\n",
      "5961/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4982\n",
      "5962/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.4985\n",
      "5963/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5027\n",
      "5964/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4977\n",
      "5965/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4956\n",
      "5966/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5197\n",
      "5967/15000:\n",
      "Training Loss: 0.5386 Validation Loss: 0.5310\n",
      "5968/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5026\n",
      "5969/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5023\n",
      "5970/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5091\n",
      "5971/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5012\n",
      "5972/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5029\n",
      "5973/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5136\n",
      "5974/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.4983\n",
      "5975/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.4969\n",
      "5976/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4976\n",
      "5977/15000:\n",
      "Training Loss: 0.4710 Validation Loss: 0.4966\n",
      "5978/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4948\n",
      "5979/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5120\n",
      "5980/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4949\n",
      "5981/15000:\n",
      "Training Loss: 0.4639 Validation Loss: 0.5067\n",
      "5982/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5079\n",
      "5983/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5188\n",
      "5984/15000:\n",
      "Training Loss: 0.5265 Validation Loss: 0.5152\n",
      "5985/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5028\n",
      "5986/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.4993\n",
      "5987/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5068\n",
      "5988/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4995\n",
      "5989/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5090\n",
      "5990/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5018\n",
      "5991/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4995\n",
      "5992/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5006\n",
      "5993/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5117\n",
      "5994/15000:\n",
      "Training Loss: 0.5185 Validation Loss: 0.5046\n",
      "5995/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.4925\n",
      "5996/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.4929\n",
      "5997/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.4942\n",
      "5998/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5028\n",
      "5999/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5020\n",
      "6000/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5007\n",
      "6001/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5051\n",
      "6002/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5169\n",
      "6003/15000:\n",
      "Training Loss: 0.5216 Validation Loss: 0.5155\n",
      "6004/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.4990\n",
      "6005/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.4938\n",
      "6006/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4930\n",
      "6007/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.4942\n",
      "6008/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4925\n",
      "6009/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.4943\n",
      "6010/15000:\n",
      "Training Loss: 0.4589 Validation Loss: 0.4933\n",
      "6011/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5007\n",
      "6012/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5023\n",
      "6013/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5137\n",
      "6014/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5149\n",
      "6015/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5045\n",
      "6016/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5233\n",
      "6017/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.6075\n",
      "6018/15000:\n",
      "Training Loss: 0.6240 Validation Loss: 0.5114\n",
      "6019/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5081\n",
      "6020/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4992\n",
      "6021/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4969\n",
      "6022/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5054\n",
      "6023/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5051\n",
      "6024/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5135\n",
      "6025/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5038\n",
      "6026/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.5164\n",
      "6027/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5037\n",
      "6028/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5108\n",
      "6029/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.4948\n",
      "6030/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4925\n",
      "6031/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.4909\n",
      "6032/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.4956\n",
      "6033/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4994\n",
      "6034/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5012\n",
      "6035/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5009\n",
      "6036/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5113\n",
      "6037/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5084\n",
      "6038/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.4964\n",
      "6039/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.4970\n",
      "6040/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4987\n",
      "6041/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5150\n",
      "6042/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5192\n",
      "6043/15000:\n",
      "Training Loss: 0.5229 Validation Loss: 0.5274\n",
      "6044/15000:\n",
      "Training Loss: 0.5456 Validation Loss: 0.5553\n",
      "6045/15000:\n",
      "Training Loss: 0.5602 Validation Loss: 0.5413\n",
      "6046/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5221\n",
      "6047/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5038\n",
      "6048/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.4978\n",
      "6049/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4993\n",
      "6050/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5013\n",
      "6051/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5072\n",
      "6052/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5045\n",
      "6053/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5032\n",
      "6054/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5000\n",
      "6055/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5078\n",
      "6056/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5073\n",
      "6057/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5075\n",
      "6058/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4981\n",
      "6059/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5001\n",
      "6060/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4977\n",
      "6061/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5002\n",
      "6062/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5002\n",
      "6063/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.4987\n",
      "6064/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4977\n",
      "6065/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5063\n",
      "6066/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5090\n",
      "6067/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5046\n",
      "6068/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5046\n",
      "6069/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5167\n",
      "6070/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5012\n",
      "6071/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5029\n",
      "6072/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4990\n",
      "6073/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4983\n",
      "6074/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.4962\n",
      "6075/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4976\n",
      "6076/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5086\n",
      "6077/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5030\n",
      "6078/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5003\n",
      "6079/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5007\n",
      "6080/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5044\n",
      "6081/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5325\n",
      "6082/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5303\n",
      "6083/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.5154\n",
      "6084/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5058\n",
      "6085/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5174\n",
      "6086/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5178\n",
      "6087/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5256\n",
      "6088/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.4964\n",
      "6089/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.4968\n",
      "6090/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5012\n",
      "6091/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5022\n",
      "6092/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5060\n",
      "6093/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5387\n",
      "6094/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5112\n",
      "6095/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5137\n",
      "6096/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5090\n",
      "6097/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5024\n",
      "6098/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5073\n",
      "6099/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5082\n",
      "6100/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5118\n",
      "6101/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5117\n",
      "6102/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.4983\n",
      "6103/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5080\n",
      "6104/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5070\n",
      "6105/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4995\n",
      "6106/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5011\n",
      "6107/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5060\n",
      "6108/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.4975\n",
      "6109/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5021\n",
      "6110/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.4983\n",
      "6111/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5003\n",
      "6112/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5104\n",
      "6113/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5013\n",
      "6114/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5068\n",
      "6115/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4964\n",
      "6116/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4943\n",
      "6117/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.4999\n",
      "6118/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5002\n",
      "6119/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5082\n",
      "6120/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4939\n",
      "6121/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5070\n",
      "6122/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5326\n",
      "6123/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5681\n",
      "6124/15000:\n",
      "Training Loss: 0.5763 Validation Loss: 0.5783\n",
      "6125/15000:\n",
      "Training Loss: 0.5454 Validation Loss: 0.6109\n",
      "6126/15000:\n",
      "Training Loss: 0.6303 Validation Loss: 0.5570\n",
      "6127/15000:\n",
      "Training Loss: 0.5557 Validation Loss: 0.5358\n",
      "6128/15000:\n",
      "Training Loss: 0.5322 Validation Loss: 0.5135\n",
      "6129/15000:\n",
      "Training Loss: 0.5360 Validation Loss: 0.5061\n",
      "6130/15000:\n",
      "Training Loss: 0.5182 Validation Loss: 0.5073\n",
      "6131/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5101\n",
      "6132/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5040\n",
      "6133/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5046\n",
      "6134/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5021\n",
      "6135/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5019\n",
      "6136/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4995\n",
      "6137/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5002\n",
      "6138/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4974\n",
      "6139/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5009\n",
      "6140/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5022\n",
      "6141/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.4959\n",
      "6142/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4993\n",
      "6143/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4978\n",
      "6144/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.4959\n",
      "6145/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5012\n",
      "6146/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4956\n",
      "6147/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5015\n",
      "6148/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.4993\n",
      "6149/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5035\n",
      "6150/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.4995\n",
      "6151/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5041\n",
      "6152/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4957\n",
      "6153/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5043\n",
      "6154/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4979\n",
      "6155/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5047\n",
      "6156/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.4938\n",
      "6157/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5084\n",
      "6158/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5051\n",
      "6159/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.4929\n",
      "6160/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4966\n",
      "6161/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.4981\n",
      "6162/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4951\n",
      "6163/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4951\n",
      "6164/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5076\n",
      "6165/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5044\n",
      "6166/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.4984\n",
      "6167/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.4945\n",
      "6168/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.4925\n",
      "6169/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.4981\n",
      "6170/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5078\n",
      "6171/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5242\n",
      "6172/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5067\n",
      "6173/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.4995\n",
      "6174/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4985\n",
      "6175/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5062\n",
      "6176/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5089\n",
      "6177/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.4973\n",
      "6178/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5238\n",
      "6179/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4982\n",
      "6180/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5143\n",
      "6181/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5107\n",
      "6182/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5128\n",
      "6183/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5088\n",
      "6184/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5132\n",
      "6185/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5187\n",
      "6186/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5084\n",
      "6187/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5141\n",
      "6188/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.5019\n",
      "6189/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4946\n",
      "6190/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5002\n",
      "6191/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4985\n",
      "6192/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5047\n",
      "6193/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5045\n",
      "6194/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5066\n",
      "6195/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5055\n",
      "6196/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5312\n",
      "6197/15000:\n",
      "Training Loss: 0.5351 Validation Loss: 0.5370\n",
      "6198/15000:\n",
      "Training Loss: 0.5323 Validation Loss: 0.6351\n",
      "6199/15000:\n",
      "Training Loss: 0.6372 Validation Loss: 0.5162\n",
      "6200/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5079\n",
      "6201/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4953\n",
      "6202/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5048\n",
      "6203/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.4985\n",
      "6204/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5002\n",
      "6205/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.4952\n",
      "6206/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4962\n",
      "6207/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5051\n",
      "6208/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5048\n",
      "6209/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.4941\n",
      "6210/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5013\n",
      "6211/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5138\n",
      "6212/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5075\n",
      "6213/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4989\n",
      "6214/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5062\n",
      "6215/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.4964\n",
      "6216/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5044\n",
      "6217/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.4987\n",
      "6218/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4992\n",
      "6219/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5111\n",
      "6220/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5049\n",
      "6221/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.5092\n",
      "6222/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5061\n",
      "6223/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5061\n",
      "6224/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5077\n",
      "6225/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5079\n",
      "6226/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5624\n",
      "6227/15000:\n",
      "Training Loss: 0.5418 Validation Loss: 0.5321\n",
      "6228/15000:\n",
      "Training Loss: 0.5464 Validation Loss: 0.5191\n",
      "6229/15000:\n",
      "Training Loss: 0.5262 Validation Loss: 0.5131\n",
      "6230/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5148\n",
      "6231/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5111\n",
      "6232/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5165\n",
      "6233/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5194\n",
      "6234/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5288\n",
      "6235/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5002\n",
      "6236/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5097\n",
      "6237/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5088\n",
      "6238/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5015\n",
      "6239/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5036\n",
      "6240/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5146\n",
      "6241/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5053\n",
      "6242/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5052\n",
      "6243/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5136\n",
      "6244/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5071\n",
      "6245/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5029\n",
      "6246/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5014\n",
      "6247/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5021\n",
      "6248/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.4998\n",
      "6249/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4957\n",
      "6250/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5075\n",
      "6251/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5053\n",
      "6252/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4998\n",
      "6253/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5103\n",
      "6254/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5254\n",
      "6255/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5069\n",
      "6256/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5217\n",
      "6257/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5276\n",
      "6258/15000:\n",
      "Training Loss: 0.5317 Validation Loss: 0.5097\n",
      "6259/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5010\n",
      "6260/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4973\n",
      "6261/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5040\n",
      "6262/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.4996\n",
      "6263/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5032\n",
      "6264/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4979\n",
      "6265/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5064\n",
      "6266/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5029\n",
      "6267/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.4994\n",
      "6268/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5059\n",
      "6269/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5197\n",
      "6270/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5338\n",
      "6271/15000:\n",
      "Training Loss: 0.5179 Validation Loss: 0.5216\n",
      "6272/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5745\n",
      "6273/15000:\n",
      "Training Loss: 0.5500 Validation Loss: 0.5243\n",
      "6274/15000:\n",
      "Training Loss: 0.5544 Validation Loss: 0.5071\n",
      "6275/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.4997\n",
      "6276/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.4978\n",
      "6277/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5005\n",
      "6278/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5007\n",
      "6279/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5029\n",
      "6280/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4996\n",
      "6281/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5011\n",
      "6282/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4980\n",
      "6283/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5003\n",
      "6284/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5044\n",
      "6285/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.4957\n",
      "6286/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5046\n",
      "6287/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5181\n",
      "6288/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5090\n",
      "6289/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5130\n",
      "6290/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4980\n",
      "6291/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5058\n",
      "6292/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5053\n",
      "6293/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5033\n",
      "6294/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5048\n",
      "6295/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4989\n",
      "6296/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.4945\n",
      "6297/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5084\n",
      "6298/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5008\n",
      "6299/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5071\n",
      "6300/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5194\n",
      "6301/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5334\n",
      "6302/15000:\n",
      "Training Loss: 0.5333 Validation Loss: 0.5199\n",
      "6303/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5047\n",
      "6304/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5039\n",
      "6305/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5045\n",
      "6306/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5059\n",
      "6307/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5066\n",
      "6308/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5006\n",
      "6309/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5049\n",
      "6310/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4978\n",
      "6311/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.4978\n",
      "6312/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5034\n",
      "6313/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5045\n",
      "6314/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5068\n",
      "6315/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5050\n",
      "6316/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5068\n",
      "6317/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5082\n",
      "6318/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5008\n",
      "6319/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5060\n",
      "6320/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5033\n",
      "6321/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5132\n",
      "6322/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.4990\n",
      "6323/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5093\n",
      "6324/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5045\n",
      "6325/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5142\n",
      "6326/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5013\n",
      "6327/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.4997\n",
      "6328/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5180\n",
      "6329/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5329\n",
      "6330/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5757\n",
      "6331/15000:\n",
      "Training Loss: 0.5384 Validation Loss: 0.5524\n",
      "6332/15000:\n",
      "Training Loss: 0.5653 Validation Loss: 0.5227\n",
      "6333/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5202\n",
      "6334/15000:\n",
      "Training Loss: 0.5410 Validation Loss: 0.5146\n",
      "6335/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5074\n",
      "6336/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5063\n",
      "6337/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5142\n",
      "6338/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5084\n",
      "6339/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5008\n",
      "6340/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4991\n",
      "6341/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5032\n",
      "6342/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5074\n",
      "6343/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5008\n",
      "6344/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5010\n",
      "6345/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5038\n",
      "6346/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.4937\n",
      "6347/15000:\n",
      "Training Loss: 0.4637 Validation Loss: 0.4952\n",
      "6348/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5029\n",
      "6349/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5047\n",
      "6350/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5029\n",
      "6351/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.5037\n",
      "6352/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5048\n",
      "6353/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4987\n",
      "6354/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4967\n",
      "6355/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5062\n",
      "6356/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5010\n",
      "6357/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5005\n",
      "6358/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5002\n",
      "6359/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5002\n",
      "6360/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5094\n",
      "6361/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5002\n",
      "6362/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5051\n",
      "6363/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5035\n",
      "6364/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5033\n",
      "6365/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5127\n",
      "6366/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5003\n",
      "6367/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5046\n",
      "6368/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4997\n",
      "6369/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.4941\n",
      "6370/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.4946\n",
      "6371/15000:\n",
      "Training Loss: 0.4681 Validation Loss: 0.4947\n",
      "6372/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.4983\n",
      "6373/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4992\n",
      "6374/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5023\n",
      "6375/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5040\n",
      "6376/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5183\n",
      "6377/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5077\n",
      "6378/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5143\n",
      "6379/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5204\n",
      "6380/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5102\n",
      "6381/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5088\n",
      "6382/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5174\n",
      "6383/15000:\n",
      "Training Loss: 0.5263 Validation Loss: 0.6009\n",
      "6384/15000:\n",
      "Training Loss: 0.5605 Validation Loss: 0.5336\n",
      "6385/15000:\n",
      "Training Loss: 0.5499 Validation Loss: 0.5204\n",
      "6386/15000:\n",
      "Training Loss: 0.5305 Validation Loss: 0.5065\n",
      "6387/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5058\n",
      "6388/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5029\n",
      "6389/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5051\n",
      "6390/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5017\n",
      "6391/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5090\n",
      "6392/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5045\n",
      "6393/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.4941\n",
      "6394/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4972\n",
      "6395/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.4962\n",
      "6396/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5062\n",
      "6397/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5101\n",
      "6398/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4995\n",
      "6399/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4994\n",
      "6400/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4958\n",
      "6401/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5020\n",
      "6402/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5040\n",
      "6403/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5011\n",
      "6404/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4987\n",
      "6405/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4997\n",
      "6406/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4979\n",
      "6407/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5066\n",
      "6408/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.4986\n",
      "6409/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5190\n",
      "6410/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5436\n",
      "6411/15000:\n",
      "Training Loss: 0.5240 Validation Loss: 0.5909\n",
      "6412/15000:\n",
      "Training Loss: 0.5701 Validation Loss: 0.5204\n",
      "6413/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.4979\n",
      "6414/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5096\n",
      "6415/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5015\n",
      "6416/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5017\n",
      "6417/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5044\n",
      "6418/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5003\n",
      "6419/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5108\n",
      "6420/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5595\n",
      "6421/15000:\n",
      "Training Loss: 0.5518 Validation Loss: 0.5221\n",
      "6422/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5116\n",
      "6423/15000:\n",
      "Training Loss: 0.5216 Validation Loss: 0.5149\n",
      "6424/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5029\n",
      "6425/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5054\n",
      "6426/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.4958\n",
      "6427/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5042\n",
      "6428/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5052\n",
      "6429/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5048\n",
      "6430/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5035\n",
      "6431/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5016\n",
      "6432/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.4956\n",
      "6433/15000:\n",
      "Training Loss: 0.4693 Validation Loss: 0.5019\n",
      "6434/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5093\n",
      "6435/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5063\n",
      "6436/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5034\n",
      "6437/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.4963\n",
      "6438/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5001\n",
      "6439/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5002\n",
      "6440/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4999\n",
      "6441/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4990\n",
      "6442/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5063\n",
      "6443/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4979\n",
      "6444/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5119\n",
      "6445/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5048\n",
      "6446/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5021\n",
      "6447/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5052\n",
      "6448/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5010\n",
      "6449/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5037\n",
      "6450/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5039\n",
      "6451/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5256\n",
      "6452/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.5133\n",
      "6453/15000:\n",
      "Training Loss: 0.5260 Validation Loss: 0.5033\n",
      "6454/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5037\n",
      "6455/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.4932\n",
      "6456/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.4993\n",
      "6457/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.4965\n",
      "6458/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5065\n",
      "6459/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4984\n",
      "6460/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5058\n",
      "6461/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5025\n",
      "6462/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5013\n",
      "6463/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5072\n",
      "6464/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5109\n",
      "6465/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5077\n",
      "6466/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5105\n",
      "6467/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5048\n",
      "6468/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5022\n",
      "6469/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5008\n",
      "6470/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5204\n",
      "6471/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5285\n",
      "6472/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5579\n",
      "6473/15000:\n",
      "Training Loss: 0.5367 Validation Loss: 0.5076\n",
      "6474/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.4947\n",
      "6475/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4984\n",
      "6476/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.4924\n",
      "6477/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.4942\n",
      "6478/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5077\n",
      "6479/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4978\n",
      "6480/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.4982\n",
      "6481/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.4994\n",
      "6482/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5276\n",
      "6483/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5011\n",
      "6484/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5046\n",
      "6485/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5001\n",
      "6486/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5007\n",
      "6487/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5268\n",
      "6488/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5115\n",
      "6489/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5091\n",
      "6490/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5034\n",
      "6491/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5111\n",
      "6492/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5000\n",
      "6493/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5003\n",
      "6494/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5035\n",
      "6495/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.4946\n",
      "6496/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5065\n",
      "6497/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.4932\n",
      "6498/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4972\n",
      "6499/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4969\n",
      "6500/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4954\n",
      "6501/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.4948\n",
      "6502/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4950\n",
      "6503/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4957\n",
      "6504/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4904\n",
      "6505/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4901\n",
      "6506/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.4957\n",
      "6507/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4930\n",
      "6508/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.4936\n",
      "6509/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4996\n",
      "6510/15000:\n",
      "Training Loss: 0.4628 Validation Loss: 0.5051\n",
      "6511/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5098\n",
      "6512/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5080\n",
      "6513/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5307\n",
      "6514/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5147\n",
      "6515/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5017\n",
      "6516/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5206\n",
      "6517/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5410\n",
      "6518/15000:\n",
      "Training Loss: 0.5313 Validation Loss: 0.6026\n",
      "6519/15000:\n",
      "Training Loss: 0.6171 Validation Loss: 0.5291\n",
      "6520/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5167\n",
      "6521/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5126\n",
      "6522/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5002\n",
      "6523/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5005\n",
      "6524/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5023\n",
      "6525/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5207\n",
      "6526/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5144\n",
      "6527/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5051\n",
      "6528/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5043\n",
      "6529/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5096\n",
      "6530/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5201\n",
      "6531/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5010\n",
      "6532/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5005\n",
      "6533/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5001\n",
      "6534/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.4988\n",
      "6535/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.4954\n",
      "6536/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4960\n",
      "6537/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5030\n",
      "6538/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5031\n",
      "6539/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.4977\n",
      "6540/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5036\n",
      "6541/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5035\n",
      "6542/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.4989\n",
      "6543/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4966\n",
      "6544/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.4965\n",
      "6545/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4980\n",
      "6546/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5059\n",
      "6547/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4999\n",
      "6548/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5043\n",
      "6549/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.4991\n",
      "6550/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.4958\n",
      "6551/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.4914\n",
      "6552/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5039\n",
      "6553/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5234\n",
      "6554/15000:\n",
      "Training Loss: 0.5240 Validation Loss: 0.5320\n",
      "6555/15000:\n",
      "Training Loss: 0.5177 Validation Loss: 0.5200\n",
      "6556/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5036\n",
      "6557/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5019\n",
      "6558/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.4993\n",
      "6559/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.5065\n",
      "6560/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4995\n",
      "6561/15000:\n",
      "Training Loss: 0.4699 Validation Loss: 0.4946\n",
      "6562/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5024\n",
      "6563/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.4957\n",
      "6564/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.4955\n",
      "6565/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5019\n",
      "6566/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5017\n",
      "6567/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5111\n",
      "6568/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5195\n",
      "6569/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5124\n",
      "6570/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5037\n",
      "6571/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5276\n",
      "6572/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5255\n",
      "6573/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5114\n",
      "6574/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5065\n",
      "6575/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5000\n",
      "6576/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5022\n",
      "6577/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5068\n",
      "6578/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5443\n",
      "6579/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5176\n",
      "6580/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5087\n",
      "6581/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5042\n",
      "6582/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5037\n",
      "6583/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5034\n",
      "6584/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5037\n",
      "6585/15000:\n",
      "Training Loss: 0.4710 Validation Loss: 0.5066\n",
      "6586/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5081\n",
      "6587/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5052\n",
      "6588/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5064\n",
      "6589/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5285\n",
      "6590/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5047\n",
      "6591/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5030\n",
      "6592/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.4966\n",
      "6593/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5050\n",
      "6594/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5117\n",
      "6595/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5169\n",
      "6596/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5017\n",
      "6597/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5107\n",
      "6598/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5012\n",
      "6599/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5038\n",
      "6600/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5045\n",
      "6601/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5104\n",
      "6602/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5052\n",
      "6603/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5067\n",
      "6604/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5252\n",
      "6605/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.5054\n",
      "6606/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5036\n",
      "6607/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.4967\n",
      "6608/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4962\n",
      "6609/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4993\n",
      "6610/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5189\n",
      "6611/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5077\n",
      "6612/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4987\n",
      "6613/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4969\n",
      "6614/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4944\n",
      "6615/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4997\n",
      "6616/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4944\n",
      "6617/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5088\n",
      "6618/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5478\n",
      "6619/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.5464\n",
      "6620/15000:\n",
      "Training Loss: 0.5772 Validation Loss: 0.5178\n",
      "6621/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5165\n",
      "6622/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.4992\n",
      "6623/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5008\n",
      "6624/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.4906\n",
      "6625/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.4974\n",
      "6626/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.4965\n",
      "6627/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5015\n",
      "6628/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5147\n",
      "6629/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.5076\n",
      "6630/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.4978\n",
      "6631/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5135\n",
      "6632/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5270\n",
      "6633/15000:\n",
      "Training Loss: 0.5370 Validation Loss: 0.5485\n",
      "6634/15000:\n",
      "Training Loss: 0.5463 Validation Loss: 0.5222\n",
      "6635/15000:\n",
      "Training Loss: 0.5249 Validation Loss: 0.5311\n",
      "6636/15000:\n",
      "Training Loss: 0.5377 Validation Loss: 0.5152\n",
      "6637/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5155\n",
      "6638/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5058\n",
      "6639/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5153\n",
      "6640/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5039\n",
      "6641/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5196\n",
      "6642/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5156\n",
      "6643/15000:\n",
      "Training Loss: 0.5255 Validation Loss: 0.5132\n",
      "6644/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5075\n",
      "6645/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5095\n",
      "6646/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5006\n",
      "6647/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5016\n",
      "6648/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5047\n",
      "6649/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4983\n",
      "6650/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4990\n",
      "6651/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5027\n",
      "6652/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4982\n",
      "6653/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5081\n",
      "6654/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4983\n",
      "6655/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.4939\n",
      "6656/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5054\n",
      "6657/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5023\n",
      "6658/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4988\n",
      "6659/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5008\n",
      "6660/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5028\n",
      "6661/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5199\n",
      "6662/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5039\n",
      "6663/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5020\n",
      "6664/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5144\n",
      "6665/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5624\n",
      "6666/15000:\n",
      "Training Loss: 0.5498 Validation Loss: 0.5234\n",
      "6667/15000:\n",
      "Training Loss: 0.5289 Validation Loss: 0.5418\n",
      "6668/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5163\n",
      "6669/15000:\n",
      "Training Loss: 0.5206 Validation Loss: 0.5056\n",
      "6670/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5010\n",
      "6671/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5050\n",
      "6672/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5058\n",
      "6673/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5056\n",
      "6674/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5044\n",
      "6675/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5089\n",
      "6676/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5068\n",
      "6677/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5042\n",
      "6678/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4990\n",
      "6679/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4921\n",
      "6680/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.4981\n",
      "6681/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5124\n",
      "6682/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4948\n",
      "6683/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5014\n",
      "6684/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5012\n",
      "6685/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4941\n",
      "6686/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4992\n",
      "6687/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4964\n",
      "6688/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4993\n",
      "6689/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4958\n",
      "6690/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5040\n",
      "6691/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5094\n",
      "6692/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5045\n",
      "6693/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5107\n",
      "6694/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5030\n",
      "6695/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5052\n",
      "6696/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5027\n",
      "6697/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4974\n",
      "6698/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5057\n",
      "6699/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5004\n",
      "6700/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5137\n",
      "6701/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5143\n",
      "6702/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5115\n",
      "6703/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5172\n",
      "6704/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5242\n",
      "6705/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5219\n",
      "6706/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5036\n",
      "6707/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4980\n",
      "6708/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5165\n",
      "6709/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5280\n",
      "6710/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5074\n",
      "6711/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5010\n",
      "6712/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4950\n",
      "6713/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4976\n",
      "6714/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4941\n",
      "6715/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4960\n",
      "6716/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5043\n",
      "6717/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5013\n",
      "6718/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5046\n",
      "6719/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4935\n",
      "6720/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5058\n",
      "6721/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5098\n",
      "6722/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5066\n",
      "6723/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5014\n",
      "6724/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5137\n",
      "6725/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5070\n",
      "6726/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.4944\n",
      "6727/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4988\n",
      "6728/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5119\n",
      "6729/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5309\n",
      "6730/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5322\n",
      "6731/15000:\n",
      "Training Loss: 0.5487 Validation Loss: 0.5531\n",
      "6732/15000:\n",
      "Training Loss: 0.5265 Validation Loss: 0.5023\n",
      "6733/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5031\n",
      "6734/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5008\n",
      "6735/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5031\n",
      "6736/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5055\n",
      "6737/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5019\n",
      "6738/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4965\n",
      "6739/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4965\n",
      "6740/15000:\n",
      "Training Loss: 0.4700 Validation Loss: 0.5129\n",
      "6741/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5080\n",
      "6742/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5057\n",
      "6743/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5101\n",
      "6744/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5124\n",
      "6745/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5694\n",
      "6746/15000:\n",
      "Training Loss: 0.5535 Validation Loss: 0.6095\n",
      "6747/15000:\n",
      "Training Loss: 0.6415 Validation Loss: 0.5205\n",
      "6748/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5040\n",
      "6749/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5064\n",
      "6750/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5038\n",
      "6751/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5062\n",
      "6752/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4985\n",
      "6753/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4973\n",
      "6754/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5047\n",
      "6755/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5152\n",
      "6756/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.5117\n",
      "6757/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.4965\n",
      "6758/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4984\n",
      "6759/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5010\n",
      "6760/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5064\n",
      "6761/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5049\n",
      "6762/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5020\n",
      "6763/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4990\n",
      "6764/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5003\n",
      "6765/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5021\n",
      "6766/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5056\n",
      "6767/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5050\n",
      "6768/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5077\n",
      "6769/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5023\n",
      "6770/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5057\n",
      "6771/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5037\n",
      "6772/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4991\n",
      "6773/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5061\n",
      "6774/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5079\n",
      "6775/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5094\n",
      "6776/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5025\n",
      "6777/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5099\n",
      "6778/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5310\n",
      "6779/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5724\n",
      "6780/15000:\n",
      "Training Loss: 0.5803 Validation Loss: 0.5028\n",
      "6781/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5074\n",
      "6782/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4967\n",
      "6783/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5070\n",
      "6784/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5016\n",
      "6785/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5022\n",
      "6786/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5003\n",
      "6787/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5059\n",
      "6788/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5170\n",
      "6789/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5018\n",
      "6790/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5134\n",
      "6791/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5013\n",
      "6792/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5090\n",
      "6793/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4962\n",
      "6794/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4963\n",
      "6795/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5027\n",
      "6796/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5021\n",
      "6797/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5193\n",
      "6798/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5103\n",
      "6799/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5247\n",
      "6800/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5004\n",
      "6801/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5058\n",
      "6802/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5111\n",
      "6803/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5025\n",
      "6804/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4998\n",
      "6805/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.4935\n",
      "6806/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.4995\n",
      "6807/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5120\n",
      "6808/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5192\n",
      "6809/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5336\n",
      "6810/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5014\n",
      "6811/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4978\n",
      "6812/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5049\n",
      "6813/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5025\n",
      "6814/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4998\n",
      "6815/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5060\n",
      "6816/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5123\n",
      "6817/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.4970\n",
      "6818/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4948\n",
      "6819/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.4958\n",
      "6820/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5018\n",
      "6821/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5039\n",
      "6822/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5097\n",
      "6823/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5003\n",
      "6824/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5130\n",
      "6825/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5119\n",
      "6826/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5141\n",
      "6827/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5316\n",
      "6828/15000:\n",
      "Training Loss: 0.5301 Validation Loss: 0.5086\n",
      "6829/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.4976\n",
      "6830/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5016\n",
      "6831/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.4989\n",
      "6832/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4964\n",
      "6833/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.4953\n",
      "6834/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4956\n",
      "6835/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4978\n",
      "6836/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4990\n",
      "6837/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4956\n",
      "6838/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5033\n",
      "6839/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.4930\n",
      "6840/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4953\n",
      "6841/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4961\n",
      "6842/15000:\n",
      "Training Loss: 0.4707 Validation Loss: 0.4962\n",
      "6843/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4977\n",
      "6844/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.4974\n",
      "6845/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5045\n",
      "6846/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5341\n",
      "6847/15000:\n",
      "Training Loss: 0.5275 Validation Loss: 0.5100\n",
      "6848/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5016\n",
      "6849/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5024\n",
      "6850/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5159\n",
      "6851/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.4975\n",
      "6852/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4993\n",
      "6853/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.4976\n",
      "6854/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4966\n",
      "6855/15000:\n",
      "Training Loss: 0.4714 Validation Loss: 0.5023\n",
      "6856/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5052\n",
      "6857/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5146\n",
      "6858/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5458\n",
      "6859/15000:\n",
      "Training Loss: 0.5224 Validation Loss: 0.5221\n",
      "6860/15000:\n",
      "Training Loss: 0.5303 Validation Loss: 0.5089\n",
      "6861/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5084\n",
      "6862/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5120\n",
      "6863/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5077\n",
      "6864/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5137\n",
      "6865/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5029\n",
      "6866/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5033\n",
      "6867/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5234\n",
      "6868/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5196\n",
      "6869/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5138\n",
      "6870/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4955\n",
      "6871/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5011\n",
      "6872/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.4966\n",
      "6873/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5106\n",
      "6874/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5170\n",
      "6875/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5300\n",
      "6876/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5606\n",
      "6877/15000:\n",
      "Training Loss: 0.5371 Validation Loss: 0.5438\n",
      "6878/15000:\n",
      "Training Loss: 0.5484 Validation Loss: 0.5051\n",
      "6879/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.4968\n",
      "6880/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5015\n",
      "6881/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5025\n",
      "6882/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4981\n",
      "6883/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4994\n",
      "6884/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5150\n",
      "6885/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5061\n",
      "6886/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5055\n",
      "6887/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5058\n",
      "6888/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5031\n",
      "6889/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5001\n",
      "6890/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5025\n",
      "6891/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5118\n",
      "6892/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5102\n",
      "6893/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5272\n",
      "6894/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5232\n",
      "6895/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5100\n",
      "6896/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5040\n",
      "6897/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5036\n",
      "6898/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5035\n",
      "6899/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5053\n",
      "6900/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5072\n",
      "6901/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5008\n",
      "6902/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5038\n",
      "6903/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5028\n",
      "6904/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5040\n",
      "6905/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4993\n",
      "6906/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4988\n",
      "6907/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5015\n",
      "6908/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5054\n",
      "6909/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5067\n",
      "6910/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4973\n",
      "6911/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5007\n",
      "6912/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5091\n",
      "6913/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5151\n",
      "6914/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5341\n",
      "6915/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5367\n",
      "6916/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5356\n",
      "6917/15000:\n",
      "Training Loss: 0.5228 Validation Loss: 0.5368\n",
      "6918/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5095\n",
      "6919/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5089\n",
      "6920/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5194\n",
      "6921/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5069\n",
      "6922/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5006\n",
      "6923/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5005\n",
      "6924/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5088\n",
      "6925/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5301\n",
      "6926/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5390\n",
      "6927/15000:\n",
      "Training Loss: 0.5496 Validation Loss: 0.5118\n",
      "6928/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4993\n",
      "6929/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5051\n",
      "6930/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5010\n",
      "6931/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5024\n",
      "6932/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4994\n",
      "6933/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5119\n",
      "6934/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5075\n",
      "6935/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5079\n",
      "6936/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5071\n",
      "6937/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5036\n",
      "6938/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5063\n",
      "6939/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5082\n",
      "6940/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5133\n",
      "6941/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5049\n",
      "6942/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5134\n",
      "6943/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.5053\n",
      "6944/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5152\n",
      "6945/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5074\n",
      "6946/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5052\n",
      "6947/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5131\n",
      "6948/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5132\n",
      "6949/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5083\n",
      "6950/15000:\n",
      "Training Loss: 0.4646 Validation Loss: 0.5044\n",
      "6951/15000:\n",
      "Training Loss: 0.4708 Validation Loss: 0.5087\n",
      "6952/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5335\n",
      "6953/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5186\n",
      "6954/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5113\n",
      "6955/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5074\n",
      "6956/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5052\n",
      "6957/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4978\n",
      "6958/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5060\n",
      "6959/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4965\n",
      "6960/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5055\n",
      "6961/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5006\n",
      "6962/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5017\n",
      "6963/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4992\n",
      "6964/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5021\n",
      "6965/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5035\n",
      "6966/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5081\n",
      "6967/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5164\n",
      "6968/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5081\n",
      "6969/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5088\n",
      "6970/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5340\n",
      "6971/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5053\n",
      "6972/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5097\n",
      "6973/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5018\n",
      "6974/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.4915\n",
      "6975/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4954\n",
      "6976/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4947\n",
      "6977/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5014\n",
      "6978/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.4950\n",
      "6979/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4989\n",
      "6980/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5013\n",
      "6981/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5221\n",
      "6982/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5021\n",
      "6983/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5150\n",
      "6984/15000:\n",
      "Training Loss: 0.5227 Validation Loss: 0.5231\n",
      "6985/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.6072\n",
      "6986/15000:\n",
      "Training Loss: 0.5740 Validation Loss: 0.5075\n",
      "6987/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5141\n",
      "6988/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5000\n",
      "6989/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5064\n",
      "6990/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4957\n",
      "6991/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4971\n",
      "6992/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5075\n",
      "6993/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5009\n",
      "6994/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5014\n",
      "6995/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5006\n",
      "6996/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.4972\n",
      "6997/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5106\n",
      "6998/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5080\n",
      "6999/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5118\n",
      "7000/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5122\n",
      "7001/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5095\n",
      "7002/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5060\n",
      "7003/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5038\n",
      "7004/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5021\n",
      "7005/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.5022\n",
      "7006/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5079\n",
      "7007/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5114\n",
      "7008/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5064\n",
      "7009/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.4993\n",
      "7010/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5019\n",
      "7011/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4954\n",
      "7012/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5035\n",
      "7013/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5083\n",
      "7014/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5138\n",
      "7015/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5063\n",
      "7016/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5035\n",
      "7017/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5068\n",
      "7018/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5052\n",
      "7019/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5009\n",
      "7020/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5041\n",
      "7021/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5094\n",
      "7022/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.4984\n",
      "7023/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5008\n",
      "7024/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5074\n",
      "7025/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5046\n",
      "7026/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5114\n",
      "7027/15000:\n",
      "Training Loss: 0.4683 Validation Loss: 0.5102\n",
      "7028/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5010\n",
      "7029/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4962\n",
      "7030/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5138\n",
      "7031/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5030\n",
      "7032/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5144\n",
      "7033/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5279\n",
      "7034/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5072\n",
      "7035/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5146\n",
      "7036/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5055\n",
      "7037/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5032\n",
      "7038/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4928\n",
      "7039/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5046\n",
      "7040/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5035\n",
      "7041/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5027\n",
      "7042/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4965\n",
      "7043/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.4937\n",
      "7044/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5016\n",
      "7045/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5003\n",
      "7046/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5007\n",
      "7047/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5100\n",
      "7048/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5154\n",
      "7049/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.4996\n",
      "7050/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5163\n",
      "7051/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4958\n",
      "7052/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5012\n",
      "7053/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.4990\n",
      "7054/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.4989\n",
      "7055/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5007\n",
      "7056/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4987\n",
      "7057/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5128\n",
      "7058/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5080\n",
      "7059/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5105\n",
      "7060/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5126\n",
      "7061/15000:\n",
      "Training Loss: 0.5335 Validation Loss: 0.5056\n",
      "7062/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5144\n",
      "7063/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5015\n",
      "7064/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.4953\n",
      "7065/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.5089\n",
      "7066/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5139\n",
      "7067/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5040\n",
      "7068/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5029\n",
      "7069/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5118\n",
      "7070/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5585\n",
      "7071/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5046\n",
      "7072/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5015\n",
      "7073/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5028\n",
      "7074/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5136\n",
      "7075/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.4995\n",
      "7076/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4943\n",
      "7077/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5019\n",
      "7078/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4965\n",
      "7079/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5105\n",
      "7080/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5219\n",
      "7081/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5234\n",
      "7082/15000:\n",
      "Training Loss: 0.5177 Validation Loss: 0.5077\n",
      "7083/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5094\n",
      "7084/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5103\n",
      "7085/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5033\n",
      "7086/15000:\n",
      "Training Loss: 0.4687 Validation Loss: 0.5018\n",
      "7087/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.4943\n",
      "7088/15000:\n",
      "Training Loss: 0.4689 Validation Loss: 0.5002\n",
      "7089/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5022\n",
      "7090/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5006\n",
      "7091/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5030\n",
      "7092/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5007\n",
      "7093/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5044\n",
      "7094/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5216\n",
      "7095/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5093\n",
      "7096/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5075\n",
      "7097/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5061\n",
      "7098/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5328\n",
      "7099/15000:\n",
      "Training Loss: 0.5135 Validation Loss: 0.4976\n",
      "7100/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5108\n",
      "7101/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5063\n",
      "7102/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5005\n",
      "7103/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.4968\n",
      "7104/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5119\n",
      "7105/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5464\n",
      "7106/15000:\n",
      "Training Loss: 0.5361 Validation Loss: 0.5318\n",
      "7107/15000:\n",
      "Training Loss: 0.5349 Validation Loss: 0.5203\n",
      "7108/15000:\n",
      "Training Loss: 0.5262 Validation Loss: 0.5053\n",
      "7109/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5019\n",
      "7110/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.4971\n",
      "7111/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5024\n",
      "7112/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4955\n",
      "7113/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4956\n",
      "7114/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4978\n",
      "7115/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4985\n",
      "7116/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4954\n",
      "7117/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.4980\n",
      "7118/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4951\n",
      "7119/15000:\n",
      "Training Loss: 0.4701 Validation Loss: 0.4994\n",
      "7120/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5366\n",
      "7121/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.4961\n",
      "7122/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5015\n",
      "7123/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5004\n",
      "7124/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5126\n",
      "7125/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5033\n",
      "7126/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4993\n",
      "7127/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5091\n",
      "7128/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5069\n",
      "7129/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5069\n",
      "7130/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5059\n",
      "7131/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5166\n",
      "7132/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5127\n",
      "7133/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5073\n",
      "7134/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5053\n",
      "7135/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.4977\n",
      "7136/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5013\n",
      "7137/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.4999\n",
      "7138/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.5045\n",
      "7139/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5197\n",
      "7140/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5714\n",
      "7141/15000:\n",
      "Training Loss: 0.5312 Validation Loss: 0.5134\n",
      "7142/15000:\n",
      "Training Loss: 0.5250 Validation Loss: 0.5236\n",
      "7143/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5464\n",
      "7144/15000:\n",
      "Training Loss: 0.5304 Validation Loss: 0.5234\n",
      "7145/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5015\n",
      "7146/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5026\n",
      "7147/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5030\n",
      "7148/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5022\n",
      "7149/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5014\n",
      "7150/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5107\n",
      "7151/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5096\n",
      "7152/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5022\n",
      "7153/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5028\n",
      "7154/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5104\n",
      "7155/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5050\n",
      "7156/15000:\n",
      "Training Loss: 0.4719 Validation Loss: 0.4992\n",
      "7157/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5044\n",
      "7158/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.4988\n",
      "7159/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5015\n",
      "7160/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5061\n",
      "7161/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5049\n",
      "7162/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5055\n",
      "7163/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.4968\n",
      "7164/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5039\n",
      "7165/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5041\n",
      "7166/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5111\n",
      "7167/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5138\n",
      "7168/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5176\n",
      "7169/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5207\n",
      "7170/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5017\n",
      "7171/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4999\n",
      "7172/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5076\n",
      "7173/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5059\n",
      "7174/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5086\n",
      "7175/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5024\n",
      "7176/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5241\n",
      "7177/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5266\n",
      "7178/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5341\n",
      "7179/15000:\n",
      "Training Loss: 0.5266 Validation Loss: 0.5254\n",
      "7180/15000:\n",
      "Training Loss: 0.5271 Validation Loss: 0.5416\n",
      "7181/15000:\n",
      "Training Loss: 0.5509 Validation Loss: 0.5488\n",
      "7182/15000:\n",
      "Training Loss: 0.5503 Validation Loss: 0.5278\n",
      "7183/15000:\n",
      "Training Loss: 0.5323 Validation Loss: 0.5237\n",
      "7184/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5062\n",
      "7185/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5025\n",
      "7186/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5007\n",
      "7187/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4951\n",
      "7188/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5001\n",
      "7189/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5065\n",
      "7190/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5064\n",
      "7191/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5029\n",
      "7192/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5022\n",
      "7193/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5015\n",
      "7194/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5070\n",
      "7195/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5069\n",
      "7196/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5002\n",
      "7197/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4955\n",
      "7198/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5002\n",
      "7199/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5110\n",
      "7200/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.4963\n",
      "7201/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5025\n",
      "7202/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5053\n",
      "7203/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5142\n",
      "7204/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5080\n",
      "7205/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5211\n",
      "7206/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5121\n",
      "7207/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5158\n",
      "7208/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5064\n",
      "7209/15000:\n",
      "Training Loss: 0.4718 Validation Loss: 0.5046\n",
      "7210/15000:\n",
      "Training Loss: 0.4689 Validation Loss: 0.5073\n",
      "7211/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5090\n",
      "7212/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4977\n",
      "7213/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5039\n",
      "7214/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5039\n",
      "7215/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5027\n",
      "7216/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5129\n",
      "7217/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5088\n",
      "7218/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5050\n",
      "7219/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5123\n",
      "7220/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5039\n",
      "7221/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5177\n",
      "7222/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5124\n",
      "7223/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5088\n",
      "7224/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5106\n",
      "7225/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5131\n",
      "7226/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5230\n",
      "7227/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5037\n",
      "7228/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5133\n",
      "7229/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5042\n",
      "7230/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5034\n",
      "7231/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5045\n",
      "7232/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5052\n",
      "7233/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5030\n",
      "7234/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5107\n",
      "7235/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5291\n",
      "7236/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5554\n",
      "7237/15000:\n",
      "Training Loss: 0.5341 Validation Loss: 0.5075\n",
      "7238/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5017\n",
      "7239/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5035\n",
      "7240/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5022\n",
      "7241/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5051\n",
      "7242/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5069\n",
      "7243/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5043\n",
      "7244/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5080\n",
      "7245/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5008\n",
      "7246/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5017\n",
      "7247/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5077\n",
      "7248/15000:\n",
      "Training Loss: 0.4674 Validation Loss: 0.5187\n",
      "7249/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5061\n",
      "7250/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5114\n",
      "7251/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5173\n",
      "7252/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5191\n",
      "7253/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5153\n",
      "7254/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5165\n",
      "7255/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5120\n",
      "7256/15000:\n",
      "Training Loss: 0.5212 Validation Loss: 0.5185\n",
      "7257/15000:\n",
      "Training Loss: 0.5263 Validation Loss: 0.5030\n",
      "7258/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5060\n",
      "7259/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.4991\n",
      "7260/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5061\n",
      "7261/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5066\n",
      "7262/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5106\n",
      "7263/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.4954\n",
      "7264/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4988\n",
      "7265/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5000\n",
      "7266/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5009\n",
      "7267/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4963\n",
      "7268/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.4979\n",
      "7269/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5009\n",
      "7270/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5007\n",
      "7271/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5010\n",
      "7272/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5044\n",
      "7273/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.4995\n",
      "7274/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4962\n",
      "7275/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5011\n",
      "7276/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.4961\n",
      "7277/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4973\n",
      "7278/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.4980\n",
      "7279/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.4993\n",
      "7280/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5166\n",
      "7281/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.4986\n",
      "7282/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5044\n",
      "7283/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5048\n",
      "7284/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5062\n",
      "7285/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5074\n",
      "7286/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5070\n",
      "7287/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.5000\n",
      "7288/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5064\n",
      "7289/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5200\n",
      "7290/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.4994\n",
      "7291/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4975\n",
      "7292/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4937\n",
      "7293/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5001\n",
      "7294/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.4977\n",
      "7295/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4986\n",
      "7296/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5098\n",
      "7297/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5220\n",
      "7298/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5059\n",
      "7299/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4970\n",
      "7300/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5041\n",
      "7301/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5061\n",
      "7302/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5028\n",
      "7303/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5092\n",
      "7304/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5042\n",
      "7305/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5004\n",
      "7306/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5016\n",
      "7307/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.5069\n",
      "7308/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5013\n",
      "7309/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.4990\n",
      "7310/15000:\n",
      "Training Loss: 0.4696 Validation Loss: 0.5040\n",
      "7311/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4972\n",
      "7312/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5025\n",
      "7313/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5080\n",
      "7314/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5119\n",
      "7315/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5099\n",
      "7316/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5019\n",
      "7317/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5110\n",
      "7318/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5305\n",
      "7319/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5832\n",
      "7320/15000:\n",
      "Training Loss: 0.5409 Validation Loss: 0.5415\n",
      "7321/15000:\n",
      "Training Loss: 0.5703 Validation Loss: 0.5155\n",
      "7322/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5017\n",
      "7323/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5009\n",
      "7324/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5054\n",
      "7325/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5012\n",
      "7326/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.5029\n",
      "7327/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.4987\n",
      "7328/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.4981\n",
      "7329/15000:\n",
      "Training Loss: 0.4649 Validation Loss: 0.5013\n",
      "7330/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4955\n",
      "7331/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5022\n",
      "7332/15000:\n",
      "Training Loss: 0.4722 Validation Loss: 0.5017\n",
      "7333/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5070\n",
      "7334/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5213\n",
      "7335/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5224\n",
      "7336/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5101\n",
      "7337/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5046\n",
      "7338/15000:\n",
      "Training Loss: 0.4650 Validation Loss: 0.5059\n",
      "7339/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5177\n",
      "7340/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5005\n",
      "7341/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5170\n",
      "7342/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5091\n",
      "7343/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5091\n",
      "7344/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5089\n",
      "7345/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5042\n",
      "7346/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5042\n",
      "7347/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5026\n",
      "7348/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.4992\n",
      "7349/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.4976\n",
      "7350/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5030\n",
      "7351/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.4986\n",
      "7352/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4997\n",
      "7353/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.4981\n",
      "7354/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5178\n",
      "7355/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5077\n",
      "7356/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5147\n",
      "7357/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5191\n",
      "7358/15000:\n",
      "Training Loss: 0.5206 Validation Loss: 0.5386\n",
      "7359/15000:\n",
      "Training Loss: 0.5416 Validation Loss: 0.5433\n",
      "7360/15000:\n",
      "Training Loss: 0.5276 Validation Loss: 0.4991\n",
      "7361/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5056\n",
      "7362/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5045\n",
      "7363/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.4999\n",
      "7364/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4953\n",
      "7365/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5045\n",
      "7366/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5052\n",
      "7367/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5030\n",
      "7368/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5102\n",
      "7369/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5046\n",
      "7370/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5092\n",
      "7371/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5044\n",
      "7372/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5089\n",
      "7373/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.4979\n",
      "7374/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.4965\n",
      "7375/15000:\n",
      "Training Loss: 0.4673 Validation Loss: 0.5083\n",
      "7376/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5022\n",
      "7377/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4995\n",
      "7378/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5032\n",
      "7379/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5153\n",
      "7380/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5202\n",
      "7381/15000:\n",
      "Training Loss: 0.5185 Validation Loss: 0.5113\n",
      "7382/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5013\n",
      "7383/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.4986\n",
      "7384/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5082\n",
      "7385/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5083\n",
      "7386/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5508\n",
      "7387/15000:\n",
      "Training Loss: 0.5337 Validation Loss: 0.6457\n",
      "7388/15000:\n",
      "Training Loss: 0.6612 Validation Loss: 0.5327\n",
      "7389/15000:\n",
      "Training Loss: 0.5352 Validation Loss: 0.4997\n",
      "7390/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5035\n",
      "7391/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5118\n",
      "7392/15000:\n",
      "Training Loss: 0.5295 Validation Loss: 0.5155\n",
      "7393/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.4965\n",
      "7394/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5063\n",
      "7395/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.4966\n",
      "7396/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5064\n",
      "7397/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5038\n",
      "7398/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4992\n",
      "7399/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5085\n",
      "7400/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5053\n",
      "7401/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5030\n",
      "7402/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4975\n",
      "7403/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.4993\n",
      "7404/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.4969\n",
      "7405/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4993\n",
      "7406/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5009\n",
      "7407/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5120\n",
      "7408/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5185\n",
      "7409/15000:\n",
      "Training Loss: 0.5275 Validation Loss: 0.5044\n",
      "7410/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5091\n",
      "7411/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5106\n",
      "7412/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5122\n",
      "7413/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5086\n",
      "7414/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5096\n",
      "7415/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5089\n",
      "7416/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.5076\n",
      "7417/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5045\n",
      "7418/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5100\n",
      "7419/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5064\n",
      "7420/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5179\n",
      "7421/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5216\n",
      "7422/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5226\n",
      "7423/15000:\n",
      "Training Loss: 0.5127 Validation Loss: 0.5139\n",
      "7424/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5136\n",
      "7425/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5012\n",
      "7426/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4974\n",
      "7427/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5066\n",
      "7428/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5040\n",
      "7429/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5037\n",
      "7430/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5030\n",
      "7431/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4947\n",
      "7432/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4954\n",
      "7433/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5035\n",
      "7434/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5006\n",
      "7435/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5018\n",
      "7436/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5160\n",
      "7437/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5016\n",
      "7438/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5198\n",
      "7439/15000:\n",
      "Training Loss: 0.5187 Validation Loss: 0.5283\n",
      "7440/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5002\n",
      "7441/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5115\n",
      "7442/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5063\n",
      "7443/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5056\n",
      "7444/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5036\n",
      "7445/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5127\n",
      "7446/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5094\n",
      "7447/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5152\n",
      "7448/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5093\n",
      "7449/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5073\n",
      "7450/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5022\n",
      "7451/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5119\n",
      "7452/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5134\n",
      "7453/15000:\n",
      "Training Loss: 0.4613 Validation Loss: 0.5098\n",
      "7454/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5056\n",
      "7455/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5022\n",
      "7456/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5107\n",
      "7457/15000:\n",
      "Training Loss: 0.4707 Validation Loss: 0.5035\n",
      "7458/15000:\n",
      "Training Loss: 0.4748 Validation Loss: 0.5066\n",
      "7459/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5020\n",
      "7460/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5016\n",
      "7461/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5164\n",
      "7462/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5002\n",
      "7463/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5034\n",
      "7464/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5021\n",
      "7465/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.4965\n",
      "7466/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.4991\n",
      "7467/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5177\n",
      "7468/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5090\n",
      "7469/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5089\n",
      "7470/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5084\n",
      "7471/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4968\n",
      "7472/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.4980\n",
      "7473/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5071\n",
      "7474/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5310\n",
      "7475/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.5073\n",
      "7476/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5113\n",
      "7477/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4986\n",
      "7478/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5020\n",
      "7479/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5176\n",
      "7480/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5013\n",
      "7481/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5056\n",
      "7482/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5046\n",
      "7483/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5131\n",
      "7484/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5306\n",
      "7485/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5144\n",
      "7486/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5072\n",
      "7487/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5008\n",
      "7488/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5048\n",
      "7489/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5102\n",
      "7490/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5045\n",
      "7491/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5078\n",
      "7492/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5027\n",
      "7493/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5104\n",
      "7494/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5016\n",
      "7495/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5010\n",
      "7496/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.4994\n",
      "7497/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5030\n",
      "7498/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5076\n",
      "7499/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5138\n",
      "7500/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5103\n",
      "7501/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5054\n",
      "7502/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5001\n",
      "7503/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5168\n",
      "7504/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5119\n",
      "7505/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5225\n",
      "7506/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5036\n",
      "7507/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5037\n",
      "7508/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5030\n",
      "7509/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4954\n",
      "7510/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5005\n",
      "7511/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4999\n",
      "7512/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5098\n",
      "7513/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4994\n",
      "7514/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5168\n",
      "7515/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5343\n",
      "7516/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5378\n",
      "7517/15000:\n",
      "Training Loss: 0.5298 Validation Loss: 0.5035\n",
      "7518/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5030\n",
      "7519/15000:\n",
      "Training Loss: 0.4690 Validation Loss: 0.5100\n",
      "7520/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4989\n",
      "7521/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5084\n",
      "7522/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5158\n",
      "7523/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5032\n",
      "7524/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5069\n",
      "7525/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5026\n",
      "7526/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4999\n",
      "7527/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5078\n",
      "7528/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5043\n",
      "7529/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5130\n",
      "7530/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5140\n",
      "7531/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5369\n",
      "7532/15000:\n",
      "Training Loss: 0.5265 Validation Loss: 0.5262\n",
      "7533/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5137\n",
      "7534/15000:\n",
      "Training Loss: 0.5274 Validation Loss: 0.5153\n",
      "7535/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5028\n",
      "7536/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.4990\n",
      "7537/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5022\n",
      "7538/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4995\n",
      "7539/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5041\n",
      "7540/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5062\n",
      "7541/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5030\n",
      "7542/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4971\n",
      "7543/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5137\n",
      "7544/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5333\n",
      "7545/15000:\n",
      "Training Loss: 0.5285 Validation Loss: 0.5421\n",
      "7546/15000:\n",
      "Training Loss: 0.5428 Validation Loss: 0.5288\n",
      "7547/15000:\n",
      "Training Loss: 0.5226 Validation Loss: 0.5150\n",
      "7548/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5046\n",
      "7549/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5016\n",
      "7550/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5046\n",
      "7551/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.4983\n",
      "7552/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.4964\n",
      "7553/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.4979\n",
      "7554/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5009\n",
      "7555/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5151\n",
      "7556/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5109\n",
      "7557/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5118\n",
      "7558/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5068\n",
      "7559/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5141\n",
      "7560/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5049\n",
      "7561/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5195\n",
      "7562/15000:\n",
      "Training Loss: 0.5166 Validation Loss: 0.5027\n",
      "7563/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5108\n",
      "7564/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5055\n",
      "7565/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5042\n",
      "7566/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5060\n",
      "7567/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5087\n",
      "7568/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4988\n",
      "7569/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5089\n",
      "7570/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4986\n",
      "7571/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4974\n",
      "7572/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5089\n",
      "7573/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5091\n",
      "7574/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.4994\n",
      "7575/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4968\n",
      "7576/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5114\n",
      "7577/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4967\n",
      "7578/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5145\n",
      "7579/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5089\n",
      "7580/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5190\n",
      "7581/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5106\n",
      "7582/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5062\n",
      "7583/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.4961\n",
      "7584/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5054\n",
      "7585/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5167\n",
      "7586/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5078\n",
      "7587/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5152\n",
      "7588/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.5324\n",
      "7589/15000:\n",
      "Training Loss: 0.5288 Validation Loss: 0.5142\n",
      "7590/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5023\n",
      "7591/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.4991\n",
      "7592/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5073\n",
      "7593/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5041\n",
      "7594/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5029\n",
      "7595/15000:\n",
      "Training Loss: 0.4692 Validation Loss: 0.5048\n",
      "7596/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5054\n",
      "7597/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5021\n",
      "7598/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5005\n",
      "7599/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5069\n",
      "7600/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5003\n",
      "7601/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5105\n",
      "7602/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5126\n",
      "7603/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5049\n",
      "7604/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5204\n",
      "7605/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5112\n",
      "7606/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5218\n",
      "7607/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5051\n",
      "7608/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5143\n",
      "7609/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5129\n",
      "7610/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5339\n",
      "7611/15000:\n",
      "Training Loss: 0.5405 Validation Loss: 0.5029\n",
      "7612/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.4982\n",
      "7613/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5119\n",
      "7614/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5003\n",
      "7615/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5065\n",
      "7616/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5069\n",
      "7617/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5011\n",
      "7618/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5042\n",
      "7619/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5042\n",
      "7620/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5048\n",
      "7621/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5102\n",
      "7622/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5170\n",
      "7623/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5009\n",
      "7624/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5027\n",
      "7625/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5097\n",
      "7626/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5136\n",
      "7627/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4974\n",
      "7628/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5035\n",
      "7629/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5002\n",
      "7630/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.4973\n",
      "7631/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5065\n",
      "7632/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5198\n",
      "7633/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5201\n",
      "7634/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5107\n",
      "7635/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5059\n",
      "7636/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5019\n",
      "7637/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.4964\n",
      "7638/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5093\n",
      "7639/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5118\n",
      "7640/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5033\n",
      "7641/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5069\n",
      "7642/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5037\n",
      "7643/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5040\n",
      "7644/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5125\n",
      "7645/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5022\n",
      "7646/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5132\n",
      "7647/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5105\n",
      "7648/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5114\n",
      "7649/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5242\n",
      "7650/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5349\n",
      "7651/15000:\n",
      "Training Loss: 0.5301 Validation Loss: 0.5235\n",
      "7652/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5024\n",
      "7653/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5036\n",
      "7654/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5118\n",
      "7655/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4953\n",
      "7656/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5055\n",
      "7657/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5260\n",
      "7658/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5269\n",
      "7659/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4983\n",
      "7660/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5147\n",
      "7661/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4967\n",
      "7662/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5087\n",
      "7663/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5074\n",
      "7664/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5005\n",
      "7665/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5218\n",
      "7666/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5086\n",
      "7667/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5068\n",
      "7668/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5074\n",
      "7669/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5033\n",
      "7670/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5047\n",
      "7671/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5089\n",
      "7672/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5112\n",
      "7673/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5052\n",
      "7674/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5079\n",
      "7675/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5053\n",
      "7676/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5119\n",
      "7677/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5040\n",
      "7678/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5033\n",
      "7679/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.4947\n",
      "7680/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4962\n",
      "7681/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5001\n",
      "7682/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5029\n",
      "7683/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5047\n",
      "7684/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.4992\n",
      "7685/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4956\n",
      "7686/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5023\n",
      "7687/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5036\n",
      "7688/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5088\n",
      "7689/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5390\n",
      "7690/15000:\n",
      "Training Loss: 0.5303 Validation Loss: 0.5798\n",
      "7691/15000:\n",
      "Training Loss: 0.5961 Validation Loss: 0.5350\n",
      "7692/15000:\n",
      "Training Loss: 0.5387 Validation Loss: 0.5122\n",
      "7693/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5214\n",
      "7694/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5036\n",
      "7695/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5116\n",
      "7696/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4962\n",
      "7697/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5017\n",
      "7698/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5076\n",
      "7699/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5007\n",
      "7700/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5142\n",
      "7701/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5037\n",
      "7702/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5082\n",
      "7703/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.4980\n",
      "7704/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4981\n",
      "7705/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.4974\n",
      "7706/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5016\n",
      "7707/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5029\n",
      "7708/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4999\n",
      "7709/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5180\n",
      "7710/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.4950\n",
      "7711/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4971\n",
      "7712/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4968\n",
      "7713/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4993\n",
      "7714/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4991\n",
      "7715/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5029\n",
      "7716/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5058\n",
      "7717/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5107\n",
      "7718/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5073\n",
      "7719/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.4980\n",
      "7720/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5035\n",
      "7721/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5023\n",
      "7722/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5139\n",
      "7723/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4979\n",
      "7724/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5075\n",
      "7725/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5042\n",
      "7726/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5087\n",
      "7727/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5008\n",
      "7728/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5112\n",
      "7729/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5100\n",
      "7730/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5136\n",
      "7731/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.5351\n",
      "7732/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.6244\n",
      "7733/15000:\n",
      "Training Loss: 0.6422 Validation Loss: 0.5272\n",
      "7734/15000:\n",
      "Training Loss: 0.5250 Validation Loss: 0.5302\n",
      "7735/15000:\n",
      "Training Loss: 0.5472 Validation Loss: 0.5113\n",
      "7736/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5082\n",
      "7737/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5064\n",
      "7738/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5035\n",
      "7739/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5060\n",
      "7740/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5113\n",
      "7741/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5069\n",
      "7742/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5048\n",
      "7743/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5115\n",
      "7744/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5051\n",
      "7745/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4992\n",
      "7746/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5004\n",
      "7747/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5080\n",
      "7748/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5083\n",
      "7749/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5086\n",
      "7750/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5107\n",
      "7751/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4976\n",
      "7752/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5014\n",
      "7753/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4963\n",
      "7754/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.4994\n",
      "7755/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5019\n",
      "7756/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4989\n",
      "7757/15000:\n",
      "Training Loss: 0.4695 Validation Loss: 0.5039\n",
      "7758/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5195\n",
      "7759/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5107\n",
      "7760/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5062\n",
      "7761/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5054\n",
      "7762/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5072\n",
      "7763/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5002\n",
      "7764/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5002\n",
      "7765/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5024\n",
      "7766/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5017\n",
      "7767/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5023\n",
      "7768/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.4996\n",
      "7769/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5088\n",
      "7770/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.4991\n",
      "7771/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5015\n",
      "7772/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5034\n",
      "7773/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.4951\n",
      "7774/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5036\n",
      "7775/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5180\n",
      "7776/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5077\n",
      "7777/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5088\n",
      "7778/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5027\n",
      "7779/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5008\n",
      "7780/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.5041\n",
      "7781/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4987\n",
      "7782/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.4990\n",
      "7783/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5006\n",
      "7784/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5070\n",
      "7785/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5154\n",
      "7786/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5040\n",
      "7787/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5031\n",
      "7788/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4996\n",
      "7789/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.4986\n",
      "7790/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5049\n",
      "7791/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4979\n",
      "7792/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5090\n",
      "7793/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5172\n",
      "7794/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5141\n",
      "7795/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.5035\n",
      "7796/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5050\n",
      "7797/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4980\n",
      "7798/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4941\n",
      "7799/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5064\n",
      "7800/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5053\n",
      "7801/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5179\n",
      "7802/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5004\n",
      "7803/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5116\n",
      "7804/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5184\n",
      "7805/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5206\n",
      "7806/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5035\n",
      "7807/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5097\n",
      "7808/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5074\n",
      "7809/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.4994\n",
      "7810/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5083\n",
      "7811/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5066\n",
      "7812/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5154\n",
      "7813/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5119\n",
      "7814/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5090\n",
      "7815/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5059\n",
      "7816/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5025\n",
      "7817/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4968\n",
      "7818/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5024\n",
      "7819/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.4941\n",
      "7820/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5074\n",
      "7821/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5091\n",
      "7822/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5199\n",
      "7823/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5092\n",
      "7824/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5081\n",
      "7825/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5026\n",
      "7826/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5046\n",
      "7827/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5068\n",
      "7828/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5067\n",
      "7829/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5083\n",
      "7830/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5075\n",
      "7831/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5129\n",
      "7832/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5143\n",
      "7833/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5039\n",
      "7834/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5051\n",
      "7835/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5144\n",
      "7836/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.4957\n",
      "7837/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5097\n",
      "7838/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5241\n",
      "7839/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5107\n",
      "7840/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5228\n",
      "7841/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5133\n",
      "7842/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5013\n",
      "7843/15000:\n",
      "Training Loss: 0.4587 Validation Loss: 0.4980\n",
      "7844/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5075\n",
      "7845/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5136\n",
      "7846/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5047\n",
      "7847/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5106\n",
      "7848/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5076\n",
      "7849/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.5239\n",
      "7850/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5219\n",
      "7851/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5501\n",
      "7852/15000:\n",
      "Training Loss: 0.5633 Validation Loss: 0.5108\n",
      "7853/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5002\n",
      "7854/15000:\n",
      "Training Loss: 0.4700 Validation Loss: 0.4978\n",
      "7855/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.4971\n",
      "7856/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.4972\n",
      "7857/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5011\n",
      "7858/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5010\n",
      "7859/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5087\n",
      "7860/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5168\n",
      "7861/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5162\n",
      "7862/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5009\n",
      "7863/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5138\n",
      "7864/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5090\n",
      "7865/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5054\n",
      "7866/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5245\n",
      "7867/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5112\n",
      "7868/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5021\n",
      "7869/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5065\n",
      "7870/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.4964\n",
      "7871/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5018\n",
      "7872/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5049\n",
      "7873/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4986\n",
      "7874/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4969\n",
      "7875/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.4961\n",
      "7876/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5012\n",
      "7877/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.4997\n",
      "7878/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4925\n",
      "7879/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5120\n",
      "7880/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5237\n",
      "7881/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5360\n",
      "7882/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5255\n",
      "7883/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5207\n",
      "7884/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5350\n",
      "7885/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5473\n",
      "7886/15000:\n",
      "Training Loss: 0.5641 Validation Loss: 0.5133\n",
      "7887/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.4997\n",
      "7888/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5051\n",
      "7889/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5068\n",
      "7890/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5022\n",
      "7891/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5084\n",
      "7892/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5042\n",
      "7893/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5010\n",
      "7894/15000:\n",
      "Training Loss: 0.4648 Validation Loss: 0.4983\n",
      "7895/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.5050\n",
      "7896/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5012\n",
      "7897/15000:\n",
      "Training Loss: 0.4719 Validation Loss: 0.5064\n",
      "7898/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5025\n",
      "7899/15000:\n",
      "Training Loss: 0.4695 Validation Loss: 0.5001\n",
      "7900/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5033\n",
      "7901/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5056\n",
      "7902/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5048\n",
      "7903/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.4988\n",
      "7904/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5070\n",
      "7905/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5065\n",
      "7906/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5213\n",
      "7907/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5183\n",
      "7908/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5144\n",
      "7909/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5286\n",
      "7910/15000:\n",
      "Training Loss: 0.5308 Validation Loss: 0.5046\n",
      "7911/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5066\n",
      "7912/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5025\n",
      "7913/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5293\n",
      "7914/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5130\n",
      "7915/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5321\n",
      "7916/15000:\n",
      "Training Loss: 0.5340 Validation Loss: 0.5258\n",
      "7917/15000:\n",
      "Training Loss: 0.5298 Validation Loss: 0.5130\n",
      "7918/15000:\n",
      "Training Loss: 0.5167 Validation Loss: 0.5003\n",
      "7919/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5057\n",
      "7920/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5034\n",
      "7921/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5010\n",
      "7922/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5073\n",
      "7923/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5059\n",
      "7924/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5028\n",
      "7925/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5048\n",
      "7926/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5045\n",
      "7927/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5082\n",
      "7928/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5021\n",
      "7929/15000:\n",
      "Training Loss: 0.4614 Validation Loss: 0.5033\n",
      "7930/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5090\n",
      "7931/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5367\n",
      "7932/15000:\n",
      "Training Loss: 0.5312 Validation Loss: 0.5343\n",
      "7933/15000:\n",
      "Training Loss: 0.5305 Validation Loss: 0.5216\n",
      "7934/15000:\n",
      "Training Loss: 0.5230 Validation Loss: 0.5846\n",
      "7935/15000:\n",
      "Training Loss: 0.5566 Validation Loss: 0.5157\n",
      "7936/15000:\n",
      "Training Loss: 0.5283 Validation Loss: 0.5165\n",
      "7937/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5049\n",
      "7938/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5157\n",
      "7939/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.4996\n",
      "7940/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5062\n",
      "7941/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5068\n",
      "7942/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5069\n",
      "7943/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5079\n",
      "7944/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5089\n",
      "7945/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5047\n",
      "7946/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5073\n",
      "7947/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5045\n",
      "7948/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5035\n",
      "7949/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5100\n",
      "7950/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.4998\n",
      "7951/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5066\n",
      "7952/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5097\n",
      "7953/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5104\n",
      "7954/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5041\n",
      "7955/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.4968\n",
      "7956/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5005\n",
      "7957/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5014\n",
      "7958/15000:\n",
      "Training Loss: 0.4661 Validation Loss: 0.5065\n",
      "7959/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5171\n",
      "7960/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5178\n",
      "7961/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5227\n",
      "7962/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5281\n",
      "7963/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5140\n",
      "7964/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5037\n",
      "7965/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5030\n",
      "7966/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5070\n",
      "7967/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5033\n",
      "7968/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4988\n",
      "7969/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5034\n",
      "7970/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5030\n",
      "7971/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5074\n",
      "7972/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.4980\n",
      "7973/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5000\n",
      "7974/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5069\n",
      "7975/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5080\n",
      "7976/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5341\n",
      "7977/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5046\n",
      "7978/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5084\n",
      "7979/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4986\n",
      "7980/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5059\n",
      "7981/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5110\n",
      "7982/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5017\n",
      "7983/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5052\n",
      "7984/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5058\n",
      "7985/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4971\n",
      "7986/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5032\n",
      "7987/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.4983\n",
      "7988/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.4930\n",
      "7989/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4963\n",
      "7990/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4991\n",
      "7991/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4998\n",
      "7992/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5041\n",
      "7993/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5042\n",
      "7994/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5051\n",
      "7995/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5021\n",
      "7996/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5136\n",
      "7997/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5169\n",
      "7998/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5039\n",
      "7999/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5039\n",
      "8000/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5104\n",
      "8001/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5043\n",
      "8002/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5065\n",
      "8003/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5162\n",
      "8004/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5136\n",
      "8005/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4999\n",
      "8006/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5010\n",
      "8007/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5110\n",
      "8008/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5107\n",
      "8009/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5093\n",
      "8010/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5250\n",
      "8011/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5035\n",
      "8012/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5111\n",
      "8013/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5124\n",
      "8014/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5072\n",
      "8015/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5155\n",
      "8016/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.4963\n",
      "8017/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4969\n",
      "8018/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.4989\n",
      "8019/15000:\n",
      "Training Loss: 0.4707 Validation Loss: 0.5111\n",
      "8020/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5168\n",
      "8021/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5286\n",
      "8022/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5103\n",
      "8023/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4989\n",
      "8024/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5071\n",
      "8025/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5003\n",
      "8026/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4991\n",
      "8027/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5088\n",
      "8028/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5038\n",
      "8029/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5038\n",
      "8030/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4988\n",
      "8031/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.4979\n",
      "8032/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4975\n",
      "8033/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4998\n",
      "8034/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.4972\n",
      "8035/15000:\n",
      "Training Loss: 0.4720 Validation Loss: 0.4921\n",
      "8036/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5184\n",
      "8037/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5188\n",
      "8038/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5235\n",
      "8039/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5468\n",
      "8040/15000:\n",
      "Training Loss: 0.5290 Validation Loss: 0.5668\n",
      "8041/15000:\n",
      "Training Loss: 0.5970 Validation Loss: 0.5218\n",
      "8042/15000:\n",
      "Training Loss: 0.5185 Validation Loss: 0.5313\n",
      "8043/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5076\n",
      "8044/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5104\n",
      "8045/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5288\n",
      "8046/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5240\n",
      "8047/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.5208\n",
      "8048/15000:\n",
      "Training Loss: 0.5237 Validation Loss: 0.5157\n",
      "8049/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5108\n",
      "8050/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5113\n",
      "8051/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5090\n",
      "8052/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5186\n",
      "8053/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5130\n",
      "8054/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5091\n",
      "8055/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.5258\n",
      "8056/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.5721\n",
      "8057/15000:\n",
      "Training Loss: 0.5678 Validation Loss: 0.5220\n",
      "8058/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5155\n",
      "8059/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5191\n",
      "8060/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5098\n",
      "8061/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5054\n",
      "8062/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5117\n",
      "8063/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4972\n",
      "8064/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4981\n",
      "8065/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4981\n",
      "8066/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5051\n",
      "8067/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4987\n",
      "8068/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5086\n",
      "8069/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5088\n",
      "8070/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5052\n",
      "8071/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5147\n",
      "8072/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4980\n",
      "8073/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5062\n",
      "8074/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5158\n",
      "8075/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5021\n",
      "8076/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.4933\n",
      "8077/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4921\n",
      "8078/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5003\n",
      "8079/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5014\n",
      "8080/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5074\n",
      "8081/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5103\n",
      "8082/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5186\n",
      "8083/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5113\n",
      "8084/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5217\n",
      "8085/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5116\n",
      "8086/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5014\n",
      "8087/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5030\n",
      "8088/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5042\n",
      "8089/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5065\n",
      "8090/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.4996\n",
      "8091/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4993\n",
      "8092/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4982\n",
      "8093/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5088\n",
      "8094/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4957\n",
      "8095/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5029\n",
      "8096/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5083\n",
      "8097/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4988\n",
      "8098/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5091\n",
      "8099/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5000\n",
      "8100/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4973\n",
      "8101/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5004\n",
      "8102/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5049\n",
      "8103/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5175\n",
      "8104/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5176\n",
      "8105/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5335\n",
      "8106/15000:\n",
      "Training Loss: 0.5401 Validation Loss: 0.5134\n",
      "8107/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5080\n",
      "8108/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5111\n",
      "8109/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5175\n",
      "8110/15000:\n",
      "Training Loss: 0.5267 Validation Loss: 0.5160\n",
      "8111/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4953\n",
      "8112/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.4988\n",
      "8113/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5001\n",
      "8114/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5008\n",
      "8115/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5018\n",
      "8116/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5063\n",
      "8117/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5012\n",
      "8118/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5006\n",
      "8119/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5039\n",
      "8120/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5047\n",
      "8121/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.4962\n",
      "8122/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5070\n",
      "8123/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5025\n",
      "8124/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4981\n",
      "8125/15000:\n",
      "Training Loss: 0.4665 Validation Loss: 0.5021\n",
      "8126/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5088\n",
      "8127/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5017\n",
      "8128/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.4963\n",
      "8129/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.4978\n",
      "8130/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5040\n",
      "8131/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.4994\n",
      "8132/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.4999\n",
      "8133/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4975\n",
      "8134/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4979\n",
      "8135/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.4947\n",
      "8136/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4980\n",
      "8137/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.4948\n",
      "8138/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.4979\n",
      "8139/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5006\n",
      "8140/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.4974\n",
      "8141/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5005\n",
      "8142/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5073\n",
      "8143/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5059\n",
      "8144/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5034\n",
      "8145/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.4994\n",
      "8146/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.4925\n",
      "8147/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4975\n",
      "8148/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4923\n",
      "8149/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4971\n",
      "8150/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.4978\n",
      "8151/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4998\n",
      "8152/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4986\n",
      "8153/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.4961\n",
      "8154/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5053\n",
      "8155/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4955\n",
      "8156/15000:\n",
      "Training Loss: 0.4713 Validation Loss: 0.4986\n",
      "8157/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.4922\n",
      "8158/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4915\n",
      "8159/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4958\n",
      "8160/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4987\n",
      "8161/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5215\n",
      "8162/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5433\n",
      "8163/15000:\n",
      "Training Loss: 0.5166 Validation Loss: 0.5298\n",
      "8164/15000:\n",
      "Training Loss: 0.5275 Validation Loss: 0.5199\n",
      "8165/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4957\n",
      "8166/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5028\n",
      "8167/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4942\n",
      "8168/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4935\n",
      "8169/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.4966\n",
      "8170/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5044\n",
      "8171/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5240\n",
      "8172/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5028\n",
      "8173/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4951\n",
      "8174/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5044\n",
      "8175/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5285\n",
      "8176/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5131\n",
      "8177/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5100\n",
      "8178/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5014\n",
      "8179/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.4921\n",
      "8180/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.4916\n",
      "8181/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.4923\n",
      "8182/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4916\n",
      "8183/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4998\n",
      "8184/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.5054\n",
      "8185/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4959\n",
      "8186/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5005\n",
      "8187/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.4970\n",
      "8188/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5085\n",
      "8189/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5002\n",
      "8190/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5032\n",
      "8191/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4998\n",
      "8192/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4961\n",
      "8193/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4950\n",
      "8194/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.4980\n",
      "8195/15000:\n",
      "Training Loss: 0.4640 Validation Loss: 0.4935\n",
      "8196/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4963\n",
      "8197/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.4947\n",
      "8198/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.4935\n",
      "8199/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.4979\n",
      "8200/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5249\n",
      "8201/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5061\n",
      "8202/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5289\n",
      "8203/15000:\n",
      "Training Loss: 0.5234 Validation Loss: 0.5190\n",
      "8204/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5158\n",
      "8205/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5303\n",
      "8206/15000:\n",
      "Training Loss: 0.5241 Validation Loss: 0.5733\n",
      "8207/15000:\n",
      "Training Loss: 0.5516 Validation Loss: 0.5221\n",
      "8208/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5583\n",
      "8209/15000:\n",
      "Training Loss: 0.5390 Validation Loss: 0.5072\n",
      "8210/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5036\n",
      "8211/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5026\n",
      "8212/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5029\n",
      "8213/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5105\n",
      "8214/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5001\n",
      "8215/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4997\n",
      "8216/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5000\n",
      "8217/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4996\n",
      "8218/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.4980\n",
      "8219/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5150\n",
      "8220/15000:\n",
      "Training Loss: 0.5272 Validation Loss: 0.5161\n",
      "8221/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5097\n",
      "8222/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4985\n",
      "8223/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.4968\n",
      "8224/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4957\n",
      "8225/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5026\n",
      "8226/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5051\n",
      "8227/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5096\n",
      "8228/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5092\n",
      "8229/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5156\n",
      "8230/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.4983\n",
      "8231/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.4984\n",
      "8232/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4978\n",
      "8233/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5049\n",
      "8234/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4948\n",
      "8235/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5001\n",
      "8236/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.4924\n",
      "8237/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.4982\n",
      "8238/15000:\n",
      "Training Loss: 0.4657 Validation Loss: 0.5058\n",
      "8239/15000:\n",
      "Training Loss: 0.5181 Validation Loss: 0.4990\n",
      "8240/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.4993\n",
      "8241/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.4977\n",
      "8242/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4985\n",
      "8243/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4949\n",
      "8244/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4960\n",
      "8245/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.4976\n",
      "8246/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5204\n",
      "8247/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5126\n",
      "8248/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.4981\n",
      "8249/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5085\n",
      "8250/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5072\n",
      "8251/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5031\n",
      "8252/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5140\n",
      "8253/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5003\n",
      "8254/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5038\n",
      "8255/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4986\n",
      "8256/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.4977\n",
      "8257/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5014\n",
      "8258/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5214\n",
      "8259/15000:\n",
      "Training Loss: 0.5299 Validation Loss: 0.5149\n",
      "8260/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5086\n",
      "8261/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4993\n",
      "8262/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5079\n",
      "8263/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5070\n",
      "8264/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4990\n",
      "8265/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5013\n",
      "8266/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5223\n",
      "8267/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5100\n",
      "8268/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5048\n",
      "8269/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.4947\n",
      "8270/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.4937\n",
      "8271/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.4954\n",
      "8272/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4985\n",
      "8273/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4929\n",
      "8274/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4947\n",
      "8275/15000:\n",
      "Training Loss: 0.4653 Validation Loss: 0.4938\n",
      "8276/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5006\n",
      "8277/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5044\n",
      "8278/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5177\n",
      "8279/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5096\n",
      "8280/15000:\n",
      "Training Loss: 0.5140 Validation Loss: 0.5001\n",
      "8281/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4993\n",
      "8282/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5033\n",
      "8283/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5061\n",
      "8284/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5003\n",
      "8285/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5203\n",
      "8286/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5303\n",
      "8287/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5335\n",
      "8288/15000:\n",
      "Training Loss: 0.5253 Validation Loss: 0.5588\n",
      "8289/15000:\n",
      "Training Loss: 0.5438 Validation Loss: 0.5227\n",
      "8290/15000:\n",
      "Training Loss: 0.5414 Validation Loss: 0.5143\n",
      "8291/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5009\n",
      "8292/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5019\n",
      "8293/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5005\n",
      "8294/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.4975\n",
      "8295/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4981\n",
      "8296/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4950\n",
      "8297/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5123\n",
      "8298/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5153\n",
      "8299/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4982\n",
      "8300/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5018\n",
      "8301/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4992\n",
      "8302/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.4954\n",
      "8303/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.4955\n",
      "8304/15000:\n",
      "Training Loss: 0.4702 Validation Loss: 0.5068\n",
      "8305/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5009\n",
      "8306/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5042\n",
      "8307/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5002\n",
      "8308/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5076\n",
      "8309/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5031\n",
      "8310/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5262\n",
      "8311/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5180\n",
      "8312/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5093\n",
      "8313/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5063\n",
      "8314/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5055\n",
      "8315/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5007\n",
      "8316/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5052\n",
      "8317/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.4999\n",
      "8318/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5074\n",
      "8319/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5030\n",
      "8320/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5039\n",
      "8321/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5153\n",
      "8322/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5037\n",
      "8323/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5069\n",
      "8324/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5106\n",
      "8325/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4985\n",
      "8326/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5026\n",
      "8327/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5029\n",
      "8328/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5221\n",
      "8329/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5188\n",
      "8330/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5112\n",
      "8331/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5074\n",
      "8332/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4964\n",
      "8333/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5006\n",
      "8334/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5023\n",
      "8335/15000:\n",
      "Training Loss: 0.4678 Validation Loss: 0.4997\n",
      "8336/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.4984\n",
      "8337/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4999\n",
      "8338/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5000\n",
      "8339/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.5008\n",
      "8340/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5024\n",
      "8341/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5044\n",
      "8342/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5010\n",
      "8343/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4992\n",
      "8344/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4993\n",
      "8345/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5008\n",
      "8346/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.4998\n",
      "8347/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5109\n",
      "8348/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5319\n",
      "8349/15000:\n",
      "Training Loss: 0.5246 Validation Loss: 0.5243\n",
      "8350/15000:\n",
      "Training Loss: 0.5174 Validation Loss: 0.5115\n",
      "8351/15000:\n",
      "Training Loss: 0.5297 Validation Loss: 0.5039\n",
      "8352/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.4992\n",
      "8353/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4931\n",
      "8354/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.4936\n",
      "8355/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4999\n",
      "8356/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.4983\n",
      "8357/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5047\n",
      "8358/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4930\n",
      "8359/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4933\n",
      "8360/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4930\n",
      "8361/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4983\n",
      "8362/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5015\n",
      "8363/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.4976\n",
      "8364/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.5077\n",
      "8365/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5219\n",
      "8366/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5092\n",
      "8367/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5196\n",
      "8368/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5133\n",
      "8369/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5535\n",
      "8370/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.4951\n",
      "8371/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5063\n",
      "8372/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5054\n",
      "8373/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5010\n",
      "8374/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5087\n",
      "8375/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5063\n",
      "8376/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5117\n",
      "8377/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5139\n",
      "8378/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.5022\n",
      "8379/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5037\n",
      "8380/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5092\n",
      "8381/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5078\n",
      "8382/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4947\n",
      "8383/15000:\n",
      "Training Loss: 0.4690 Validation Loss: 0.4878\n",
      "8384/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4956\n",
      "8385/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4939\n",
      "8386/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.4962\n",
      "8387/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5011\n",
      "8388/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5000\n",
      "8389/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4976\n",
      "8390/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5102\n",
      "8391/15000:\n",
      "Training Loss: 0.5155 Validation Loss: 0.5275\n",
      "8392/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.6015\n",
      "8393/15000:\n",
      "Training Loss: 0.5899 Validation Loss: 0.5205\n",
      "8394/15000:\n",
      "Training Loss: 0.5242 Validation Loss: 0.5285\n",
      "8395/15000:\n",
      "Training Loss: 0.5211 Validation Loss: 0.5072\n",
      "8396/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5013\n",
      "8397/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5015\n",
      "8398/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5011\n",
      "8399/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5052\n",
      "8400/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5014\n",
      "8401/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5009\n",
      "8402/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5074\n",
      "8403/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5092\n",
      "8404/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5043\n",
      "8405/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5044\n",
      "8406/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5046\n",
      "8407/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5077\n",
      "8408/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5215\n",
      "8409/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5539\n",
      "8410/15000:\n",
      "Training Loss: 0.5386 Validation Loss: 0.5144\n",
      "8411/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5165\n",
      "8412/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5075\n",
      "8413/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5018\n",
      "8414/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5021\n",
      "8415/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.4994\n",
      "8416/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5043\n",
      "8417/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5043\n",
      "8418/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5049\n",
      "8419/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5115\n",
      "8420/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5103\n",
      "8421/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5041\n",
      "8422/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5120\n",
      "8423/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4988\n",
      "8424/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5057\n",
      "8425/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5009\n",
      "8426/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5131\n",
      "8427/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5043\n",
      "8428/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.4998\n",
      "8429/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5102\n",
      "8430/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5038\n",
      "8431/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5024\n",
      "8432/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5066\n",
      "8433/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.4975\n",
      "8434/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4951\n",
      "8435/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.4948\n",
      "8436/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.5023\n",
      "8437/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5009\n",
      "8438/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5076\n",
      "8439/15000:\n",
      "Training Loss: 0.4679 Validation Loss: 0.5016\n",
      "8440/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5015\n",
      "8441/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5039\n",
      "8442/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5025\n",
      "8443/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4992\n",
      "8444/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4996\n",
      "8445/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5020\n",
      "8446/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.4999\n",
      "8447/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.4978\n",
      "8448/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5060\n",
      "8449/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.4986\n",
      "8450/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5081\n",
      "8451/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4976\n",
      "8452/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.4987\n",
      "8453/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.5058\n",
      "8454/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5150\n",
      "8455/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5053\n",
      "8456/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5325\n",
      "8457/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5394\n",
      "8458/15000:\n",
      "Training Loss: 0.5245 Validation Loss: 0.6078\n",
      "8459/15000:\n",
      "Training Loss: 0.6150 Validation Loss: 0.5502\n",
      "8460/15000:\n",
      "Training Loss: 0.5432 Validation Loss: 0.5349\n",
      "8461/15000:\n",
      "Training Loss: 0.5443 Validation Loss: 0.5132\n",
      "8462/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5061\n",
      "8463/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5016\n",
      "8464/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4978\n",
      "8465/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5030\n",
      "8466/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5064\n",
      "8467/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5050\n",
      "8468/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5188\n",
      "8469/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.4960\n",
      "8470/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.5099\n",
      "8471/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4969\n",
      "8472/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4973\n",
      "8473/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5161\n",
      "8474/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5121\n",
      "8475/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.4948\n",
      "8476/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5026\n",
      "8477/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5016\n",
      "8478/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5001\n",
      "8479/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.4960\n",
      "8480/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4991\n",
      "8481/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4987\n",
      "8482/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5055\n",
      "8483/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5029\n",
      "8484/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5013\n",
      "8485/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5052\n",
      "8486/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5059\n",
      "8487/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5027\n",
      "8488/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5161\n",
      "8489/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5091\n",
      "8490/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5153\n",
      "8491/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5170\n",
      "8492/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5930\n",
      "8493/15000:\n",
      "Training Loss: 0.6113 Validation Loss: 0.5724\n",
      "8494/15000:\n",
      "Training Loss: 0.5650 Validation Loss: 0.5245\n",
      "8495/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5059\n",
      "8496/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5063\n",
      "8497/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5054\n",
      "8498/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5130\n",
      "8499/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5248\n",
      "8500/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5027\n",
      "8501/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5137\n",
      "8502/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5120\n",
      "8503/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5083\n",
      "8504/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5074\n",
      "8505/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5055\n",
      "8506/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5004\n",
      "8507/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.4976\n",
      "8508/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5076\n",
      "8509/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5130\n",
      "8510/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5138\n",
      "8511/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5041\n",
      "8512/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5067\n",
      "8513/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5049\n",
      "8514/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5082\n",
      "8515/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5098\n",
      "8516/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5008\n",
      "8517/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5155\n",
      "8518/15000:\n",
      "Training Loss: 0.4658 Validation Loss: 0.5114\n",
      "8519/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5074\n",
      "8520/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5094\n",
      "8521/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5136\n",
      "8522/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5088\n",
      "8523/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5147\n",
      "8524/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5171\n",
      "8525/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5226\n",
      "8526/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5026\n",
      "8527/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5133\n",
      "8528/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4989\n",
      "8529/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5015\n",
      "8530/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5184\n",
      "8531/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5078\n",
      "8532/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5043\n",
      "8533/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4991\n",
      "8534/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4977\n",
      "8535/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5021\n",
      "8536/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.4947\n",
      "8537/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4998\n",
      "8538/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.4967\n",
      "8539/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5034\n",
      "8540/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5019\n",
      "8541/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5046\n",
      "8542/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5068\n",
      "8543/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5226\n",
      "8544/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5092\n",
      "8545/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5016\n",
      "8546/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5064\n",
      "8547/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5078\n",
      "8548/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5229\n",
      "8549/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5170\n",
      "8550/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5262\n",
      "8551/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5439\n",
      "8552/15000:\n",
      "Training Loss: 0.5234 Validation Loss: 0.4991\n",
      "8553/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4967\n",
      "8554/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.4956\n",
      "8555/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5055\n",
      "8556/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5031\n",
      "8557/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5068\n",
      "8558/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4960\n",
      "8559/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4971\n",
      "8560/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.4975\n",
      "8561/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.4997\n",
      "8562/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.4993\n",
      "8563/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5028\n",
      "8564/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5031\n",
      "8565/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5005\n",
      "8566/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5208\n",
      "8567/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5110\n",
      "8568/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5129\n",
      "8569/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4965\n",
      "8570/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4965\n",
      "8571/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5056\n",
      "8572/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5076\n",
      "8573/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5385\n",
      "8574/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5167\n",
      "8575/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5059\n",
      "8576/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5089\n",
      "8577/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5082\n",
      "8578/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.4979\n",
      "8579/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5070\n",
      "8580/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5022\n",
      "8581/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5065\n",
      "8582/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5022\n",
      "8583/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4957\n",
      "8584/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5095\n",
      "8585/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5030\n",
      "8586/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5086\n",
      "8587/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5038\n",
      "8588/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5117\n",
      "8589/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5117\n",
      "8590/15000:\n",
      "Training Loss: 0.5246 Validation Loss: 0.5314\n",
      "8591/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4952\n",
      "8592/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.4967\n",
      "8593/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.4956\n",
      "8594/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5019\n",
      "8595/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5016\n",
      "8596/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5067\n",
      "8597/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5103\n",
      "8598/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5047\n",
      "8599/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.4994\n",
      "8600/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5022\n",
      "8601/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4975\n",
      "8602/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.4977\n",
      "8603/15000:\n",
      "Training Loss: 0.4715 Validation Loss: 0.5002\n",
      "8604/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5003\n",
      "8605/15000:\n",
      "Training Loss: 0.4669 Validation Loss: 0.4953\n",
      "8606/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5033\n",
      "8607/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5087\n",
      "8608/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5292\n",
      "8609/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5253\n",
      "8610/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5490\n",
      "8611/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5657\n",
      "8612/15000:\n",
      "Training Loss: 0.5440 Validation Loss: 0.5141\n",
      "8613/15000:\n",
      "Training Loss: 0.5134 Validation Loss: 0.5112\n",
      "8614/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5025\n",
      "8615/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5135\n",
      "8616/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5008\n",
      "8617/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5046\n",
      "8618/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4990\n",
      "8619/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5065\n",
      "8620/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5052\n",
      "8621/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5161\n",
      "8622/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5385\n",
      "8623/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5195\n",
      "8624/15000:\n",
      "Training Loss: 0.5287 Validation Loss: 0.5121\n",
      "8625/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5057\n",
      "8626/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4957\n",
      "8627/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4977\n",
      "8628/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5007\n",
      "8629/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5001\n",
      "8630/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.4953\n",
      "8631/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4986\n",
      "8632/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5284\n",
      "8633/15000:\n",
      "Training Loss: 0.5320 Validation Loss: 0.5000\n",
      "8634/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5015\n",
      "8635/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5096\n",
      "8636/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5028\n",
      "8637/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4995\n",
      "8638/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5007\n",
      "8639/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5092\n",
      "8640/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5080\n",
      "8641/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5202\n",
      "8642/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5042\n",
      "8643/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5071\n",
      "8644/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5035\n",
      "8645/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5137\n",
      "8646/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5082\n",
      "8647/15000:\n",
      "Training Loss: 0.4701 Validation Loss: 0.5061\n",
      "8648/15000:\n",
      "Training Loss: 0.4608 Validation Loss: 0.5069\n",
      "8649/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5077\n",
      "8650/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5098\n",
      "8651/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5042\n",
      "8652/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5229\n",
      "8653/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5544\n",
      "8654/15000:\n",
      "Training Loss: 0.5369 Validation Loss: 0.5123\n",
      "8655/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5158\n",
      "8656/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5041\n",
      "8657/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5105\n",
      "8658/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5075\n",
      "8659/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5150\n",
      "8660/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5088\n",
      "8661/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5150\n",
      "8662/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5081\n",
      "8663/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5094\n",
      "8664/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5108\n",
      "8665/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5075\n",
      "8666/15000:\n",
      "Training Loss: 0.4697 Validation Loss: 0.5230\n",
      "8667/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5173\n",
      "8668/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5130\n",
      "8669/15000:\n",
      "Training Loss: 0.5198 Validation Loss: 0.5260\n",
      "8670/15000:\n",
      "Training Loss: 0.5297 Validation Loss: 0.5386\n",
      "8671/15000:\n",
      "Training Loss: 0.5278 Validation Loss: 0.5144\n",
      "8672/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5097\n",
      "8673/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5059\n",
      "8674/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5060\n",
      "8675/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5068\n",
      "8676/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5078\n",
      "8677/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5076\n",
      "8678/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4986\n",
      "8679/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5072\n",
      "8680/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5096\n",
      "8681/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5094\n",
      "8682/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5086\n",
      "8683/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5050\n",
      "8684/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.4994\n",
      "8685/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5002\n",
      "8686/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4991\n",
      "8687/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5334\n",
      "8688/15000:\n",
      "Training Loss: 0.5482 Validation Loss: 0.5296\n",
      "8689/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.4993\n",
      "8690/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5012\n",
      "8691/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.4971\n",
      "8692/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4990\n",
      "8693/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4951\n",
      "8694/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4961\n",
      "8695/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4957\n",
      "8696/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4967\n",
      "8697/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5003\n",
      "8698/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4973\n",
      "8699/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.4986\n",
      "8700/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5045\n",
      "8701/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5168\n",
      "8702/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5295\n",
      "8703/15000:\n",
      "Training Loss: 0.5257 Validation Loss: 0.5274\n",
      "8704/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5031\n",
      "8705/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5102\n",
      "8706/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5038\n",
      "8707/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5012\n",
      "8708/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4975\n",
      "8709/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5183\n",
      "8710/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5108\n",
      "8711/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5018\n",
      "8712/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5039\n",
      "8713/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5197\n",
      "8714/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5456\n",
      "8715/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5281\n",
      "8716/15000:\n",
      "Training Loss: 0.5556 Validation Loss: 0.5170\n",
      "8717/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5035\n",
      "8718/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5070\n",
      "8719/15000:\n",
      "Training Loss: 0.5199 Validation Loss: 0.4976\n",
      "8720/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5026\n",
      "8721/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5039\n",
      "8722/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5012\n",
      "8723/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4979\n",
      "8724/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5102\n",
      "8725/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5022\n",
      "8726/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5106\n",
      "8727/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5026\n",
      "8728/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5061\n",
      "8729/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5102\n",
      "8730/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5071\n",
      "8731/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5037\n",
      "8732/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5014\n",
      "8733/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5135\n",
      "8734/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5101\n",
      "8735/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5080\n",
      "8736/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5008\n",
      "8737/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5086\n",
      "8738/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5097\n",
      "8739/15000:\n",
      "Training Loss: 0.4691 Validation Loss: 0.5146\n",
      "8740/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5139\n",
      "8741/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5473\n",
      "8742/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5280\n",
      "8743/15000:\n",
      "Training Loss: 0.5252 Validation Loss: 0.5055\n",
      "8744/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5039\n",
      "8745/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5084\n",
      "8746/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5043\n",
      "8747/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5058\n",
      "8748/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5080\n",
      "8749/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5098\n",
      "8750/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5118\n",
      "8751/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5133\n",
      "8752/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5047\n",
      "8753/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5050\n",
      "8754/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5265\n",
      "8755/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5287\n",
      "8756/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5395\n",
      "8757/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5197\n",
      "8758/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5013\n",
      "8759/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5010\n",
      "8760/15000:\n",
      "Training Loss: 0.4686 Validation Loss: 0.5069\n",
      "8761/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5020\n",
      "8762/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5107\n",
      "8763/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5214\n",
      "8764/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5058\n",
      "8765/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5205\n",
      "8766/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5142\n",
      "8767/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5109\n",
      "8768/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5103\n",
      "8769/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5228\n",
      "8770/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5119\n",
      "8771/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5149\n",
      "8772/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5028\n",
      "8773/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5026\n",
      "8774/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5055\n",
      "8775/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5029\n",
      "8776/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5055\n",
      "8777/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5113\n",
      "8778/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5216\n",
      "8779/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5159\n",
      "8780/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5200\n",
      "8781/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5169\n",
      "8782/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5263\n",
      "8783/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5387\n",
      "8784/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5300\n",
      "8785/15000:\n",
      "Training Loss: 0.5120 Validation Loss: 0.5864\n",
      "8786/15000:\n",
      "Training Loss: 0.5579 Validation Loss: 0.5199\n",
      "8787/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5239\n",
      "8788/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5085\n",
      "8789/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5168\n",
      "8790/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5213\n",
      "8791/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.4954\n",
      "8792/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5067\n",
      "8793/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5012\n",
      "8794/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5036\n",
      "8795/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5046\n",
      "8796/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.5042\n",
      "8797/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5010\n",
      "8798/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5116\n",
      "8799/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5057\n",
      "8800/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5060\n",
      "8801/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5039\n",
      "8802/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5093\n",
      "8803/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5058\n",
      "8804/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5106\n",
      "8805/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5162\n",
      "8806/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5116\n",
      "8807/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5120\n",
      "8808/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5008\n",
      "8809/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5103\n",
      "8810/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5034\n",
      "8811/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5074\n",
      "8812/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5040\n",
      "8813/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5065\n",
      "8814/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5029\n",
      "8815/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5084\n",
      "8816/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5036\n",
      "8817/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5049\n",
      "8818/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5051\n",
      "8819/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5056\n",
      "8820/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5016\n",
      "8821/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5021\n",
      "8822/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5186\n",
      "8823/15000:\n",
      "Training Loss: 0.4686 Validation Loss: 0.5084\n",
      "8824/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5098\n",
      "8825/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5183\n",
      "8826/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5176\n",
      "8827/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5070\n",
      "8828/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5267\n",
      "8829/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5409\n",
      "8830/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5206\n",
      "8831/15000:\n",
      "Training Loss: 0.5242 Validation Loss: 0.5156\n",
      "8832/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5059\n",
      "8833/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5043\n",
      "8834/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5044\n",
      "8835/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5023\n",
      "8836/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5011\n",
      "8837/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4951\n",
      "8838/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5031\n",
      "8839/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5143\n",
      "8840/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.4985\n",
      "8841/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5099\n",
      "8842/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5374\n",
      "8843/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5180\n",
      "8844/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5074\n",
      "8845/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.4981\n",
      "8846/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.4978\n",
      "8847/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5044\n",
      "8848/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5053\n",
      "8849/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.4995\n",
      "8850/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5153\n",
      "8851/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5142\n",
      "8852/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5082\n",
      "8853/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5142\n",
      "8854/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5112\n",
      "8855/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5013\n",
      "8856/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5004\n",
      "8857/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.4998\n",
      "8858/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5071\n",
      "8859/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4994\n",
      "8860/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5018\n",
      "8861/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5028\n",
      "8862/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.4997\n",
      "8863/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5002\n",
      "8864/15000:\n",
      "Training Loss: 0.4675 Validation Loss: 0.4976\n",
      "8865/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5007\n",
      "8866/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5024\n",
      "8867/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5185\n",
      "8868/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5486\n",
      "8869/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5471\n",
      "8870/15000:\n",
      "Training Loss: 0.5392 Validation Loss: 0.7008\n",
      "8871/15000:\n",
      "Training Loss: 0.7300 Validation Loss: 0.5590\n",
      "8872/15000:\n",
      "Training Loss: 0.5376 Validation Loss: 0.5477\n",
      "8873/15000:\n",
      "Training Loss: 0.5917 Validation Loss: 0.5299\n",
      "8874/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5141\n",
      "8875/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5146\n",
      "8876/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5105\n",
      "8877/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5208\n",
      "8878/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5219\n",
      "8879/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5179\n",
      "8880/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5142\n",
      "8881/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5188\n",
      "8882/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5392\n",
      "8883/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5109\n",
      "8884/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5099\n",
      "8885/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5065\n",
      "8886/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5024\n",
      "8887/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5017\n",
      "8888/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5062\n",
      "8889/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5102\n",
      "8890/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5128\n",
      "8891/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5109\n",
      "8892/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5072\n",
      "8893/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5067\n",
      "8894/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5114\n",
      "8895/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5052\n",
      "8896/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5221\n",
      "8897/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5032\n",
      "8898/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5081\n",
      "8899/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.4961\n",
      "8900/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4964\n",
      "8901/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5030\n",
      "8902/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5045\n",
      "8903/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5060\n",
      "8904/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5081\n",
      "8905/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5146\n",
      "8906/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5132\n",
      "8907/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5051\n",
      "8908/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.4987\n",
      "8909/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5020\n",
      "8910/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5045\n",
      "8911/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5023\n",
      "8912/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5081\n",
      "8913/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5098\n",
      "8914/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5062\n",
      "8915/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5024\n",
      "8916/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.4926\n",
      "8917/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5021\n",
      "8918/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5066\n",
      "8919/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5197\n",
      "8920/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5119\n",
      "8921/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4971\n",
      "8922/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5031\n",
      "8923/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5094\n",
      "8924/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5135\n",
      "8925/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5054\n",
      "8926/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5096\n",
      "8927/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5048\n",
      "8928/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5005\n",
      "8929/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5183\n",
      "8930/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5111\n",
      "8931/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5303\n",
      "8932/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5846\n",
      "8933/15000:\n",
      "Training Loss: 0.6047 Validation Loss: 0.5689\n",
      "8934/15000:\n",
      "Training Loss: 0.5447 Validation Loss: 0.5312\n",
      "8935/15000:\n",
      "Training Loss: 0.5549 Validation Loss: 0.5114\n",
      "8936/15000:\n",
      "Training Loss: 0.5167 Validation Loss: 0.5036\n",
      "8937/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5074\n",
      "8938/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5040\n",
      "8939/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5032\n",
      "8940/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5098\n",
      "8941/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5124\n",
      "8942/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5132\n",
      "8943/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5109\n",
      "8944/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5157\n",
      "8945/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5059\n",
      "8946/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5089\n",
      "8947/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5139\n",
      "8948/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5259\n",
      "8949/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5237\n",
      "8950/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5018\n",
      "8951/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5072\n",
      "8952/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5035\n",
      "8953/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5014\n",
      "8954/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5085\n",
      "8955/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5084\n",
      "8956/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5253\n",
      "8957/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5174\n",
      "8958/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5154\n",
      "8959/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.5113\n",
      "8960/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5088\n",
      "8961/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5009\n",
      "8962/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4996\n",
      "8963/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4977\n",
      "8964/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5131\n",
      "8965/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5130\n",
      "8966/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5070\n",
      "8967/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5025\n",
      "8968/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4996\n",
      "8969/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4904\n",
      "8970/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.4984\n",
      "8971/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4969\n",
      "8972/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5022\n",
      "8973/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5072\n",
      "8974/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5086\n",
      "8975/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5027\n",
      "8976/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5128\n",
      "8977/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5169\n",
      "8978/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5439\n",
      "8979/15000:\n",
      "Training Loss: 0.5443 Validation Loss: 0.5241\n",
      "8980/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5109\n",
      "8981/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5069\n",
      "8982/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5098\n",
      "8983/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5170\n",
      "8984/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5227\n",
      "8985/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5130\n",
      "8986/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5159\n",
      "8987/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5179\n",
      "8988/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5119\n",
      "8989/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5148\n",
      "8990/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5126\n",
      "8991/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5093\n",
      "8992/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5072\n",
      "8993/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5029\n",
      "8994/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5121\n",
      "8995/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5183\n",
      "8996/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5159\n",
      "8997/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5139\n",
      "8998/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.5091\n",
      "8999/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5151\n",
      "9000/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.5046\n",
      "9001/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5091\n",
      "9002/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5130\n",
      "9003/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5341\n",
      "9004/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5137\n",
      "9005/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5026\n",
      "9006/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5040\n",
      "9007/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5037\n",
      "9008/15000:\n",
      "Training Loss: 0.4689 Validation Loss: 0.5018\n",
      "9009/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5034\n",
      "9010/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5037\n",
      "9011/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5073\n",
      "9012/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5138\n",
      "9013/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5119\n",
      "9014/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5118\n",
      "9015/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5023\n",
      "9016/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5033\n",
      "9017/15000:\n",
      "Training Loss: 0.4699 Validation Loss: 0.5020\n",
      "9018/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4993\n",
      "9019/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5049\n",
      "9020/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5019\n",
      "9021/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5156\n",
      "9022/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5196\n",
      "9023/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5207\n",
      "9024/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5054\n",
      "9025/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5098\n",
      "9026/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5112\n",
      "9027/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5505\n",
      "9028/15000:\n",
      "Training Loss: 0.5166 Validation Loss: 0.5209\n",
      "9029/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5173\n",
      "9030/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.5126\n",
      "9031/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5094\n",
      "9032/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5013\n",
      "9033/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4991\n",
      "9034/15000:\n",
      "Training Loss: 0.4687 Validation Loss: 0.4969\n",
      "9035/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.4965\n",
      "9036/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5009\n",
      "9037/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5061\n",
      "9038/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5204\n",
      "9039/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5002\n",
      "9040/15000:\n",
      "Training Loss: 0.4674 Validation Loss: 0.5132\n",
      "9041/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.4995\n",
      "9042/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.4978\n",
      "9043/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4976\n",
      "9044/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5025\n",
      "9045/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5002\n",
      "9046/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5034\n",
      "9047/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5090\n",
      "9048/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5343\n",
      "9049/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5337\n",
      "9050/15000:\n",
      "Training Loss: 0.5297 Validation Loss: 0.5235\n",
      "9051/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5046\n",
      "9052/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5078\n",
      "9053/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5151\n",
      "9054/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5066\n",
      "9055/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5085\n",
      "9056/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5030\n",
      "9057/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5140\n",
      "9058/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5028\n",
      "9059/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5174\n",
      "9060/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5104\n",
      "9061/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5074\n",
      "9062/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5069\n",
      "9063/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5129\n",
      "9064/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5143\n",
      "9065/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5085\n",
      "9066/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.4974\n",
      "9067/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4987\n",
      "9068/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.4980\n",
      "9069/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4971\n",
      "9070/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4967\n",
      "9071/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.4979\n",
      "9072/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4995\n",
      "9073/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5022\n",
      "9074/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5015\n",
      "9075/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4963\n",
      "9076/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.4955\n",
      "9077/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5044\n",
      "9078/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5148\n",
      "9079/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5114\n",
      "9080/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5289\n",
      "9081/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5008\n",
      "9082/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5081\n",
      "9083/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5004\n",
      "9084/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4961\n",
      "9085/15000:\n",
      "Training Loss: 0.4668 Validation Loss: 0.5057\n",
      "9086/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5157\n",
      "9087/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.4998\n",
      "9088/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5012\n",
      "9089/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5011\n",
      "9090/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5154\n",
      "9091/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5066\n",
      "9092/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5004\n",
      "9093/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5134\n",
      "9094/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.4962\n",
      "9095/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5090\n",
      "9096/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4964\n",
      "9097/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5116\n",
      "9098/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5170\n",
      "9099/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5237\n",
      "9100/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5146\n",
      "9101/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5433\n",
      "9102/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4980\n",
      "9103/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5037\n",
      "9104/15000:\n",
      "Training Loss: 0.4673 Validation Loss: 0.5093\n",
      "9105/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5039\n",
      "9106/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5036\n",
      "9107/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5044\n",
      "9108/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4958\n",
      "9109/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4982\n",
      "9110/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5075\n",
      "9111/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5058\n",
      "9112/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.4980\n",
      "9113/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.4967\n",
      "9114/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5020\n",
      "9115/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4980\n",
      "9116/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5048\n",
      "9117/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.4987\n",
      "9118/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4935\n",
      "9119/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.4963\n",
      "9120/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5077\n",
      "9121/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5166\n",
      "9122/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5563\n",
      "9123/15000:\n",
      "Training Loss: 0.5523 Validation Loss: 0.7466\n",
      "9124/15000:\n",
      "Training Loss: 0.7244 Validation Loss: 0.5376\n",
      "9125/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5281\n",
      "9126/15000:\n",
      "Training Loss: 0.5326 Validation Loss: 0.5250\n",
      "9127/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5132\n",
      "9128/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5212\n",
      "9129/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5156\n",
      "9130/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5196\n",
      "9131/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5026\n",
      "9132/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5101\n",
      "9133/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5105\n",
      "9134/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5155\n",
      "9135/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5090\n",
      "9136/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5035\n",
      "9137/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5259\n",
      "9138/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5117\n",
      "9139/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5026\n",
      "9140/15000:\n",
      "Training Loss: 0.4719 Validation Loss: 0.5057\n",
      "9141/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5069\n",
      "9142/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5061\n",
      "9143/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5073\n",
      "9144/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5035\n",
      "9145/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5054\n",
      "9146/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.5050\n",
      "9147/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5022\n",
      "9148/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5012\n",
      "9149/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5007\n",
      "9150/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5067\n",
      "9151/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5116\n",
      "9152/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5099\n",
      "9153/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.4990\n",
      "9154/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5014\n",
      "9155/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5087\n",
      "9156/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5027\n",
      "9157/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5044\n",
      "9158/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5093\n",
      "9159/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5156\n",
      "9160/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5033\n",
      "9161/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5037\n",
      "9162/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.5096\n",
      "9163/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5047\n",
      "9164/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5078\n",
      "9165/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.5178\n",
      "9166/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5172\n",
      "9167/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5406\n",
      "9168/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5013\n",
      "9169/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5007\n",
      "9170/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5138\n",
      "9171/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5321\n",
      "9172/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5274\n",
      "9173/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5281\n",
      "9174/15000:\n",
      "Training Loss: 0.5211 Validation Loss: 0.5090\n",
      "9175/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5116\n",
      "9176/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5142\n",
      "9177/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5221\n",
      "9178/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5193\n",
      "9179/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5031\n",
      "9180/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5066\n",
      "9181/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5052\n",
      "9182/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5174\n",
      "9183/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5121\n",
      "9184/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5066\n",
      "9185/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5054\n",
      "9186/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5009\n",
      "9187/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5054\n",
      "9188/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5088\n",
      "9189/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5053\n",
      "9190/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5149\n",
      "9191/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5255\n",
      "9192/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5119\n",
      "9193/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5218\n",
      "9194/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5111\n",
      "9195/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.6098\n",
      "9196/15000:\n",
      "Training Loss: 0.5720 Validation Loss: 0.4934\n",
      "9197/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4918\n",
      "9198/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.4935\n",
      "9199/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5002\n",
      "9200/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.4952\n",
      "9201/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.4950\n",
      "9202/15000:\n",
      "Training Loss: 0.4710 Validation Loss: 0.4949\n",
      "9203/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5105\n",
      "9204/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5126\n",
      "9205/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5010\n",
      "9206/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.4996\n",
      "9207/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5148\n",
      "9208/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5087\n",
      "9209/15000:\n",
      "Training Loss: 0.5176 Validation Loss: 0.4990\n",
      "9210/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5058\n",
      "9211/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.4942\n",
      "9212/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.4932\n",
      "9213/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4919\n",
      "9214/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4956\n",
      "9215/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.4947\n",
      "9216/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5087\n",
      "9217/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4993\n",
      "9218/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5003\n",
      "9219/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5150\n",
      "9220/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5131\n",
      "9221/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5075\n",
      "9222/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.5094\n",
      "9223/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5011\n",
      "9224/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5001\n",
      "9225/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4949\n",
      "9226/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5012\n",
      "9227/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5044\n",
      "9228/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5056\n",
      "9229/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4985\n",
      "9230/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4987\n",
      "9231/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4961\n",
      "9232/15000:\n",
      "Training Loss: 0.4684 Validation Loss: 0.4922\n",
      "9233/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.4949\n",
      "9234/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5126\n",
      "9235/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5107\n",
      "9236/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.4996\n",
      "9237/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4950\n",
      "9238/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5134\n",
      "9239/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4902\n",
      "9240/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4942\n",
      "9241/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5098\n",
      "9242/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.4996\n",
      "9243/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5112\n",
      "9244/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.4896\n",
      "9245/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4866\n",
      "9246/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.4918\n",
      "9247/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4913\n",
      "9248/15000:\n",
      "Training Loss: 0.4655 Validation Loss: 0.5197\n",
      "9249/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5012\n",
      "9250/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5014\n",
      "9251/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5050\n",
      "9252/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5011\n",
      "9253/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5106\n",
      "9254/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5161\n",
      "9255/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5236\n",
      "9256/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5432\n",
      "9257/15000:\n",
      "Training Loss: 0.5305 Validation Loss: 0.5305\n",
      "9258/15000:\n",
      "Training Loss: 0.5389 Validation Loss: 0.5207\n",
      "9259/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.4992\n",
      "9260/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.4968\n",
      "9261/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5062\n",
      "9262/15000:\n",
      "Training Loss: 0.5220 Validation Loss: 0.5034\n",
      "9263/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5034\n",
      "9264/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5048\n",
      "9265/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5049\n",
      "9266/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5094\n",
      "9267/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5043\n",
      "9268/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4986\n",
      "9269/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5037\n",
      "9270/15000:\n",
      "Training Loss: 0.4678 Validation Loss: 0.5010\n",
      "9271/15000:\n",
      "Training Loss: 0.4701 Validation Loss: 0.5075\n",
      "9272/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5009\n",
      "9273/15000:\n",
      "Training Loss: 0.4718 Validation Loss: 0.4985\n",
      "9274/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5090\n",
      "9275/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5259\n",
      "9276/15000:\n",
      "Training Loss: 0.5218 Validation Loss: 0.5060\n",
      "9277/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5041\n",
      "9278/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5000\n",
      "9279/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5009\n",
      "9280/15000:\n",
      "Training Loss: 0.4692 Validation Loss: 0.5056\n",
      "9281/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5039\n",
      "9282/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5002\n",
      "9283/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5098\n",
      "9284/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5069\n",
      "9285/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5164\n",
      "9286/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5046\n",
      "9287/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.4994\n",
      "9288/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5067\n",
      "9289/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5047\n",
      "9290/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5053\n",
      "9291/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5041\n",
      "9292/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5015\n",
      "9293/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5314\n",
      "9294/15000:\n",
      "Training Loss: 0.5247 Validation Loss: 0.5476\n",
      "9295/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5026\n",
      "9296/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5211\n",
      "9297/15000:\n",
      "Training Loss: 0.5326 Validation Loss: 0.5167\n",
      "9298/15000:\n",
      "Training Loss: 0.5253 Validation Loss: 0.5152\n",
      "9299/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4984\n",
      "9300/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5190\n",
      "9301/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5002\n",
      "9302/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4927\n",
      "9303/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4988\n",
      "9304/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5088\n",
      "9305/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4979\n",
      "9306/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5027\n",
      "9307/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.4951\n",
      "9308/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4999\n",
      "9309/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5009\n",
      "9310/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5033\n",
      "9311/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5005\n",
      "9312/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5003\n",
      "9313/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.4966\n",
      "9314/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5018\n",
      "9315/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4979\n",
      "9316/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5007\n",
      "9317/15000:\n",
      "Training Loss: 0.4705 Validation Loss: 0.4940\n",
      "9318/15000:\n",
      "Training Loss: 0.4705 Validation Loss: 0.4972\n",
      "9319/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4938\n",
      "9320/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.4968\n",
      "9321/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5044\n",
      "9322/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5015\n",
      "9323/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5014\n",
      "9324/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.4957\n",
      "9325/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.4994\n",
      "9326/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5053\n",
      "9327/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5210\n",
      "9328/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5100\n",
      "9329/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5222\n",
      "9330/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5097\n",
      "9331/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5147\n",
      "9332/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5266\n",
      "9333/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5767\n",
      "9334/15000:\n",
      "Training Loss: 0.5605 Validation Loss: 0.5352\n",
      "9335/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5136\n",
      "9336/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5190\n",
      "9337/15000:\n",
      "Training Loss: 0.5195 Validation Loss: 0.5136\n",
      "9338/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5036\n",
      "9339/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5137\n",
      "9340/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5084\n",
      "9341/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5072\n",
      "9342/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5109\n",
      "9343/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5059\n",
      "9344/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5146\n",
      "9345/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5062\n",
      "9346/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5018\n",
      "9347/15000:\n",
      "Training Loss: 0.4685 Validation Loss: 0.5077\n",
      "9348/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5072\n",
      "9349/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5008\n",
      "9350/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5109\n",
      "9351/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5085\n",
      "9352/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5062\n",
      "9353/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5014\n",
      "9354/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5002\n",
      "9355/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.4987\n",
      "9356/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.4987\n",
      "9357/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.4983\n",
      "9358/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5047\n",
      "9359/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.4959\n",
      "9360/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5030\n",
      "9361/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5158\n",
      "9362/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5326\n",
      "9363/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5113\n",
      "9364/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5007\n",
      "9365/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5063\n",
      "9366/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5001\n",
      "9367/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5051\n",
      "9368/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5026\n",
      "9369/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5004\n",
      "9370/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5053\n",
      "9371/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5093\n",
      "9372/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5019\n",
      "9373/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5117\n",
      "9374/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5125\n",
      "9375/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5068\n",
      "9376/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5143\n",
      "9377/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5094\n",
      "9378/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5056\n",
      "9379/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5022\n",
      "9380/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5053\n",
      "9381/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5080\n",
      "9382/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5033\n",
      "9383/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5039\n",
      "9384/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5114\n",
      "9385/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5021\n",
      "9386/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5100\n",
      "9387/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5361\n",
      "9388/15000:\n",
      "Training Loss: 0.5429 Validation Loss: 0.5201\n",
      "9389/15000:\n",
      "Training Loss: 0.5265 Validation Loss: 0.5114\n",
      "9390/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.4985\n",
      "9391/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5002\n",
      "9392/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5084\n",
      "9393/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5101\n",
      "9394/15000:\n",
      "Training Loss: 0.5199 Validation Loss: 0.5137\n",
      "9395/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5194\n",
      "9396/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5137\n",
      "9397/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5020\n",
      "9398/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5132\n",
      "9399/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5033\n",
      "9400/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5047\n",
      "9401/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5176\n",
      "9402/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5071\n",
      "9403/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5031\n",
      "9404/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5012\n",
      "9405/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5017\n",
      "9406/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5029\n",
      "9407/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5039\n",
      "9408/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5031\n",
      "9409/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5018\n",
      "9410/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5185\n",
      "9411/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5097\n",
      "9412/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.4996\n",
      "9413/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5021\n",
      "9414/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5054\n",
      "9415/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.4961\n",
      "9416/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5005\n",
      "9417/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4956\n",
      "9418/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.4978\n",
      "9419/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5321\n",
      "9420/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5622\n",
      "9421/15000:\n",
      "Training Loss: 0.5530 Validation Loss: 0.5387\n",
      "9422/15000:\n",
      "Training Loss: 0.5245 Validation Loss: 0.5058\n",
      "9423/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.4947\n",
      "9424/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5006\n",
      "9425/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4986\n",
      "9426/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5020\n",
      "9427/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5031\n",
      "9428/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5032\n",
      "9429/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4968\n",
      "9430/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5049\n",
      "9431/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5118\n",
      "9432/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5160\n",
      "9433/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5370\n",
      "9434/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5336\n",
      "9435/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5465\n",
      "9436/15000:\n",
      "Training Loss: 0.5447 Validation Loss: 0.5337\n",
      "9437/15000:\n",
      "Training Loss: 0.5248 Validation Loss: 0.5529\n",
      "9438/15000:\n",
      "Training Loss: 0.5313 Validation Loss: 0.5146\n",
      "9439/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5090\n",
      "9440/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5152\n",
      "9441/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5045\n",
      "9442/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5004\n",
      "9443/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5245\n",
      "9444/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5074\n",
      "9445/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4970\n",
      "9446/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5049\n",
      "9447/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5126\n",
      "9448/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5062\n",
      "9449/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5110\n",
      "9450/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5146\n",
      "9451/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5088\n",
      "9452/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5015\n",
      "9453/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5105\n",
      "9454/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.4959\n",
      "9455/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.4992\n",
      "9456/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5015\n",
      "9457/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5009\n",
      "9458/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.4986\n",
      "9459/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5007\n",
      "9460/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5012\n",
      "9461/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4932\n",
      "9462/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5088\n",
      "9463/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5360\n",
      "9464/15000:\n",
      "Training Loss: 0.5116 Validation Loss: 0.5011\n",
      "9465/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5034\n",
      "9466/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5012\n",
      "9467/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5074\n",
      "9468/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5073\n",
      "9469/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5067\n",
      "9470/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5069\n",
      "9471/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5003\n",
      "9472/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.4971\n",
      "9473/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4955\n",
      "9474/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.4941\n",
      "9475/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.4946\n",
      "9476/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4979\n",
      "9477/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5014\n",
      "9478/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5033\n",
      "9479/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.4961\n",
      "9480/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4994\n",
      "9481/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.4960\n",
      "9482/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5006\n",
      "9483/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.5061\n",
      "9484/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5049\n",
      "9485/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5197\n",
      "9486/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5279\n",
      "9487/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5702\n",
      "9488/15000:\n",
      "Training Loss: 0.5367 Validation Loss: 0.4959\n",
      "9489/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5009\n",
      "9490/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.4933\n",
      "9491/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5109\n",
      "9492/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5065\n",
      "9493/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5015\n",
      "9494/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5032\n",
      "9495/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5148\n",
      "9496/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5162\n",
      "9497/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5131\n",
      "9498/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5021\n",
      "9499/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4989\n",
      "9500/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.4966\n",
      "9501/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.4999\n",
      "9502/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5050\n",
      "9503/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4963\n",
      "9504/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4947\n",
      "9505/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5032\n",
      "9506/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5003\n",
      "9507/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5018\n",
      "9508/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5107\n",
      "9509/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5096\n",
      "9510/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5240\n",
      "9511/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5357\n",
      "9512/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5082\n",
      "9513/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5179\n",
      "9514/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5118\n",
      "9515/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5167\n",
      "9516/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5030\n",
      "9517/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.4995\n",
      "9518/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5084\n",
      "9519/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5117\n",
      "9520/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5058\n",
      "9521/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5148\n",
      "9522/15000:\n",
      "Training Loss: 0.4616 Validation Loss: 0.5087\n",
      "9523/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5132\n",
      "9524/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5010\n",
      "9525/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5038\n",
      "9526/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5061\n",
      "9527/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.4945\n",
      "9528/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5077\n",
      "9529/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5112\n",
      "9530/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5226\n",
      "9531/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.4989\n",
      "9532/15000:\n",
      "Training Loss: 0.4691 Validation Loss: 0.4983\n",
      "9533/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.4955\n",
      "9534/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5078\n",
      "9535/15000:\n",
      "Training Loss: 0.4717 Validation Loss: 0.5196\n",
      "9536/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5191\n",
      "9537/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5065\n",
      "9538/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5055\n",
      "9539/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5107\n",
      "9540/15000:\n",
      "Training Loss: 0.4682 Validation Loss: 0.4987\n",
      "9541/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5003\n",
      "9542/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5014\n",
      "9543/15000:\n",
      "Training Loss: 0.4718 Validation Loss: 0.5019\n",
      "9544/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5027\n",
      "9545/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5050\n",
      "9546/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5231\n",
      "9547/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5259\n",
      "9548/15000:\n",
      "Training Loss: 0.5225 Validation Loss: 0.5397\n",
      "9549/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5068\n",
      "9550/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5183\n",
      "9551/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5044\n",
      "9552/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5051\n",
      "9553/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5004\n",
      "9554/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5126\n",
      "9555/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5114\n",
      "9556/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5014\n",
      "9557/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5018\n",
      "9558/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5073\n",
      "9559/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4923\n",
      "9560/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.4939\n",
      "9561/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.4967\n",
      "9562/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5000\n",
      "9563/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5056\n",
      "9564/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5018\n",
      "9565/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4961\n",
      "9566/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.4991\n",
      "9567/15000:\n",
      "Training Loss: 0.4674 Validation Loss: 0.4992\n",
      "9568/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5020\n",
      "9569/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4973\n",
      "9570/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5068\n",
      "9571/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5103\n",
      "9572/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5089\n",
      "9573/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5210\n",
      "9574/15000:\n",
      "Training Loss: 0.5155 Validation Loss: 0.5133\n",
      "9575/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5040\n",
      "9576/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5136\n",
      "9577/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5073\n",
      "9578/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.4989\n",
      "9579/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5048\n",
      "9580/15000:\n",
      "Training Loss: 0.4689 Validation Loss: 0.5041\n",
      "9581/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5110\n",
      "9582/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5024\n",
      "9583/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5078\n",
      "9584/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5055\n",
      "9585/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5058\n",
      "9586/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5015\n",
      "9587/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5046\n",
      "9588/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5010\n",
      "9589/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5074\n",
      "9590/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.5105\n",
      "9591/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5087\n",
      "9592/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5160\n",
      "9593/15000:\n",
      "Training Loss: 0.4651 Validation Loss: 0.5065\n",
      "9594/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5094\n",
      "9595/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5181\n",
      "9596/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5234\n",
      "9597/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5088\n",
      "9598/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5048\n",
      "9599/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5055\n",
      "9600/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5135\n",
      "9601/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5080\n",
      "9602/15000:\n",
      "Training Loss: 0.4634 Validation Loss: 0.5140\n",
      "9603/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5091\n",
      "9604/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5160\n",
      "9605/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5011\n",
      "9606/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5016\n",
      "9607/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5002\n",
      "9608/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5106\n",
      "9609/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5032\n",
      "9610/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5023\n",
      "9611/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.4986\n",
      "9612/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.4971\n",
      "9613/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5045\n",
      "9614/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5009\n",
      "9615/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5014\n",
      "9616/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5074\n",
      "9617/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.5118\n",
      "9618/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5136\n",
      "9619/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4904\n",
      "9620/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4942\n",
      "9621/15000:\n",
      "Training Loss: 0.4647 Validation Loss: 0.4970\n",
      "9622/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4973\n",
      "9623/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5155\n",
      "9624/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5398\n",
      "9625/15000:\n",
      "Training Loss: 0.5325 Validation Loss: 0.5191\n",
      "9626/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5270\n",
      "9627/15000:\n",
      "Training Loss: 0.5180 Validation Loss: 0.5002\n",
      "9628/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5213\n",
      "9629/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5112\n",
      "9630/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5095\n",
      "9631/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5000\n",
      "9632/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5062\n",
      "9633/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5055\n",
      "9634/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5085\n",
      "9635/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5001\n",
      "9636/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.4934\n",
      "9637/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5146\n",
      "9638/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5029\n",
      "9639/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5083\n",
      "9640/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5196\n",
      "9641/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5052\n",
      "9642/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5018\n",
      "9643/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.4931\n",
      "9644/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4933\n",
      "9645/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4917\n",
      "9646/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5000\n",
      "9647/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5020\n",
      "9648/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5115\n",
      "9649/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.4993\n",
      "9650/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4981\n",
      "9651/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.4955\n",
      "9652/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5001\n",
      "9653/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.4968\n",
      "9654/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5024\n",
      "9655/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5229\n",
      "9656/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5110\n",
      "9657/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5136\n",
      "9658/15000:\n",
      "Training Loss: 0.5193 Validation Loss: 0.5057\n",
      "9659/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5085\n",
      "9660/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5098\n",
      "9661/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.5106\n",
      "9662/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.4941\n",
      "9663/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4945\n",
      "9664/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5002\n",
      "9665/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5050\n",
      "9666/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5103\n",
      "9667/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5063\n",
      "9668/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5212\n",
      "9669/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5025\n",
      "9670/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5047\n",
      "9671/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5034\n",
      "9672/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5072\n",
      "9673/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.4976\n",
      "9674/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5024\n",
      "9675/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5019\n",
      "9676/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4979\n",
      "9677/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.4983\n",
      "9678/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5024\n",
      "9679/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5086\n",
      "9680/15000:\n",
      "Training Loss: 0.4722 Validation Loss: 0.5196\n",
      "9681/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5137\n",
      "9682/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5050\n",
      "9683/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5024\n",
      "9684/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5092\n",
      "9685/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5010\n",
      "9686/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5079\n",
      "9687/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4992\n",
      "9688/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5027\n",
      "9689/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5092\n",
      "9690/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.4987\n",
      "9691/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5004\n",
      "9692/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5154\n",
      "9693/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5215\n",
      "9694/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5003\n",
      "9695/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5028\n",
      "9696/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.4985\n",
      "9697/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5014\n",
      "9698/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5115\n",
      "9699/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5028\n",
      "9700/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5063\n",
      "9701/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5002\n",
      "9702/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5046\n",
      "9703/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5087\n",
      "9704/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5068\n",
      "9705/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5110\n",
      "9706/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5040\n",
      "9707/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5222\n",
      "9708/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5066\n",
      "9709/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5057\n",
      "9710/15000:\n",
      "Training Loss: 0.4679 Validation Loss: 0.5171\n",
      "9711/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5169\n",
      "9712/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5105\n",
      "9713/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5121\n",
      "9714/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5077\n",
      "9715/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5215\n",
      "9716/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5068\n",
      "9717/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5179\n",
      "9718/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5038\n",
      "9719/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5391\n",
      "9720/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5089\n",
      "9721/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5099\n",
      "9722/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5130\n",
      "9723/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4999\n",
      "9724/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5017\n",
      "9725/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5042\n",
      "9726/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.5102\n",
      "9727/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.5070\n",
      "9728/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5014\n",
      "9729/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5065\n",
      "9730/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5021\n",
      "9731/15000:\n",
      "Training Loss: 0.4693 Validation Loss: 0.4999\n",
      "9732/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5055\n",
      "9733/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5146\n",
      "9734/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5159\n",
      "9735/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5635\n",
      "9736/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5111\n",
      "9737/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5232\n",
      "9738/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5213\n",
      "9739/15000:\n",
      "Training Loss: 0.5344 Validation Loss: 0.5257\n",
      "9740/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5064\n",
      "9741/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5104\n",
      "9742/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5037\n",
      "9743/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5035\n",
      "9744/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5049\n",
      "9745/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5095\n",
      "9746/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5040\n",
      "9747/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5042\n",
      "9748/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5115\n",
      "9749/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5055\n",
      "9750/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5023\n",
      "9751/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4971\n",
      "9752/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.4948\n",
      "9753/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5089\n",
      "9754/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5173\n",
      "9755/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5253\n",
      "9756/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5164\n",
      "9757/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5056\n",
      "9758/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5126\n",
      "9759/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5056\n",
      "9760/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5127\n",
      "9761/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5132\n",
      "9762/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5146\n",
      "9763/15000:\n",
      "Training Loss: 0.4631 Validation Loss: 0.5061\n",
      "9764/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5127\n",
      "9765/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5098\n",
      "9766/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5007\n",
      "9767/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4960\n",
      "9768/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.4989\n",
      "9769/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5084\n",
      "9770/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.4953\n",
      "9771/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.4974\n",
      "9772/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4965\n",
      "9773/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5064\n",
      "9774/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5070\n",
      "9775/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5058\n",
      "9776/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5027\n",
      "9777/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5117\n",
      "9778/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5048\n",
      "9779/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5088\n",
      "9780/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4976\n",
      "9781/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5023\n",
      "9782/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5081\n",
      "9783/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5066\n",
      "9784/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5050\n",
      "9785/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5141\n",
      "9786/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5189\n",
      "9787/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5601\n",
      "9788/15000:\n",
      "Training Loss: 0.5302 Validation Loss: 0.5180\n",
      "9789/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5118\n",
      "9790/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5064\n",
      "9791/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5017\n",
      "9792/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5053\n",
      "9793/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5060\n",
      "9794/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5115\n",
      "9795/15000:\n",
      "Training Loss: 0.4712 Validation Loss: 0.5028\n",
      "9796/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5053\n",
      "9797/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.4993\n",
      "9798/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5072\n",
      "9799/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4968\n",
      "9800/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4995\n",
      "9801/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5072\n",
      "9802/15000:\n",
      "Training Loss: 0.4672 Validation Loss: 0.5030\n",
      "9803/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4971\n",
      "9804/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.4988\n",
      "9805/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5028\n",
      "9806/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5113\n",
      "9807/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5143\n",
      "9808/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5096\n",
      "9809/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5084\n",
      "9810/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5200\n",
      "9811/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5180\n",
      "9812/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5225\n",
      "9813/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5137\n",
      "9814/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5019\n",
      "9815/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5061\n",
      "9816/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5095\n",
      "9817/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5034\n",
      "9818/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5109\n",
      "9819/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5085\n",
      "9820/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.4980\n",
      "9821/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5021\n",
      "9822/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5001\n",
      "9823/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4967\n",
      "9824/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4989\n",
      "9825/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5038\n",
      "9826/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5122\n",
      "9827/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5035\n",
      "9828/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4952\n",
      "9829/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.4969\n",
      "9830/15000:\n",
      "Training Loss: 0.4682 Validation Loss: 0.5012\n",
      "9831/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5019\n",
      "9832/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5099\n",
      "9833/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5098\n",
      "9834/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5084\n",
      "9835/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5037\n",
      "9836/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5087\n",
      "9837/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5253\n",
      "9838/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5456\n",
      "9839/15000:\n",
      "Training Loss: 0.5196 Validation Loss: 0.5114\n",
      "9840/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.4971\n",
      "9841/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5011\n",
      "9842/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5037\n",
      "9843/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5112\n",
      "9844/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5061\n",
      "9845/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5051\n",
      "9846/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5046\n",
      "9847/15000:\n",
      "Training Loss: 0.4685 Validation Loss: 0.4998\n",
      "9848/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4967\n",
      "9849/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.4942\n",
      "9850/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4996\n",
      "9851/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5022\n",
      "9852/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5063\n",
      "9853/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5040\n",
      "9854/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5115\n",
      "9855/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5117\n",
      "9856/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5087\n",
      "9857/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5121\n",
      "9858/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5027\n",
      "9859/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5122\n",
      "9860/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5297\n",
      "9861/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5151\n",
      "9862/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.4995\n",
      "9863/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4972\n",
      "9864/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4997\n",
      "9865/15000:\n",
      "Training Loss: 0.4714 Validation Loss: 0.5037\n",
      "9866/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5021\n",
      "9867/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5050\n",
      "9868/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5049\n",
      "9869/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5081\n",
      "9870/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4995\n",
      "9871/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.4996\n",
      "9872/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5042\n",
      "9873/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5037\n",
      "9874/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5135\n",
      "9875/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5162\n",
      "9876/15000:\n",
      "Training Loss: 0.4680 Validation Loss: 0.5030\n",
      "9877/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5079\n",
      "9878/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5058\n",
      "9879/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5182\n",
      "9880/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5054\n",
      "9881/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5105\n",
      "9882/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5159\n",
      "9883/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5704\n",
      "9884/15000:\n",
      "Training Loss: 0.5465 Validation Loss: 0.5050\n",
      "9885/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5014\n",
      "9886/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.4960\n",
      "9887/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5071\n",
      "9888/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5089\n",
      "9889/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5165\n",
      "9890/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5026\n",
      "9891/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4998\n",
      "9892/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5062\n",
      "9893/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5035\n",
      "9894/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5137\n",
      "9895/15000:\n",
      "Training Loss: 0.4683 Validation Loss: 0.4988\n",
      "9896/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5092\n",
      "9897/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4969\n",
      "9898/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5017\n",
      "9899/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4984\n",
      "9900/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.4994\n",
      "9901/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.4965\n",
      "9902/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5048\n",
      "9903/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5050\n",
      "9904/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5050\n",
      "9905/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5048\n",
      "9906/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4900\n",
      "9907/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.4945\n",
      "9908/15000:\n",
      "Training Loss: 0.4677 Validation Loss: 0.4952\n",
      "9909/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.4944\n",
      "9910/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5011\n",
      "9911/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.4972\n",
      "9912/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5004\n",
      "9913/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5076\n",
      "9914/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5068\n",
      "9915/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5051\n",
      "9916/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5320\n",
      "9917/15000:\n",
      "Training Loss: 0.5254 Validation Loss: 0.5709\n",
      "9918/15000:\n",
      "Training Loss: 0.5457 Validation Loss: 0.5116\n",
      "9919/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5062\n",
      "9920/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5094\n",
      "9921/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5073\n",
      "9922/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5017\n",
      "9923/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5042\n",
      "9924/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5028\n",
      "9925/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5035\n",
      "9926/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5025\n",
      "9927/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5022\n",
      "9928/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5087\n",
      "9929/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5037\n",
      "9930/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5024\n",
      "9931/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4997\n",
      "9932/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5039\n",
      "9933/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5085\n",
      "9934/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5182\n",
      "9935/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5230\n",
      "9936/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5050\n",
      "9937/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5069\n",
      "9938/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5130\n",
      "9939/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5243\n",
      "9940/15000:\n",
      "Training Loss: 0.5199 Validation Loss: 0.5152\n",
      "9941/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5313\n",
      "9942/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5085\n",
      "9943/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5057\n",
      "9944/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5027\n",
      "9945/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5018\n",
      "9946/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4997\n",
      "9947/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4976\n",
      "9948/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5040\n",
      "9949/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5030\n",
      "9950/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5067\n",
      "9951/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5060\n",
      "9952/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5104\n",
      "9953/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5111\n",
      "9954/15000:\n",
      "Training Loss: 0.4657 Validation Loss: 0.5104\n",
      "9955/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5031\n",
      "9956/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5225\n",
      "9957/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5198\n",
      "9958/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5333\n",
      "9959/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5278\n",
      "9960/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5388\n",
      "9961/15000:\n",
      "Training Loss: 0.5199 Validation Loss: 0.5204\n",
      "9962/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5135\n",
      "9963/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.5027\n",
      "9964/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5028\n",
      "9965/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5063\n",
      "9966/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5040\n",
      "9967/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5038\n",
      "9968/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4976\n",
      "9969/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5020\n",
      "9970/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5028\n",
      "9971/15000:\n",
      "Training Loss: 0.4672 Validation Loss: 0.4975\n",
      "9972/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5066\n",
      "9973/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5083\n",
      "9974/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5170\n",
      "9975/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5268\n",
      "9976/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5260\n",
      "9977/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4980\n",
      "9978/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5116\n",
      "9979/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5062\n",
      "9980/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5096\n",
      "9981/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5057\n",
      "9982/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5107\n",
      "9983/15000:\n",
      "Training Loss: 0.4648 Validation Loss: 0.5065\n",
      "9984/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5074\n",
      "9985/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5069\n",
      "9986/15000:\n",
      "Training Loss: 0.4655 Validation Loss: 0.5069\n",
      "9987/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5186\n",
      "9988/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5026\n",
      "9989/15000:\n",
      "Training Loss: 0.4722 Validation Loss: 0.5060\n",
      "9990/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5091\n",
      "9991/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5295\n",
      "9992/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5427\n",
      "9993/15000:\n",
      "Training Loss: 0.5201 Validation Loss: 0.6045\n",
      "9994/15000:\n",
      "Training Loss: 0.6092 Validation Loss: 0.5265\n",
      "9995/15000:\n",
      "Training Loss: 0.5097 Validation Loss: 0.5151\n",
      "9996/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5092\n",
      "9997/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5080\n",
      "9998/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.4984\n",
      "9999/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5106\n",
      "10000/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.4994\n",
      "10001/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.4967\n",
      "10002/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4945\n",
      "10003/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5042\n",
      "10004/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5001\n",
      "10005/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5034\n",
      "10006/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.4984\n",
      "10007/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5018\n",
      "10008/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5006\n",
      "10009/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5134\n",
      "10010/15000:\n",
      "Training Loss: 0.5037 Validation Loss: 0.5062\n",
      "10011/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5058\n",
      "10012/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5042\n",
      "10013/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5054\n",
      "10014/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5072\n",
      "10015/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5034\n",
      "10016/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5057\n",
      "10017/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5051\n",
      "10018/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5063\n",
      "10019/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5038\n",
      "10020/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5011\n",
      "10021/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5094\n",
      "10022/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5070\n",
      "10023/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4965\n",
      "10024/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5033\n",
      "10025/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5318\n",
      "10026/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5649\n",
      "10027/15000:\n",
      "Training Loss: 0.5558 Validation Loss: 0.5108\n",
      "10028/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5042\n",
      "10029/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4970\n",
      "10030/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5005\n",
      "10031/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5131\n",
      "10032/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5156\n",
      "10033/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5081\n",
      "10034/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5224\n",
      "10035/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5103\n",
      "10036/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5207\n",
      "10037/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5018\n",
      "10038/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5126\n",
      "10039/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5094\n",
      "10040/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.4962\n",
      "10041/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5015\n",
      "10042/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5023\n",
      "10043/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5102\n",
      "10044/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5192\n",
      "10045/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5195\n",
      "10046/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5150\n",
      "10047/15000:\n",
      "Training Loss: 0.5234 Validation Loss: 0.5140\n",
      "10048/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4977\n",
      "10049/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5020\n",
      "10050/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5193\n",
      "10051/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5172\n",
      "10052/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5072\n",
      "10053/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5007\n",
      "10054/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5246\n",
      "10055/15000:\n",
      "Training Loss: 0.5213 Validation Loss: 0.5113\n",
      "10056/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5126\n",
      "10057/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5164\n",
      "10058/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5236\n",
      "10059/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5164\n",
      "10060/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5283\n",
      "10061/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5279\n",
      "10062/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5175\n",
      "10063/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5224\n",
      "10064/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5181\n",
      "10065/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5181\n",
      "10066/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5192\n",
      "10067/15000:\n",
      "Training Loss: 0.4748 Validation Loss: 0.5206\n",
      "10068/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5217\n",
      "10069/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5274\n",
      "10070/15000:\n",
      "Training Loss: 0.5241 Validation Loss: 0.5285\n",
      "10071/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5395\n",
      "10072/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5260\n",
      "10073/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5268\n",
      "10074/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5175\n",
      "10075/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5216\n",
      "10076/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5125\n",
      "10077/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5093\n",
      "10078/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5258\n",
      "10079/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5173\n",
      "10080/15000:\n",
      "Training Loss: 0.5355 Validation Loss: 0.5126\n",
      "10081/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5160\n",
      "10082/15000:\n",
      "Training Loss: 0.5136 Validation Loss: 0.5057\n",
      "10083/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5095\n",
      "10084/15000:\n",
      "Training Loss: 0.5374 Validation Loss: 0.5086\n",
      "10085/15000:\n",
      "Training Loss: 0.5294 Validation Loss: 0.5065\n",
      "10086/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5075\n",
      "10087/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5080\n",
      "10088/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5118\n",
      "10089/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5184\n",
      "10090/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5198\n",
      "10091/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5102\n",
      "10092/15000:\n",
      "Training Loss: 0.5159 Validation Loss: 0.5187\n",
      "10093/15000:\n",
      "Training Loss: 0.5304 Validation Loss: 0.5143\n",
      "10094/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5181\n",
      "10095/15000:\n",
      "Training Loss: 0.5297 Validation Loss: 0.5048\n",
      "10096/15000:\n",
      "Training Loss: 0.5188 Validation Loss: 0.5017\n",
      "10097/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5067\n",
      "10098/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5074\n",
      "10099/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5132\n",
      "10100/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.4986\n",
      "10101/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5014\n",
      "10102/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5045\n",
      "10103/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5093\n",
      "10104/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5011\n",
      "10105/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4999\n",
      "10106/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.4977\n",
      "10107/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.5004\n",
      "10108/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5018\n",
      "10109/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.4983\n",
      "10110/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5004\n",
      "10111/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.4992\n",
      "10112/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5078\n",
      "10113/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5037\n",
      "10114/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5057\n",
      "10115/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5505\n",
      "10116/15000:\n",
      "Training Loss: 0.5632 Validation Loss: 0.6129\n",
      "10117/15000:\n",
      "Training Loss: 0.6041 Validation Loss: 0.7613\n",
      "10118/15000:\n",
      "Training Loss: 0.8131 Validation Loss: 0.6078\n",
      "10119/15000:\n",
      "Training Loss: 0.5874 Validation Loss: 0.5859\n",
      "10120/15000:\n",
      "Training Loss: 0.6187 Validation Loss: 0.5404\n",
      "10121/15000:\n",
      "Training Loss: 0.5429 Validation Loss: 0.5370\n",
      "10122/15000:\n",
      "Training Loss: 0.5353 Validation Loss: 0.5304\n",
      "10123/15000:\n",
      "Training Loss: 0.5325 Validation Loss: 0.5241\n",
      "10124/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5135\n",
      "10125/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5173\n",
      "10126/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5253\n",
      "10127/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5161\n",
      "10128/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5221\n",
      "10129/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5180\n",
      "10130/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5168\n",
      "10131/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5135\n",
      "10132/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5254\n",
      "10133/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5187\n",
      "10134/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5105\n",
      "10135/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5099\n",
      "10136/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5144\n",
      "10137/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5101\n",
      "10138/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5125\n",
      "10139/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5127\n",
      "10140/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5124\n",
      "10141/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5211\n",
      "10142/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5155\n",
      "10143/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5028\n",
      "10144/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5177\n",
      "10145/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5176\n",
      "10146/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5141\n",
      "10147/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5125\n",
      "10148/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5108\n",
      "10149/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5160\n",
      "10150/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5150\n",
      "10151/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5350\n",
      "10152/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5254\n",
      "10153/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5006\n",
      "10154/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5027\n",
      "10155/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.4995\n",
      "10156/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5051\n",
      "10157/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5356\n",
      "10158/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5050\n",
      "10159/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5012\n",
      "10160/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5004\n",
      "10161/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5098\n",
      "10162/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5035\n",
      "10163/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.4971\n",
      "10164/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5180\n",
      "10165/15000:\n",
      "Training Loss: 0.5190 Validation Loss: 0.5208\n",
      "10166/15000:\n",
      "Training Loss: 0.5222 Validation Loss: 0.5094\n",
      "10167/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5125\n",
      "10168/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5146\n",
      "10169/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5197\n",
      "10170/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5198\n",
      "10171/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5272\n",
      "10172/15000:\n",
      "Training Loss: 0.5179 Validation Loss: 0.5150\n",
      "10173/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5045\n",
      "10174/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5056\n",
      "10175/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.4936\n",
      "10176/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5011\n",
      "10177/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5033\n",
      "10178/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5204\n",
      "10179/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5104\n",
      "10180/15000:\n",
      "Training Loss: 0.5087 Validation Loss: 0.5105\n",
      "10181/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4974\n",
      "10182/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4998\n",
      "10183/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5015\n",
      "10184/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5193\n",
      "10185/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5062\n",
      "10186/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5021\n",
      "10187/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5077\n",
      "10188/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5040\n",
      "10189/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5290\n",
      "10190/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5288\n",
      "10191/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5433\n",
      "10192/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5339\n",
      "10193/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5030\n",
      "10194/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.4995\n",
      "10195/15000:\n",
      "Training Loss: 0.4705 Validation Loss: 0.4971\n",
      "10196/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5056\n",
      "10197/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5118\n",
      "10198/15000:\n",
      "Training Loss: 0.4707 Validation Loss: 0.5058\n",
      "10199/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5014\n",
      "10200/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.4948\n",
      "10201/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5049\n",
      "10202/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4974\n",
      "10203/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4956\n",
      "10204/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4941\n",
      "10205/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5407\n",
      "10206/15000:\n",
      "Training Loss: 0.5609 Validation Loss: 0.5124\n",
      "10207/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5413\n",
      "10208/15000:\n",
      "Training Loss: 0.5319 Validation Loss: 0.5104\n",
      "10209/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5200\n",
      "10210/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5137\n",
      "10211/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5054\n",
      "10212/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5126\n",
      "10213/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5028\n",
      "10214/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5145\n",
      "10215/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5086\n",
      "10216/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5015\n",
      "10217/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5155\n",
      "10218/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5005\n",
      "10219/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5036\n",
      "10220/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5069\n",
      "10221/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5028\n",
      "10222/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5009\n",
      "10223/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4961\n",
      "10224/15000:\n",
      "Training Loss: 0.4722 Validation Loss: 0.5028\n",
      "10225/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5059\n",
      "10226/15000:\n",
      "Training Loss: 0.4720 Validation Loss: 0.4981\n",
      "10227/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4990\n",
      "10228/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.5014\n",
      "10229/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5038\n",
      "10230/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4945\n",
      "10231/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5001\n",
      "10232/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4978\n",
      "10233/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5040\n",
      "10234/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5076\n",
      "10235/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4983\n",
      "10236/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5020\n",
      "10237/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.4979\n",
      "10238/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5005\n",
      "10239/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5018\n",
      "10240/15000:\n",
      "Training Loss: 0.4695 Validation Loss: 0.5053\n",
      "10241/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5061\n",
      "10242/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.4983\n",
      "10243/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5026\n",
      "10244/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5022\n",
      "10245/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5047\n",
      "10246/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5024\n",
      "10247/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5071\n",
      "10248/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5006\n",
      "10249/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5158\n",
      "10250/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5226\n",
      "10251/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5110\n",
      "10252/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5050\n",
      "10253/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5157\n",
      "10254/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5181\n",
      "10255/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5285\n",
      "10256/15000:\n",
      "Training Loss: 0.5375 Validation Loss: 0.5102\n",
      "10257/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5014\n",
      "10258/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5000\n",
      "10259/15000:\n",
      "Training Loss: 0.4667 Validation Loss: 0.5127\n",
      "10260/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5156\n",
      "10261/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5025\n",
      "10262/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5043\n",
      "10263/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4988\n",
      "10264/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.5060\n",
      "10265/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5012\n",
      "10266/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5087\n",
      "10267/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5064\n",
      "10268/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4988\n",
      "10269/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5022\n",
      "10270/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4880\n",
      "10271/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4899\n",
      "10272/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.4869\n",
      "10273/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5025\n",
      "10274/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.4952\n",
      "10275/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5258\n",
      "10276/15000:\n",
      "Training Loss: 0.5274 Validation Loss: 0.5257\n",
      "10277/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5344\n",
      "10278/15000:\n",
      "Training Loss: 0.5411 Validation Loss: 0.5442\n",
      "10279/15000:\n",
      "Training Loss: 0.5225 Validation Loss: 0.5872\n",
      "10280/15000:\n",
      "Training Loss: 0.6257 Validation Loss: 0.5260\n",
      "10281/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5090\n",
      "10282/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5070\n",
      "10283/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5026\n",
      "10284/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5021\n",
      "10285/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5059\n",
      "10286/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5174\n",
      "10287/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5043\n",
      "10288/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5038\n",
      "10289/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4990\n",
      "10290/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5107\n",
      "10291/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5082\n",
      "10292/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5133\n",
      "10293/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5019\n",
      "10294/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5071\n",
      "10295/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5033\n",
      "10296/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4962\n",
      "10297/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5079\n",
      "10298/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5178\n",
      "10299/15000:\n",
      "Training Loss: 0.5389 Validation Loss: 0.5116\n",
      "10300/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5001\n",
      "10301/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5117\n",
      "10302/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5027\n",
      "10303/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5089\n",
      "10304/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5042\n",
      "10305/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5098\n",
      "10306/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5222\n",
      "10307/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5286\n",
      "10308/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5018\n",
      "10309/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5028\n",
      "10310/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5101\n",
      "10311/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5079\n",
      "10312/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5348\n",
      "10313/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5210\n",
      "10314/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5084\n",
      "10315/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5029\n",
      "10316/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5074\n",
      "10317/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5043\n",
      "10318/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5078\n",
      "10319/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5035\n",
      "10320/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5090\n",
      "10321/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4979\n",
      "10322/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5057\n",
      "10323/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5008\n",
      "10324/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5010\n",
      "10325/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5031\n",
      "10326/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4994\n",
      "10327/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.4973\n",
      "10328/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5100\n",
      "10329/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5077\n",
      "10330/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5040\n",
      "10331/15000:\n",
      "Training Loss: 0.4715 Validation Loss: 0.5097\n",
      "10332/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5094\n",
      "10333/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5110\n",
      "10334/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5135\n",
      "10335/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5113\n",
      "10336/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5080\n",
      "10337/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5192\n",
      "10338/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5168\n",
      "10339/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5169\n",
      "10340/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5085\n",
      "10341/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4973\n",
      "10342/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.4974\n",
      "10343/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4977\n",
      "10344/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.4942\n",
      "10345/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5002\n",
      "10346/15000:\n",
      "Training Loss: 0.4617 Validation Loss: 0.5030\n",
      "10347/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5118\n",
      "10348/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5403\n",
      "10349/15000:\n",
      "Training Loss: 0.5163 Validation Loss: 0.5477\n",
      "10350/15000:\n",
      "Training Loss: 0.5217 Validation Loss: 0.5366\n",
      "10351/15000:\n",
      "Training Loss: 0.5292 Validation Loss: 0.5602\n",
      "10352/15000:\n",
      "Training Loss: 0.5686 Validation Loss: 0.5089\n",
      "10353/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5008\n",
      "10354/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4985\n",
      "10355/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5088\n",
      "10356/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5080\n",
      "10357/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5129\n",
      "10358/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5119\n",
      "10359/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5211\n",
      "10360/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5197\n",
      "10361/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5136\n",
      "10362/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5215\n",
      "10363/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5061\n",
      "10364/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5042\n",
      "10365/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5020\n",
      "10366/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5018\n",
      "10367/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5018\n",
      "10368/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5054\n",
      "10369/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5057\n",
      "10370/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5006\n",
      "10371/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5134\n",
      "10372/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5090\n",
      "10373/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5311\n",
      "10374/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5341\n",
      "10375/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5151\n",
      "10376/15000:\n",
      "Training Loss: 0.5229 Validation Loss: 0.5029\n",
      "10377/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.5077\n",
      "10378/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5040\n",
      "10379/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4969\n",
      "10380/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4966\n",
      "10381/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.4929\n",
      "10382/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4964\n",
      "10383/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5118\n",
      "10384/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5063\n",
      "10385/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5025\n",
      "10386/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5010\n",
      "10387/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4934\n",
      "10388/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.4991\n",
      "10389/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.4978\n",
      "10390/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5152\n",
      "10391/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5076\n",
      "10392/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5319\n",
      "10393/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5155\n",
      "10394/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5047\n",
      "10395/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5046\n",
      "10396/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4965\n",
      "10397/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4988\n",
      "10398/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5014\n",
      "10399/15000:\n",
      "Training Loss: 0.4690 Validation Loss: 0.4996\n",
      "10400/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5056\n",
      "10401/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5099\n",
      "10402/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5064\n",
      "10403/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5052\n",
      "10404/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5017\n",
      "10405/15000:\n",
      "Training Loss: 0.4710 Validation Loss: 0.5057\n",
      "10406/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5146\n",
      "10407/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5190\n",
      "10408/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5274\n",
      "10409/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5265\n",
      "10410/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.4972\n",
      "10411/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5073\n",
      "10412/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5017\n",
      "10413/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5033\n",
      "10414/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5022\n",
      "10415/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5050\n",
      "10416/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5094\n",
      "10417/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5096\n",
      "10418/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5099\n",
      "10419/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5028\n",
      "10420/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5020\n",
      "10421/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5126\n",
      "10422/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5170\n",
      "10423/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5045\n",
      "10424/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4994\n",
      "10425/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4998\n",
      "10426/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5001\n",
      "10427/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5119\n",
      "10428/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5176\n",
      "10429/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5361\n",
      "10430/15000:\n",
      "Training Loss: 0.5263 Validation Loss: 0.5245\n",
      "10431/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5055\n",
      "10432/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5241\n",
      "10433/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5104\n",
      "10434/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5059\n",
      "10435/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5195\n",
      "10436/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5193\n",
      "10437/15000:\n",
      "Training Loss: 0.5177 Validation Loss: 0.5155\n",
      "10438/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5402\n",
      "10439/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.5197\n",
      "10440/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5278\n",
      "10441/15000:\n",
      "Training Loss: 0.5143 Validation Loss: 0.5105\n",
      "10442/15000:\n",
      "Training Loss: 0.5132 Validation Loss: 0.5052\n",
      "10443/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5057\n",
      "10444/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5151\n",
      "10445/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5064\n",
      "10446/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5192\n",
      "10447/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5134\n",
      "10448/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5268\n",
      "10449/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5154\n",
      "10450/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5106\n",
      "10451/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5394\n",
      "10452/15000:\n",
      "Training Loss: 0.5590 Validation Loss: 0.5307\n",
      "10453/15000:\n",
      "Training Loss: 0.5223 Validation Loss: 0.5078\n",
      "10454/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5112\n",
      "10455/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5091\n",
      "10456/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5052\n",
      "10457/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5103\n",
      "10458/15000:\n",
      "Training Loss: 0.5178 Validation Loss: 0.5251\n",
      "10459/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5087\n",
      "10460/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5107\n",
      "10461/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.4998\n",
      "10462/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5123\n",
      "10463/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5069\n",
      "10464/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5011\n",
      "10465/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5037\n",
      "10466/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.5098\n",
      "10467/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5070\n",
      "10468/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5130\n",
      "10469/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5073\n",
      "10470/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5089\n",
      "10471/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5117\n",
      "10472/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5178\n",
      "10473/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5103\n",
      "10474/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5085\n",
      "10475/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5135\n",
      "10476/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5046\n",
      "10477/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5120\n",
      "10478/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5107\n",
      "10479/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5063\n",
      "10480/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5065\n",
      "10481/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.5145\n",
      "10482/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5084\n",
      "10483/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5070\n",
      "10484/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5101\n",
      "10485/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5069\n",
      "10486/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5129\n",
      "10487/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5146\n",
      "10488/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5106\n",
      "10489/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5048\n",
      "10490/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5067\n",
      "10491/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5022\n",
      "10492/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5016\n",
      "10493/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5005\n",
      "10494/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4994\n",
      "10495/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5065\n",
      "10496/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5050\n",
      "10497/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5099\n",
      "10498/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5055\n",
      "10499/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5017\n",
      "10500/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5036\n",
      "10501/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.4986\n",
      "10502/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5028\n",
      "10503/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5085\n",
      "10504/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5045\n",
      "10505/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5028\n",
      "10506/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5043\n",
      "10507/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5068\n",
      "10508/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5101\n",
      "10509/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5042\n",
      "10510/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5030\n",
      "10511/15000:\n",
      "Training Loss: 0.4748 Validation Loss: 0.5002\n",
      "10512/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5029\n",
      "10513/15000:\n",
      "Training Loss: 0.4693 Validation Loss: 0.5048\n",
      "10514/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5188\n",
      "10515/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5117\n",
      "10516/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5137\n",
      "10517/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5043\n",
      "10518/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5090\n",
      "10519/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5003\n",
      "10520/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5019\n",
      "10521/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5033\n",
      "10522/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.4941\n",
      "10523/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.5045\n",
      "10524/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5044\n",
      "10525/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5125\n",
      "10526/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5200\n",
      "10527/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5061\n",
      "10528/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5069\n",
      "10529/15000:\n",
      "Training Loss: 0.4644 Validation Loss: 0.5026\n",
      "10530/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5086\n",
      "10531/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.4993\n",
      "10532/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4988\n",
      "10533/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.5019\n",
      "10534/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5051\n",
      "10535/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5037\n",
      "10536/15000:\n",
      "Training Loss: 0.4719 Validation Loss: 0.5132\n",
      "10537/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5055\n",
      "10538/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5080\n",
      "10539/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5050\n",
      "10540/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5025\n",
      "10541/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5389\n",
      "10542/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5418\n",
      "10543/15000:\n",
      "Training Loss: 0.5166 Validation Loss: 0.5107\n",
      "10544/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5021\n",
      "10545/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5114\n",
      "10546/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5037\n",
      "10547/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5074\n",
      "10548/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4965\n",
      "10549/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.4967\n",
      "10550/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5002\n",
      "10551/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.4972\n",
      "10552/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4974\n",
      "10553/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5003\n",
      "10554/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.4981\n",
      "10555/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4930\n",
      "10556/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.4967\n",
      "10557/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5063\n",
      "10558/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4973\n",
      "10559/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4986\n",
      "10560/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5020\n",
      "10561/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4956\n",
      "10562/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5033\n",
      "10563/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5213\n",
      "10564/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5376\n",
      "10565/15000:\n",
      "Training Loss: 0.5442 Validation Loss: 0.5014\n",
      "10566/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.4964\n",
      "10567/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4943\n",
      "10568/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5045\n",
      "10569/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.4994\n",
      "10570/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4983\n",
      "10571/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5050\n",
      "10572/15000:\n",
      "Training Loss: 0.4666 Validation Loss: 0.5056\n",
      "10573/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5042\n",
      "10574/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5089\n",
      "10575/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5015\n",
      "10576/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5048\n",
      "10577/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5053\n",
      "10578/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5028\n",
      "10579/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5155\n",
      "10580/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5258\n",
      "10581/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5182\n",
      "10582/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5010\n",
      "10583/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5059\n",
      "10584/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5122\n",
      "10585/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5043\n",
      "10586/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5224\n",
      "10587/15000:\n",
      "Training Loss: 0.5149 Validation Loss: 0.5661\n",
      "10588/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.5182\n",
      "10589/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5241\n",
      "10590/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5042\n",
      "10591/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5138\n",
      "10592/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5069\n",
      "10593/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5039\n",
      "10594/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5014\n",
      "10595/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5021\n",
      "10596/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5064\n",
      "10597/15000:\n",
      "Training Loss: 0.4691 Validation Loss: 0.5009\n",
      "10598/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5038\n",
      "10599/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5012\n",
      "10600/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5105\n",
      "10601/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5105\n",
      "10602/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5175\n",
      "10603/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5074\n",
      "10604/15000:\n",
      "Training Loss: 0.4715 Validation Loss: 0.5086\n",
      "10605/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5067\n",
      "10606/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5005\n",
      "10607/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5067\n",
      "10608/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.4949\n",
      "10609/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4912\n",
      "10610/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4954\n",
      "10611/15000:\n",
      "Training Loss: 0.4622 Validation Loss: 0.4992\n",
      "10612/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4988\n",
      "10613/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4980\n",
      "10614/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5016\n",
      "10615/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5066\n",
      "10616/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5066\n",
      "10617/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5109\n",
      "10618/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5080\n",
      "10619/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5096\n",
      "10620/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5067\n",
      "10621/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.4965\n",
      "10622/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4941\n",
      "10623/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5170\n",
      "10624/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5072\n",
      "10625/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5144\n",
      "10626/15000:\n",
      "Training Loss: 0.5330 Validation Loss: 0.5165\n",
      "10627/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5041\n",
      "10628/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5094\n",
      "10629/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5012\n",
      "10630/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5021\n",
      "10631/15000:\n",
      "Training Loss: 0.4583 Validation Loss: 0.5009\n",
      "10632/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5035\n",
      "10633/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5031\n",
      "10634/15000:\n",
      "Training Loss: 0.4689 Validation Loss: 0.5106\n",
      "10635/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5042\n",
      "10636/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5135\n",
      "10637/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5154\n",
      "10638/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5012\n",
      "10639/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.4995\n",
      "10640/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5055\n",
      "10641/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5063\n",
      "10642/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5854\n",
      "10643/15000:\n",
      "Training Loss: 0.5938 Validation Loss: 0.5281\n",
      "10644/15000:\n",
      "Training Loss: 0.5189 Validation Loss: 0.5016\n",
      "10645/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.4993\n",
      "10646/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4973\n",
      "10647/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5011\n",
      "10648/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5007\n",
      "10649/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5005\n",
      "10650/15000:\n",
      "Training Loss: 0.4529 Validation Loss: 0.4966\n",
      "10651/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4981\n",
      "10652/15000:\n",
      "Training Loss: 0.4667 Validation Loss: 0.5108\n",
      "10653/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5103\n",
      "10654/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5032\n",
      "10655/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5083\n",
      "10656/15000:\n",
      "Training Loss: 0.4564 Validation Loss: 0.5002\n",
      "10657/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5120\n",
      "10658/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5118\n",
      "10659/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5026\n",
      "10660/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5002\n",
      "10661/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.5026\n",
      "10662/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.5011\n",
      "10663/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5119\n",
      "10664/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4973\n",
      "10665/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5039\n",
      "10666/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4975\n",
      "10667/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5042\n",
      "10668/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.4983\n",
      "10669/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5097\n",
      "10670/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5060\n",
      "10671/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5069\n",
      "10672/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5001\n",
      "10673/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.4958\n",
      "10674/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4937\n",
      "10675/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5020\n",
      "10676/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.4983\n",
      "10677/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5023\n",
      "10678/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5025\n",
      "10679/15000:\n",
      "Training Loss: 0.4705 Validation Loss: 0.5098\n",
      "10680/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5180\n",
      "10681/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5112\n",
      "10682/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5043\n",
      "10683/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5738\n",
      "10684/15000:\n",
      "Training Loss: 0.5338 Validation Loss: 0.5074\n",
      "10685/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5151\n",
      "10686/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.4962\n",
      "10687/15000:\n",
      "Training Loss: 0.4696 Validation Loss: 0.5135\n",
      "10688/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5063\n",
      "10689/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5043\n",
      "10690/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5129\n",
      "10691/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5005\n",
      "10692/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5030\n",
      "10693/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5026\n",
      "10694/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5008\n",
      "10695/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5038\n",
      "10696/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5084\n",
      "10697/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5091\n",
      "10698/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5050\n",
      "10699/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.4976\n",
      "10700/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.4983\n",
      "10701/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.4998\n",
      "10702/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5028\n",
      "10703/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5060\n",
      "10704/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5064\n",
      "10705/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.5094\n",
      "10706/15000:\n",
      "Training Loss: 0.5059 Validation Loss: 0.5110\n",
      "10707/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5151\n",
      "10708/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5050\n",
      "10709/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5025\n",
      "10710/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4996\n",
      "10711/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5024\n",
      "10712/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5077\n",
      "10713/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5210\n",
      "10714/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5045\n",
      "10715/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5035\n",
      "10716/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4996\n",
      "10717/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4994\n",
      "10718/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5030\n",
      "10719/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.4961\n",
      "10720/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5102\n",
      "10721/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5063\n",
      "10722/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.4995\n",
      "10723/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5013\n",
      "10724/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5115\n",
      "10725/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5037\n",
      "10726/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5012\n",
      "10727/15000:\n",
      "Training Loss: 0.4712 Validation Loss: 0.5245\n",
      "10728/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5087\n",
      "10729/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5013\n",
      "10730/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5080\n",
      "10731/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5052\n",
      "10732/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5164\n",
      "10733/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5124\n",
      "10734/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4991\n",
      "10735/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5076\n",
      "10736/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.4991\n",
      "10737/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5106\n",
      "10738/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.4997\n",
      "10739/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5265\n",
      "10740/15000:\n",
      "Training Loss: 0.5228 Validation Loss: 0.5434\n",
      "10741/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.5075\n",
      "10742/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5091\n",
      "10743/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5074\n",
      "10744/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5070\n",
      "10745/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5040\n",
      "10746/15000:\n",
      "Training Loss: 0.4708 Validation Loss: 0.5123\n",
      "10747/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5509\n",
      "10748/15000:\n",
      "Training Loss: 0.5197 Validation Loss: 0.5257\n",
      "10749/15000:\n",
      "Training Loss: 0.5296 Validation Loss: 0.5164\n",
      "10750/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5259\n",
      "10751/15000:\n",
      "Training Loss: 0.5153 Validation Loss: 0.5099\n",
      "10752/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5017\n",
      "10753/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5137\n",
      "10754/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5056\n",
      "10755/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5053\n",
      "10756/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5093\n",
      "10757/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5026\n",
      "10758/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5138\n",
      "10759/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5066\n",
      "10760/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5110\n",
      "10761/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5252\n",
      "10762/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5282\n",
      "10763/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5166\n",
      "10764/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5004\n",
      "10765/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5023\n",
      "10766/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5084\n",
      "10767/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5057\n",
      "10768/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5137\n",
      "10769/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5128\n",
      "10770/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5120\n",
      "10771/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5036\n",
      "10772/15000:\n",
      "Training Loss: 0.4661 Validation Loss: 0.5095\n",
      "10773/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5052\n",
      "10774/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5067\n",
      "10775/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5057\n",
      "10776/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5001\n",
      "10777/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5218\n",
      "10778/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5209\n",
      "10779/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5195\n",
      "10780/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5404\n",
      "10781/15000:\n",
      "Training Loss: 0.5699 Validation Loss: 0.5001\n",
      "10782/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5016\n",
      "10783/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5010\n",
      "10784/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5019\n",
      "10785/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5002\n",
      "10786/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.4994\n",
      "10787/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.4986\n",
      "10788/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4926\n",
      "10789/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4987\n",
      "10790/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4988\n",
      "10791/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4997\n",
      "10792/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5111\n",
      "10793/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5004\n",
      "10794/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5134\n",
      "10795/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5123\n",
      "10796/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5042\n",
      "10797/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5027\n",
      "10798/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5014\n",
      "10799/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4976\n",
      "10800/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.4997\n",
      "10801/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5092\n",
      "10802/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5254\n",
      "10803/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5150\n",
      "10804/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.4959\n",
      "10805/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5049\n",
      "10806/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5013\n",
      "10807/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5145\n",
      "10808/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5054\n",
      "10809/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4999\n",
      "10810/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5146\n",
      "10811/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5203\n",
      "10812/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5078\n",
      "10813/15000:\n",
      "Training Loss: 0.5155 Validation Loss: 0.5052\n",
      "10814/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5018\n",
      "10815/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5006\n",
      "10816/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4992\n",
      "10817/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5061\n",
      "10818/15000:\n",
      "Training Loss: 0.4653 Validation Loss: 0.4945\n",
      "10819/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4979\n",
      "10820/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5022\n",
      "10821/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5052\n",
      "10822/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.4974\n",
      "10823/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.4915\n",
      "10824/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4938\n",
      "10825/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5000\n",
      "10826/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4931\n",
      "10827/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4964\n",
      "10828/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.4972\n",
      "10829/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4922\n",
      "10830/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5033\n",
      "10831/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5050\n",
      "10832/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5293\n",
      "10833/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.4957\n",
      "10834/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5026\n",
      "10835/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.4987\n",
      "10836/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.4946\n",
      "10837/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.4947\n",
      "10838/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.4989\n",
      "10839/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5040\n",
      "10840/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5067\n",
      "10841/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5207\n",
      "10842/15000:\n",
      "Training Loss: 0.5071 Validation Loss: 0.5024\n",
      "10843/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5083\n",
      "10844/15000:\n",
      "Training Loss: 0.4622 Validation Loss: 0.5047\n",
      "10845/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5013\n",
      "10846/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.4972\n",
      "10847/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5034\n",
      "10848/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4983\n",
      "10849/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5040\n",
      "10850/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5101\n",
      "10851/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5251\n",
      "10852/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5406\n",
      "10853/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5145\n",
      "10854/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5030\n",
      "10855/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5018\n",
      "10856/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5122\n",
      "10857/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5145\n",
      "10858/15000:\n",
      "Training Loss: 0.5083 Validation Loss: 0.5007\n",
      "10859/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5044\n",
      "10860/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.4981\n",
      "10861/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5039\n",
      "10862/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5064\n",
      "10863/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5099\n",
      "10864/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.4986\n",
      "10865/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5092\n",
      "10866/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5038\n",
      "10867/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5061\n",
      "10868/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5073\n",
      "10869/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5054\n",
      "10870/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.4982\n",
      "10871/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5085\n",
      "10872/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.4958\n",
      "10873/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.4947\n",
      "10874/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5013\n",
      "10875/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5086\n",
      "10876/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4998\n",
      "10877/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5096\n",
      "10878/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5043\n",
      "10879/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5017\n",
      "10880/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.4977\n",
      "10881/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4936\n",
      "10882/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5045\n",
      "10883/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5017\n",
      "10884/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5042\n",
      "10885/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5249\n",
      "10886/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5023\n",
      "10887/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5073\n",
      "10888/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5074\n",
      "10889/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5176\n",
      "10890/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5198\n",
      "10891/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5301\n",
      "10892/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5168\n",
      "10893/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5220\n",
      "10894/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.4980\n",
      "10895/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5239\n",
      "10896/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5096\n",
      "10897/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5030\n",
      "10898/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5081\n",
      "10899/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5031\n",
      "10900/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5049\n",
      "10901/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5088\n",
      "10902/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5101\n",
      "10903/15000:\n",
      "Training Loss: 0.4671 Validation Loss: 0.5153\n",
      "10904/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5079\n",
      "10905/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5221\n",
      "10906/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.5395\n",
      "10907/15000:\n",
      "Training Loss: 0.5214 Validation Loss: 0.5212\n",
      "10908/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5022\n",
      "10909/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5035\n",
      "10910/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5006\n",
      "10911/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5012\n",
      "10912/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4998\n",
      "10913/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5047\n",
      "10914/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5020\n",
      "10915/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5043\n",
      "10916/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5007\n",
      "10917/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.4945\n",
      "10918/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.4973\n",
      "10919/15000:\n",
      "Training Loss: 0.4705 Validation Loss: 0.5021\n",
      "10920/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5106\n",
      "10921/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5225\n",
      "10922/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.5049\n",
      "10923/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.4993\n",
      "10924/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5124\n",
      "10925/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5115\n",
      "10926/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5227\n",
      "10927/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5121\n",
      "10928/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5196\n",
      "10929/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5214\n",
      "10930/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5109\n",
      "10931/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5012\n",
      "10932/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5007\n",
      "10933/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5269\n",
      "10934/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5097\n",
      "10935/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.4995\n",
      "10936/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5041\n",
      "10937/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5037\n",
      "10938/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5022\n",
      "10939/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5110\n",
      "10940/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5115\n",
      "10941/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5080\n",
      "10942/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5120\n",
      "10943/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5400\n",
      "10944/15000:\n",
      "Training Loss: 0.5255 Validation Loss: 0.5368\n",
      "10945/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5100\n",
      "10946/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4986\n",
      "10947/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5019\n",
      "10948/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5058\n",
      "10949/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.5040\n",
      "10950/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5075\n",
      "10951/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5251\n",
      "10952/15000:\n",
      "Training Loss: 0.4715 Validation Loss: 0.5123\n",
      "10953/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5097\n",
      "10954/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5111\n",
      "10955/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5203\n",
      "10956/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5160\n",
      "10957/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5201\n",
      "10958/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5237\n",
      "10959/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5205\n",
      "10960/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5094\n",
      "10961/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4997\n",
      "10962/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.4969\n",
      "10963/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5055\n",
      "10964/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5122\n",
      "10965/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5030\n",
      "10966/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5188\n",
      "10967/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5508\n",
      "10968/15000:\n",
      "Training Loss: 0.5265 Validation Loss: 0.5182\n",
      "10969/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5100\n",
      "10970/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5068\n",
      "10971/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5105\n",
      "10972/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5128\n",
      "10973/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5061\n",
      "10974/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5098\n",
      "10975/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5010\n",
      "10976/15000:\n",
      "Training Loss: 0.4618 Validation Loss: 0.5154\n",
      "10977/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5064\n",
      "10978/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5076\n",
      "10979/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5165\n",
      "10980/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5352\n",
      "10981/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5170\n",
      "10982/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5079\n",
      "10983/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.4956\n",
      "10984/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5064\n",
      "10985/15000:\n",
      "Training Loss: 0.4588 Validation Loss: 0.5056\n",
      "10986/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5095\n",
      "10987/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5091\n",
      "10988/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5058\n",
      "10989/15000:\n",
      "Training Loss: 0.4677 Validation Loss: 0.5056\n",
      "10990/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.4960\n",
      "10991/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5070\n",
      "10992/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5081\n",
      "10993/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5194\n",
      "10994/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5070\n",
      "10995/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5056\n",
      "10996/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5024\n",
      "10997/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.4990\n",
      "10998/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4996\n",
      "10999/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.4989\n",
      "11000/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5029\n",
      "11001/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5058\n",
      "11002/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5050\n",
      "11003/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5187\n",
      "11004/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5038\n",
      "11005/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5281\n",
      "11006/15000:\n",
      "Training Loss: 0.5169 Validation Loss: 0.5326\n",
      "11007/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5182\n",
      "11008/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.4982\n",
      "11009/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5066\n",
      "11010/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4982\n",
      "11011/15000:\n",
      "Training Loss: 0.4669 Validation Loss: 0.5058\n",
      "11012/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5048\n",
      "11013/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5205\n",
      "11014/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5333\n",
      "11015/15000:\n",
      "Training Loss: 0.5216 Validation Loss: 0.5653\n",
      "11016/15000:\n",
      "Training Loss: 0.5555 Validation Loss: 0.5152\n",
      "11017/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5129\n",
      "11018/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5012\n",
      "11019/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.4973\n",
      "11020/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5050\n",
      "11021/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.4982\n",
      "11022/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5038\n",
      "11023/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5095\n",
      "11024/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5015\n",
      "11025/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5053\n",
      "11026/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5037\n",
      "11027/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5007\n",
      "11028/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5050\n",
      "11029/15000:\n",
      "Training Loss: 0.4693 Validation Loss: 0.5134\n",
      "11030/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5117\n",
      "11031/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5108\n",
      "11032/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5116\n",
      "11033/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5066\n",
      "11034/15000:\n",
      "Training Loss: 0.4637 Validation Loss: 0.5057\n",
      "11035/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5083\n",
      "11036/15000:\n",
      "Training Loss: 0.4699 Validation Loss: 0.5082\n",
      "11037/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5078\n",
      "11038/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5079\n",
      "11039/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5073\n",
      "11040/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5072\n",
      "11041/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5018\n",
      "11042/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5070\n",
      "11043/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5048\n",
      "11044/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5400\n",
      "11045/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5536\n",
      "11046/15000:\n",
      "Training Loss: 0.5281 Validation Loss: 0.5154\n",
      "11047/15000:\n",
      "Training Loss: 0.5231 Validation Loss: 0.5092\n",
      "11048/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5065\n",
      "11049/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5006\n",
      "11050/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5066\n",
      "11051/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.4973\n",
      "11052/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5074\n",
      "11053/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5056\n",
      "11054/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5075\n",
      "11055/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5022\n",
      "11056/15000:\n",
      "Training Loss: 0.4674 Validation Loss: 0.5063\n",
      "11057/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5069\n",
      "11058/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5064\n",
      "11059/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5029\n",
      "11060/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5129\n",
      "11061/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5159\n",
      "11062/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.4953\n",
      "11063/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5010\n",
      "11064/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5048\n",
      "11065/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5018\n",
      "11066/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5059\n",
      "11067/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5032\n",
      "11068/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5091\n",
      "11069/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5033\n",
      "11070/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5045\n",
      "11071/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4998\n",
      "11072/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5107\n",
      "11073/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5095\n",
      "11074/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5054\n",
      "11075/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5134\n",
      "11076/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5016\n",
      "11077/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5318\n",
      "11078/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5331\n",
      "11079/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5470\n",
      "11080/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5115\n",
      "11081/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5146\n",
      "11082/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5033\n",
      "11083/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5029\n",
      "11084/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5033\n",
      "11085/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5086\n",
      "11086/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5051\n",
      "11087/15000:\n",
      "Training Loss: 0.4643 Validation Loss: 0.5060\n",
      "11088/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5063\n",
      "11089/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5057\n",
      "11090/15000:\n",
      "Training Loss: 0.4668 Validation Loss: 0.5030\n",
      "11091/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5083\n",
      "11092/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5044\n",
      "11093/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5008\n",
      "11094/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5177\n",
      "11095/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5142\n",
      "11096/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5250\n",
      "11097/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5020\n",
      "11098/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.4970\n",
      "11099/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.5035\n",
      "11100/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5076\n",
      "11101/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5247\n",
      "11102/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.4976\n",
      "11103/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5213\n",
      "11104/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5103\n",
      "11105/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5115\n",
      "11106/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5069\n",
      "11107/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5123\n",
      "11108/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5036\n",
      "11109/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5089\n",
      "11110/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5015\n",
      "11111/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5024\n",
      "11112/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5026\n",
      "11113/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.5096\n",
      "11114/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5020\n",
      "11115/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5114\n",
      "11116/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4937\n",
      "11117/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.4974\n",
      "11118/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.4964\n",
      "11119/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.4943\n",
      "11120/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4997\n",
      "11121/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.4995\n",
      "11122/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5051\n",
      "11123/15000:\n",
      "Training Loss: 0.4697 Validation Loss: 0.4960\n",
      "11124/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5151\n",
      "11125/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5090\n",
      "11126/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5243\n",
      "11127/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.4981\n",
      "11128/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.4999\n",
      "11129/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4987\n",
      "11130/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5089\n",
      "11131/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5057\n",
      "11132/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5309\n",
      "11133/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.5431\n",
      "11134/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5290\n",
      "11135/15000:\n",
      "Training Loss: 0.5317 Validation Loss: 0.5109\n",
      "11136/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5015\n",
      "11137/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5009\n",
      "11138/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5024\n",
      "11139/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5042\n",
      "11140/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5055\n",
      "11141/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5042\n",
      "11142/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5128\n",
      "11143/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5036\n",
      "11144/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5061\n",
      "11145/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5004\n",
      "11146/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.4998\n",
      "11147/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5061\n",
      "11148/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5128\n",
      "11149/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5070\n",
      "11150/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5285\n",
      "11151/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5034\n",
      "11152/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5098\n",
      "11153/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4963\n",
      "11154/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5086\n",
      "11155/15000:\n",
      "Training Loss: 0.5233 Validation Loss: 0.5053\n",
      "11156/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5045\n",
      "11157/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5055\n",
      "11158/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5073\n",
      "11159/15000:\n",
      "Training Loss: 0.4712 Validation Loss: 0.5093\n",
      "11160/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5301\n",
      "11161/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5249\n",
      "11162/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5395\n",
      "11163/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5237\n",
      "11164/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5014\n",
      "11165/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.4978\n",
      "11166/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5096\n",
      "11167/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5067\n",
      "11168/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5029\n",
      "11169/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5047\n",
      "11170/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5098\n",
      "11171/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5055\n",
      "11172/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5074\n",
      "11173/15000:\n",
      "Training Loss: 0.4684 Validation Loss: 0.5133\n",
      "11174/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5086\n",
      "11175/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5156\n",
      "11176/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5089\n",
      "11177/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5108\n",
      "11178/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.4978\n",
      "11179/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.4969\n",
      "11180/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5022\n",
      "11181/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5013\n",
      "11182/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4990\n",
      "11183/15000:\n",
      "Training Loss: 0.4720 Validation Loss: 0.5053\n",
      "11184/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5151\n",
      "11185/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5097\n",
      "11186/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5024\n",
      "11187/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5053\n",
      "11188/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5054\n",
      "11189/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5050\n",
      "11190/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.5202\n",
      "11191/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5113\n",
      "11192/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5109\n",
      "11193/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5052\n",
      "11194/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5113\n",
      "11195/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5101\n",
      "11196/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4994\n",
      "11197/15000:\n",
      "Training Loss: 0.4670 Validation Loss: 0.5007\n",
      "11198/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.5031\n",
      "11199/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.5075\n",
      "11200/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5116\n",
      "11201/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5025\n",
      "11202/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.5165\n",
      "11203/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5254\n",
      "11204/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5110\n",
      "11205/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5153\n",
      "11206/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5124\n",
      "11207/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5049\n",
      "11208/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5075\n",
      "11209/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5129\n",
      "11210/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5147\n",
      "11211/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5063\n",
      "11212/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.4969\n",
      "11213/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5072\n",
      "11214/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5222\n",
      "11215/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4995\n",
      "11216/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5031\n",
      "11217/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5013\n",
      "11218/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.4999\n",
      "11219/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5017\n",
      "11220/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5098\n",
      "11221/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.4996\n",
      "11222/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5035\n",
      "11223/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.4953\n",
      "11224/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5032\n",
      "11225/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5234\n",
      "11226/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5572\n",
      "11227/15000:\n",
      "Training Loss: 0.5290 Validation Loss: 0.5253\n",
      "11228/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.4995\n",
      "11229/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4927\n",
      "11230/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5017\n",
      "11231/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5054\n",
      "11232/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5099\n",
      "11233/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5097\n",
      "11234/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5027\n",
      "11235/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.4981\n",
      "11236/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.4992\n",
      "11237/15000:\n",
      "Training Loss: 0.4715 Validation Loss: 0.5047\n",
      "11238/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5119\n",
      "11239/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5139\n",
      "11240/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4982\n",
      "11241/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5085\n",
      "11242/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5060\n",
      "11243/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5043\n",
      "11244/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5006\n",
      "11245/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5150\n",
      "11246/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5162\n",
      "11247/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5472\n",
      "11248/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5229\n",
      "11249/15000:\n",
      "Training Loss: 0.5333 Validation Loss: 0.5147\n",
      "11250/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5105\n",
      "11251/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5004\n",
      "11252/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.4988\n",
      "11253/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.4984\n",
      "11254/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5145\n",
      "11255/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5394\n",
      "11256/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.5293\n",
      "11257/15000:\n",
      "Training Loss: 0.5259 Validation Loss: 0.5095\n",
      "11258/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5058\n",
      "11259/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5045\n",
      "11260/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5054\n",
      "11261/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5013\n",
      "11262/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5003\n",
      "11263/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5070\n",
      "11264/15000:\n",
      "Training Loss: 0.4688 Validation Loss: 0.5043\n",
      "11265/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5074\n",
      "11266/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5128\n",
      "11267/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5197\n",
      "11268/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5175\n",
      "11269/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5079\n",
      "11270/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5076\n",
      "11271/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5067\n",
      "11272/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5061\n",
      "11273/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5047\n",
      "11274/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5051\n",
      "11275/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5097\n",
      "11276/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5099\n",
      "11277/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5107\n",
      "11278/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5073\n",
      "11279/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5083\n",
      "11280/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5236\n",
      "11281/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5217\n",
      "11282/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5116\n",
      "11283/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5061\n",
      "11284/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5083\n",
      "11285/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5125\n",
      "11286/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5069\n",
      "11287/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5157\n",
      "11288/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5091\n",
      "11289/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5099\n",
      "11290/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5107\n",
      "11291/15000:\n",
      "Training Loss: 0.4708 Validation Loss: 0.5054\n",
      "11292/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5110\n",
      "11293/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5129\n",
      "11294/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5117\n",
      "11295/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5172\n",
      "11296/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5114\n",
      "11297/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.4990\n",
      "11298/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5010\n",
      "11299/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5090\n",
      "11300/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5054\n",
      "11301/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5061\n",
      "11302/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5065\n",
      "11303/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5178\n",
      "11304/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5091\n",
      "11305/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5102\n",
      "11306/15000:\n",
      "Training Loss: 0.4640 Validation Loss: 0.5086\n",
      "11307/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5191\n",
      "11308/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5040\n",
      "11309/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5091\n",
      "11310/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5149\n",
      "11311/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5195\n",
      "11312/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5133\n",
      "11313/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5188\n",
      "11314/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5095\n",
      "11315/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5006\n",
      "11316/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5092\n",
      "11317/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5156\n",
      "11318/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5197\n",
      "11319/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5175\n",
      "11320/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5250\n",
      "11321/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5143\n",
      "11322/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5073\n",
      "11323/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5211\n",
      "11324/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5048\n",
      "11325/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5103\n",
      "11326/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5024\n",
      "11327/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.4995\n",
      "11328/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5018\n",
      "11329/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.4991\n",
      "11330/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.4997\n",
      "11331/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5034\n",
      "11332/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.4989\n",
      "11333/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5085\n",
      "11334/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5043\n",
      "11335/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5103\n",
      "11336/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5142\n",
      "11337/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5088\n",
      "11338/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5043\n",
      "11339/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5078\n",
      "11340/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5103\n",
      "11341/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5070\n",
      "11342/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5179\n",
      "11343/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5198\n",
      "11344/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5382\n",
      "11345/15000:\n",
      "Training Loss: 0.5202 Validation Loss: 0.5138\n",
      "11346/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5105\n",
      "11347/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5040\n",
      "11348/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4995\n",
      "11349/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5062\n",
      "11350/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5039\n",
      "11351/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5024\n",
      "11352/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4971\n",
      "11353/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5060\n",
      "11354/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5057\n",
      "11355/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5245\n",
      "11356/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5143\n",
      "11357/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5093\n",
      "11358/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5034\n",
      "11359/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5045\n",
      "11360/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5014\n",
      "11361/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4996\n",
      "11362/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5082\n",
      "11363/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5066\n",
      "11364/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5221\n",
      "11365/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5218\n",
      "11366/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5059\n",
      "11367/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5029\n",
      "11368/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5021\n",
      "11369/15000:\n",
      "Training Loss: 0.4558 Validation Loss: 0.5076\n",
      "11370/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5258\n",
      "11371/15000:\n",
      "Training Loss: 0.5318 Validation Loss: 0.5032\n",
      "11372/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5028\n",
      "11373/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5129\n",
      "11374/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5414\n",
      "11375/15000:\n",
      "Training Loss: 0.5150 Validation Loss: 0.5256\n",
      "11376/15000:\n",
      "Training Loss: 0.5316 Validation Loss: 0.5126\n",
      "11377/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5072\n",
      "11378/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5013\n",
      "11379/15000:\n",
      "Training Loss: 0.4659 Validation Loss: 0.5106\n",
      "11380/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5112\n",
      "11381/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5053\n",
      "11382/15000:\n",
      "Training Loss: 0.4660 Validation Loss: 0.5156\n",
      "11383/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5092\n",
      "11384/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5164\n",
      "11385/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5088\n",
      "11386/15000:\n",
      "Training Loss: 0.4705 Validation Loss: 0.5074\n",
      "11387/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.4968\n",
      "11388/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5020\n",
      "11389/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5047\n",
      "11390/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5083\n",
      "11391/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5073\n",
      "11392/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.4997\n",
      "11393/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5014\n",
      "11394/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5076\n",
      "11395/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5222\n",
      "11396/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5133\n",
      "11397/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5088\n",
      "11398/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5096\n",
      "11399/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5080\n",
      "11400/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5053\n",
      "11401/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5019\n",
      "11402/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5061\n",
      "11403/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5032\n",
      "11404/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5048\n",
      "11405/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.4962\n",
      "11406/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5124\n",
      "11407/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5031\n",
      "11408/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.4983\n",
      "11409/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5038\n",
      "11410/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5220\n",
      "11411/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5088\n",
      "11412/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5037\n",
      "11413/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5067\n",
      "11414/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5037\n",
      "11415/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5041\n",
      "11416/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.4933\n",
      "11417/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.4980\n",
      "11418/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.4969\n",
      "11419/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.5145\n",
      "11420/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5208\n",
      "11421/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5404\n",
      "11422/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5118\n",
      "11423/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5143\n",
      "11424/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5128\n",
      "11425/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5045\n",
      "11426/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5047\n",
      "11427/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5040\n",
      "11428/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5048\n",
      "11429/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5058\n",
      "11430/15000:\n",
      "Training Loss: 0.4699 Validation Loss: 0.5058\n",
      "11431/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.4977\n",
      "11432/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5060\n",
      "11433/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5071\n",
      "11434/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5188\n",
      "11435/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5099\n",
      "11436/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5129\n",
      "11437/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5107\n",
      "11438/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5127\n",
      "11439/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5038\n",
      "11440/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5059\n",
      "11441/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5072\n",
      "11442/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5260\n",
      "11443/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5478\n",
      "11444/15000:\n",
      "Training Loss: 0.5152 Validation Loss: 0.5579\n",
      "11445/15000:\n",
      "Training Loss: 0.5279 Validation Loss: 0.5180\n",
      "11446/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5079\n",
      "11447/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5036\n",
      "11448/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5036\n",
      "11449/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.5082\n",
      "11450/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5019\n",
      "11451/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5132\n",
      "11452/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4966\n",
      "11453/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5057\n",
      "11454/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5061\n",
      "11455/15000:\n",
      "Training Loss: 0.4708 Validation Loss: 0.5016\n",
      "11456/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5021\n",
      "11457/15000:\n",
      "Training Loss: 0.4648 Validation Loss: 0.5154\n",
      "11458/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5025\n",
      "11459/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5023\n",
      "11460/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5035\n",
      "11461/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.4994\n",
      "11462/15000:\n",
      "Training Loss: 0.4669 Validation Loss: 0.4995\n",
      "11463/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.5097\n",
      "11464/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5101\n",
      "11465/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5086\n",
      "11466/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5075\n",
      "11467/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5045\n",
      "11468/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5062\n",
      "11469/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5066\n",
      "11470/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5039\n",
      "11471/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5040\n",
      "11472/15000:\n",
      "Training Loss: 0.4696 Validation Loss: 0.5081\n",
      "11473/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5121\n",
      "11474/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5030\n",
      "11475/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5079\n",
      "11476/15000:\n",
      "Training Loss: 0.4683 Validation Loss: 0.4992\n",
      "11477/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5038\n",
      "11478/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4981\n",
      "11479/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5099\n",
      "11480/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5062\n",
      "11481/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5116\n",
      "11482/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5198\n",
      "11483/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5466\n",
      "11484/15000:\n",
      "Training Loss: 0.5280 Validation Loss: 0.5304\n",
      "11485/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5109\n",
      "11486/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5044\n",
      "11487/15000:\n",
      "Training Loss: 0.4715 Validation Loss: 0.5127\n",
      "11488/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5145\n",
      "11489/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5057\n",
      "11490/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5001\n",
      "11491/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5032\n",
      "11492/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5034\n",
      "11493/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5063\n",
      "11494/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5134\n",
      "11495/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5105\n",
      "11496/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5081\n",
      "11497/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5287\n",
      "11498/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5138\n",
      "11499/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5129\n",
      "11500/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5032\n",
      "11501/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5134\n",
      "11502/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5116\n",
      "11503/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5177\n",
      "11504/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5166\n",
      "11505/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5223\n",
      "11506/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5075\n",
      "11507/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.4987\n",
      "11508/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5111\n",
      "11509/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5019\n",
      "11510/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4993\n",
      "11511/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.5001\n",
      "11512/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4967\n",
      "11513/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5042\n",
      "11514/15000:\n",
      "Training Loss: 0.4672 Validation Loss: 0.5069\n",
      "11515/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5169\n",
      "11516/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5031\n",
      "11517/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5092\n",
      "11518/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5172\n",
      "11519/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5038\n",
      "11520/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5092\n",
      "11521/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5009\n",
      "11522/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5033\n",
      "11523/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5076\n",
      "11524/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.4998\n",
      "11525/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4973\n",
      "11526/15000:\n",
      "Training Loss: 0.4646 Validation Loss: 0.5128\n",
      "11527/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5297\n",
      "11528/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.6274\n",
      "11529/15000:\n",
      "Training Loss: 0.5749 Validation Loss: 0.5169\n",
      "11530/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5064\n",
      "11531/15000:\n",
      "Training Loss: 0.4690 Validation Loss: 0.5013\n",
      "11532/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5089\n",
      "11533/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5073\n",
      "11534/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5154\n",
      "11535/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5124\n",
      "11536/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5220\n",
      "11537/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5108\n",
      "11538/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5048\n",
      "11539/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5051\n",
      "11540/15000:\n",
      "Training Loss: 0.4660 Validation Loss: 0.5111\n",
      "11541/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5159\n",
      "11542/15000:\n",
      "Training Loss: 0.5105 Validation Loss: 0.4955\n",
      "11543/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5003\n",
      "11544/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5024\n",
      "11545/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.4960\n",
      "11546/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5011\n",
      "11547/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5044\n",
      "11548/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5087\n",
      "11549/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5084\n",
      "11550/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5235\n",
      "11551/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5110\n",
      "11552/15000:\n",
      "Training Loss: 0.4696 Validation Loss: 0.5142\n",
      "11553/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5122\n",
      "11554/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5168\n",
      "11555/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5133\n",
      "11556/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5065\n",
      "11557/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5094\n",
      "11558/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5211\n",
      "11559/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5042\n",
      "11560/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.5004\n",
      "11561/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4944\n",
      "11562/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5013\n",
      "11563/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4996\n",
      "11564/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.4965\n",
      "11565/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5021\n",
      "11566/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4992\n",
      "11567/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5152\n",
      "11568/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5094\n",
      "11569/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5344\n",
      "11570/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4956\n",
      "11571/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4968\n",
      "11572/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5042\n",
      "11573/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5056\n",
      "11574/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5187\n",
      "11575/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5143\n",
      "11576/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5096\n",
      "11577/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.4985\n",
      "11578/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5047\n",
      "11579/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5010\n",
      "11580/15000:\n",
      "Training Loss: 0.4697 Validation Loss: 0.5046\n",
      "11581/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5038\n",
      "11582/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5066\n",
      "11583/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5087\n",
      "11584/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5256\n",
      "11585/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5372\n",
      "11586/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5537\n",
      "11587/15000:\n",
      "Training Loss: 0.5460 Validation Loss: 0.5060\n",
      "11588/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5225\n",
      "11589/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5076\n",
      "11590/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5105\n",
      "11591/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5079\n",
      "11592/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5068\n",
      "11593/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5007\n",
      "11594/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.5003\n",
      "11595/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5128\n",
      "11596/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5016\n",
      "11597/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.4986\n",
      "11598/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5042\n",
      "11599/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5029\n",
      "11600/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.4993\n",
      "11601/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5037\n",
      "11602/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5009\n",
      "11603/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.4965\n",
      "11604/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5019\n",
      "11605/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5029\n",
      "11606/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5079\n",
      "11607/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5108\n",
      "11608/15000:\n",
      "Training Loss: 0.4689 Validation Loss: 0.5109\n",
      "11609/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5154\n",
      "11610/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.5333\n",
      "11611/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5134\n",
      "11612/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5242\n",
      "11613/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5140\n",
      "11614/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5105\n",
      "11615/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5102\n",
      "11616/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5038\n",
      "11617/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5141\n",
      "11618/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5154\n",
      "11619/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5166\n",
      "11620/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5380\n",
      "11621/15000:\n",
      "Training Loss: 0.5357 Validation Loss: 0.5181\n",
      "11622/15000:\n",
      "Training Loss: 0.5294 Validation Loss: 0.5073\n",
      "11623/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5075\n",
      "11624/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5061\n",
      "11625/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5060\n",
      "11626/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4994\n",
      "11627/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5020\n",
      "11628/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5071\n",
      "11629/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.5106\n",
      "11630/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5075\n",
      "11631/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.4975\n",
      "11632/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5005\n",
      "11633/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4980\n",
      "11634/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5055\n",
      "11635/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5034\n",
      "11636/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5096\n",
      "11637/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.4982\n",
      "11638/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5139\n",
      "11639/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5113\n",
      "11640/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5094\n",
      "11641/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5119\n",
      "11642/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5152\n",
      "11643/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5060\n",
      "11644/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5158\n",
      "11645/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5123\n",
      "11646/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5140\n",
      "11647/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5086\n",
      "11648/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.5093\n",
      "11649/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5306\n",
      "11650/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5302\n",
      "11651/15000:\n",
      "Training Loss: 0.5164 Validation Loss: 0.5275\n",
      "11652/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5210\n",
      "11653/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5040\n",
      "11654/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5081\n",
      "11655/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5081\n",
      "11656/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5172\n",
      "11657/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5728\n",
      "11658/15000:\n",
      "Training Loss: 0.5415 Validation Loss: 0.5169\n",
      "11659/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5195\n",
      "11660/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5028\n",
      "11661/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.4974\n",
      "11662/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5180\n",
      "11663/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5114\n",
      "11664/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5205\n",
      "11665/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5073\n",
      "11666/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5159\n",
      "11667/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5087\n",
      "11668/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5122\n",
      "11669/15000:\n",
      "Training Loss: 0.4705 Validation Loss: 0.5152\n",
      "11670/15000:\n",
      "Training Loss: 0.4673 Validation Loss: 0.5192\n",
      "11671/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5264\n",
      "11672/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5014\n",
      "11673/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5072\n",
      "11674/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5093\n",
      "11675/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5228\n",
      "11676/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5088\n",
      "11677/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.5064\n",
      "11678/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5059\n",
      "11679/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.5054\n",
      "11680/15000:\n",
      "Training Loss: 0.4712 Validation Loss: 0.5171\n",
      "11681/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4998\n",
      "11682/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5067\n",
      "11683/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5117\n",
      "11684/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5121\n",
      "11685/15000:\n",
      "Training Loss: 0.5192 Validation Loss: 0.5024\n",
      "11686/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5092\n",
      "11687/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5027\n",
      "11688/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5140\n",
      "11689/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5191\n",
      "11690/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.4995\n",
      "11691/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5071\n",
      "11692/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5053\n",
      "11693/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5205\n",
      "11694/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5276\n",
      "11695/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5753\n",
      "11696/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5069\n",
      "11697/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5268\n",
      "11698/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5081\n",
      "11699/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5015\n",
      "11700/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5023\n",
      "11701/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5075\n",
      "11702/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5052\n",
      "11703/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.5061\n",
      "11704/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5019\n",
      "11705/15000:\n",
      "Training Loss: 0.4645 Validation Loss: 0.5091\n",
      "11706/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5055\n",
      "11707/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5016\n",
      "11708/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5029\n",
      "11709/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5110\n",
      "11710/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5044\n",
      "11711/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5215\n",
      "11712/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5153\n",
      "11713/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5296\n",
      "11714/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5121\n",
      "11715/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5170\n",
      "11716/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.5046\n",
      "11717/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5046\n",
      "11718/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5032\n",
      "11719/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5114\n",
      "11720/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5126\n",
      "11721/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5327\n",
      "11722/15000:\n",
      "Training Loss: 0.5209 Validation Loss: 0.5330\n",
      "11723/15000:\n",
      "Training Loss: 0.5295 Validation Loss: 0.5809\n",
      "11724/15000:\n",
      "Training Loss: 0.5542 Validation Loss: 0.5150\n",
      "11725/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5148\n",
      "11726/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5057\n",
      "11727/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5173\n",
      "11728/15000:\n",
      "Training Loss: 0.5219 Validation Loss: 0.5130\n",
      "11729/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5126\n",
      "11730/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5251\n",
      "11731/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5021\n",
      "11732/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5041\n",
      "11733/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5045\n",
      "11734/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5103\n",
      "11735/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5067\n",
      "11736/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5040\n",
      "11737/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5127\n",
      "11738/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5041\n",
      "11739/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5009\n",
      "11740/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5068\n",
      "11741/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4958\n",
      "11742/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.4980\n",
      "11743/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5033\n",
      "11744/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5054\n",
      "11745/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5072\n",
      "11746/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5003\n",
      "11747/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5140\n",
      "11748/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5107\n",
      "11749/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5087\n",
      "11750/15000:\n",
      "Training Loss: 0.4681 Validation Loss: 0.5075\n",
      "11751/15000:\n",
      "Training Loss: 0.4682 Validation Loss: 0.5122\n",
      "11752/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5086\n",
      "11753/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5316\n",
      "11754/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5080\n",
      "11755/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5021\n",
      "11756/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5121\n",
      "11757/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5198\n",
      "11758/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5342\n",
      "11759/15000:\n",
      "Training Loss: 0.5213 Validation Loss: 0.5211\n",
      "11760/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5082\n",
      "11761/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5064\n",
      "11762/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5159\n",
      "11763/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5086\n",
      "11764/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5015\n",
      "11765/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5043\n",
      "11766/15000:\n",
      "Training Loss: 0.4680 Validation Loss: 0.5006\n",
      "11767/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5092\n",
      "11768/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5071\n",
      "11769/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5074\n",
      "11770/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5044\n",
      "11771/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5022\n",
      "11772/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5084\n",
      "11773/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5064\n",
      "11774/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4995\n",
      "11775/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5038\n",
      "11776/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5133\n",
      "11777/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5117\n",
      "11778/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5135\n",
      "11779/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5070\n",
      "11780/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5064\n",
      "11781/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5340\n",
      "11782/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5140\n",
      "11783/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5159\n",
      "11784/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5203\n",
      "11785/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5122\n",
      "11786/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5200\n",
      "11787/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5149\n",
      "11788/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5121\n",
      "11789/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5008\n",
      "11790/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5142\n",
      "11791/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.4966\n",
      "11792/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.4959\n",
      "11793/15000:\n",
      "Training Loss: 0.4691 Validation Loss: 0.5021\n",
      "11794/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.4970\n",
      "11795/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5007\n",
      "11796/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5010\n",
      "11797/15000:\n",
      "Training Loss: 0.4713 Validation Loss: 0.5052\n",
      "11798/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5031\n",
      "11799/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4985\n",
      "11800/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5062\n",
      "11801/15000:\n",
      "Training Loss: 0.4702 Validation Loss: 0.5214\n",
      "11802/15000:\n",
      "Training Loss: 0.5028 Validation Loss: 0.5063\n",
      "11803/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5203\n",
      "11804/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5240\n",
      "11805/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5024\n",
      "11806/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5034\n",
      "11807/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5054\n",
      "11808/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5016\n",
      "11809/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5076\n",
      "11810/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5063\n",
      "11811/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5067\n",
      "11812/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5082\n",
      "11813/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5118\n",
      "11814/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5011\n",
      "11815/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5007\n",
      "11816/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4960\n",
      "11817/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5032\n",
      "11818/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.4990\n",
      "11819/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5046\n",
      "11820/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5302\n",
      "11821/15000:\n",
      "Training Loss: 0.5325 Validation Loss: 0.5127\n",
      "11822/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5524\n",
      "11823/15000:\n",
      "Training Loss: 0.5235 Validation Loss: 0.5058\n",
      "11824/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5033\n",
      "11825/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5024\n",
      "11826/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5029\n",
      "11827/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4976\n",
      "11828/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.4999\n",
      "11829/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.4983\n",
      "11830/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.4994\n",
      "11831/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5311\n",
      "11832/15000:\n",
      "Training Loss: 0.5048 Validation Loss: 0.5041\n",
      "11833/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5178\n",
      "11834/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5005\n",
      "11835/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5177\n",
      "11836/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5001\n",
      "11837/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5040\n",
      "11838/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5015\n",
      "11839/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5159\n",
      "11840/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5082\n",
      "11841/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5083\n",
      "11842/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5089\n",
      "11843/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5289\n",
      "11844/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.4952\n",
      "11845/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5045\n",
      "11846/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.4993\n",
      "11847/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5048\n",
      "11848/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4969\n",
      "11849/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.4969\n",
      "11850/15000:\n",
      "Training Loss: 0.4699 Validation Loss: 0.5038\n",
      "11851/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5066\n",
      "11852/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5224\n",
      "11853/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5106\n",
      "11854/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5071\n",
      "11855/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5053\n",
      "11856/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5012\n",
      "11857/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5043\n",
      "11858/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5132\n",
      "11859/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5164\n",
      "11860/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5033\n",
      "11861/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5053\n",
      "11862/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5070\n",
      "11863/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5034\n",
      "11864/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5059\n",
      "11865/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5051\n",
      "11866/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5202\n",
      "11867/15000:\n",
      "Training Loss: 0.5251 Validation Loss: 0.5287\n",
      "11868/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5058\n",
      "11869/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5095\n",
      "11870/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5076\n",
      "11871/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5126\n",
      "11872/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5158\n",
      "11873/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5166\n",
      "11874/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5156\n",
      "11875/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5117\n",
      "11876/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5242\n",
      "11877/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5214\n",
      "11878/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5128\n",
      "11879/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5195\n",
      "11880/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5115\n",
      "11881/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5170\n",
      "11882/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5209\n",
      "11883/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5180\n",
      "11884/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5223\n",
      "11885/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5167\n",
      "11886/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5297\n",
      "11887/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5226\n",
      "11888/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5152\n",
      "11889/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5246\n",
      "11890/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5095\n",
      "11891/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5153\n",
      "11892/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5087\n",
      "11893/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5145\n",
      "11894/15000:\n",
      "Training Loss: 0.5194 Validation Loss: 0.5031\n",
      "11895/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5117\n",
      "11896/15000:\n",
      "Training Loss: 0.5155 Validation Loss: 0.5043\n",
      "11897/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5118\n",
      "11898/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5076\n",
      "11899/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5083\n",
      "11900/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5113\n",
      "11901/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5086\n",
      "11902/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5154\n",
      "11903/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5173\n",
      "11904/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5170\n",
      "11905/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5094\n",
      "11906/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.5171\n",
      "11907/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5238\n",
      "11908/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5180\n",
      "11909/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5144\n",
      "11910/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5123\n",
      "11911/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5186\n",
      "11912/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5003\n",
      "11913/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5263\n",
      "11914/15000:\n",
      "Training Loss: 0.5244 Validation Loss: 0.5896\n",
      "11915/15000:\n",
      "Training Loss: 0.5768 Validation Loss: 0.7011\n",
      "11916/15000:\n",
      "Training Loss: 0.7860 Validation Loss: 0.5438\n",
      "11917/15000:\n",
      "Training Loss: 0.5733 Validation Loss: 0.5350\n",
      "11918/15000:\n",
      "Training Loss: 0.5339 Validation Loss: 0.5272\n",
      "11919/15000:\n",
      "Training Loss: 0.5128 Validation Loss: 0.5209\n",
      "11920/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5149\n",
      "11921/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5041\n",
      "11922/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5035\n",
      "11923/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5063\n",
      "11924/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.5200\n",
      "11925/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5092\n",
      "11926/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5168\n",
      "11927/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5123\n",
      "11928/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5185\n",
      "11929/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.5115\n",
      "11930/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5181\n",
      "11931/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5092\n",
      "11932/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5045\n",
      "11933/15000:\n",
      "Training Loss: 0.4673 Validation Loss: 0.5297\n",
      "11934/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5092\n",
      "11935/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5159\n",
      "11936/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5101\n",
      "11937/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5114\n",
      "11938/15000:\n",
      "Training Loss: 0.4722 Validation Loss: 0.5138\n",
      "11939/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5174\n",
      "11940/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5121\n",
      "11941/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5119\n",
      "11942/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5163\n",
      "11943/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5100\n",
      "11944/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5078\n",
      "11945/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5032\n",
      "11946/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5228\n",
      "11947/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5295\n",
      "11948/15000:\n",
      "Training Loss: 0.5252 Validation Loss: 0.5439\n",
      "11949/15000:\n",
      "Training Loss: 0.5667 Validation Loss: 0.5251\n",
      "11950/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.5195\n",
      "11951/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5056\n",
      "11952/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5172\n",
      "11953/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5190\n",
      "11954/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5142\n",
      "11955/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5085\n",
      "11956/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5079\n",
      "11957/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5119\n",
      "11958/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5040\n",
      "11959/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5020\n",
      "11960/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5157\n",
      "11961/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5090\n",
      "11962/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5165\n",
      "11963/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5097\n",
      "11964/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5181\n",
      "11965/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5084\n",
      "11966/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5057\n",
      "11967/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5079\n",
      "11968/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5057\n",
      "11969/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5073\n",
      "11970/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5142\n",
      "11971/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5075\n",
      "11972/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5160\n",
      "11973/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5097\n",
      "11974/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5309\n",
      "11975/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5419\n",
      "11976/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5229\n",
      "11977/15000:\n",
      "Training Loss: 0.5177 Validation Loss: 0.5160\n",
      "11978/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5071\n",
      "11979/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5053\n",
      "11980/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5043\n",
      "11981/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5200\n",
      "11982/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5252\n",
      "11983/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5120\n",
      "11984/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5151\n",
      "11985/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5097\n",
      "11986/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5093\n",
      "11987/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5160\n",
      "11988/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5152\n",
      "11989/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5138\n",
      "11990/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5055\n",
      "11991/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5154\n",
      "11992/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5105\n",
      "11993/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5084\n",
      "11994/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5069\n",
      "11995/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5105\n",
      "11996/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5066\n",
      "11997/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5135\n",
      "11998/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5119\n",
      "11999/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5126\n",
      "12000/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5092\n",
      "12001/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5118\n",
      "12002/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5174\n",
      "12003/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5122\n",
      "12004/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5099\n",
      "12005/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5046\n",
      "12006/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5030\n",
      "12007/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5059\n",
      "12008/15000:\n",
      "Training Loss: 0.4678 Validation Loss: 0.5110\n",
      "12009/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5095\n",
      "12010/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5027\n",
      "12011/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5104\n",
      "12012/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5024\n",
      "12013/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5076\n",
      "12014/15000:\n",
      "Training Loss: 0.4664 Validation Loss: 0.5088\n",
      "12015/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5177\n",
      "12016/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5146\n",
      "12017/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4936\n",
      "12018/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5007\n",
      "12019/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5097\n",
      "12020/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5049\n",
      "12021/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5001\n",
      "12022/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.4998\n",
      "12023/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5003\n",
      "12024/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.4957\n",
      "12025/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5082\n",
      "12026/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5108\n",
      "12027/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5066\n",
      "12028/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.4969\n",
      "12029/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5038\n",
      "12030/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5096\n",
      "12031/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.4984\n",
      "12032/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5028\n",
      "12033/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5081\n",
      "12034/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5233\n",
      "12035/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5010\n",
      "12036/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5068\n",
      "12037/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5055\n",
      "12038/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5272\n",
      "12039/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5215\n",
      "12040/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5571\n",
      "12041/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5153\n",
      "12042/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5340\n",
      "12043/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5046\n",
      "12044/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5037\n",
      "12045/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5047\n",
      "12046/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5079\n",
      "12047/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5045\n",
      "12048/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5149\n",
      "12049/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5141\n",
      "12050/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5104\n",
      "12051/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5060\n",
      "12052/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5029\n",
      "12053/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.4961\n",
      "12054/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.4938\n",
      "12055/15000:\n",
      "Training Loss: 0.4684 Validation Loss: 0.4969\n",
      "12056/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.4973\n",
      "12057/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.4932\n",
      "12058/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5127\n",
      "12059/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5026\n",
      "12060/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5014\n",
      "12061/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4968\n",
      "12062/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5028\n",
      "12063/15000:\n",
      "Training Loss: 0.4708 Validation Loss: 0.4998\n",
      "12064/15000:\n",
      "Training Loss: 0.4623 Validation Loss: 0.5097\n",
      "12065/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5101\n",
      "12066/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5122\n",
      "12067/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.4979\n",
      "12068/15000:\n",
      "Training Loss: 0.4686 Validation Loss: 0.5143\n",
      "12069/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5001\n",
      "12070/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5189\n",
      "12071/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5038\n",
      "12072/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5069\n",
      "12073/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.4995\n",
      "12074/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5059\n",
      "12075/15000:\n",
      "Training Loss: 0.4650 Validation Loss: 0.5013\n",
      "12076/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5232\n",
      "12077/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5453\n",
      "12078/15000:\n",
      "Training Loss: 0.5264 Validation Loss: 0.5642\n",
      "12079/15000:\n",
      "Training Loss: 0.5644 Validation Loss: 0.5205\n",
      "12080/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5229\n",
      "12081/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5018\n",
      "12082/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5076\n",
      "12083/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5092\n",
      "12084/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5097\n",
      "12085/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5064\n",
      "12086/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5167\n",
      "12087/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5051\n",
      "12088/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5097\n",
      "12089/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5028\n",
      "12090/15000:\n",
      "Training Loss: 0.4720 Validation Loss: 0.5105\n",
      "12091/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5195\n",
      "12092/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5109\n",
      "12093/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5163\n",
      "12094/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5110\n",
      "12095/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5113\n",
      "12096/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5075\n",
      "12097/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5084\n",
      "12098/15000:\n",
      "Training Loss: 0.4748 Validation Loss: 0.5050\n",
      "12099/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.5109\n",
      "12100/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5157\n",
      "12101/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5057\n",
      "12102/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5082\n",
      "12103/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5136\n",
      "12104/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5138\n",
      "12105/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5157\n",
      "12106/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.4959\n",
      "12107/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5136\n",
      "12108/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5103\n",
      "12109/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5338\n",
      "12110/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5014\n",
      "12111/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5180\n",
      "12112/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5008\n",
      "12113/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5032\n",
      "12114/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5102\n",
      "12115/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5123\n",
      "12116/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5028\n",
      "12117/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5080\n",
      "12118/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5106\n",
      "12119/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5201\n",
      "12120/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5149\n",
      "12121/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5120\n",
      "12122/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5186\n",
      "12123/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5131\n",
      "12124/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5081\n",
      "12125/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5101\n",
      "12126/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5127\n",
      "12127/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5090\n",
      "12128/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5043\n",
      "12129/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5174\n",
      "12130/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5076\n",
      "12131/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5059\n",
      "12132/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5044\n",
      "12133/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5046\n",
      "12134/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.5036\n",
      "12135/15000:\n",
      "Training Loss: 0.4691 Validation Loss: 0.4933\n",
      "12136/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5016\n",
      "12137/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5018\n",
      "12138/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4967\n",
      "12139/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5059\n",
      "12140/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5026\n",
      "12141/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.4993\n",
      "12142/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5068\n",
      "12143/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.4997\n",
      "12144/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.4975\n",
      "12145/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5086\n",
      "12146/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5137\n",
      "12147/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5200\n",
      "12148/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5183\n",
      "12149/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5259\n",
      "12150/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5140\n",
      "12151/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5285\n",
      "12152/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5029\n",
      "12153/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5086\n",
      "12154/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5159\n",
      "12155/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.4920\n",
      "12156/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5083\n",
      "12157/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5004\n",
      "12158/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5037\n",
      "12159/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5228\n",
      "12160/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.5549\n",
      "12161/15000:\n",
      "Training Loss: 0.5215 Validation Loss: 0.5470\n",
      "12162/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5025\n",
      "12163/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5065\n",
      "12164/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5066\n",
      "12165/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5079\n",
      "12166/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5105\n",
      "12167/15000:\n",
      "Training Loss: 0.5145 Validation Loss: 0.4989\n",
      "12168/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5016\n",
      "12169/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5040\n",
      "12170/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5000\n",
      "12171/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5044\n",
      "12172/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5061\n",
      "12173/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5063\n",
      "12174/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5151\n",
      "12175/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5048\n",
      "12176/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5035\n",
      "12177/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5003\n",
      "12178/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5092\n",
      "12179/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5051\n",
      "12180/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5012\n",
      "12181/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5010\n",
      "12182/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.4951\n",
      "12183/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.4974\n",
      "12184/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.4935\n",
      "12185/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.4964\n",
      "12186/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5140\n",
      "12187/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5341\n",
      "12188/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5506\n",
      "12189/15000:\n",
      "Training Loss: 0.5956 Validation Loss: 0.5200\n",
      "12190/15000:\n",
      "Training Loss: 0.5327 Validation Loss: 0.5723\n",
      "12191/15000:\n",
      "Training Loss: 0.5738 Validation Loss: 0.5267\n",
      "12192/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5337\n",
      "12193/15000:\n",
      "Training Loss: 0.5154 Validation Loss: 0.5100\n",
      "12194/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5125\n",
      "12195/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5197\n",
      "12196/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5126\n",
      "12197/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5167\n",
      "12198/15000:\n",
      "Training Loss: 0.5086 Validation Loss: 0.5154\n",
      "12199/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5191\n",
      "12200/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5177\n",
      "12201/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5255\n",
      "12202/15000:\n",
      "Training Loss: 0.5236 Validation Loss: 0.5728\n",
      "12203/15000:\n",
      "Training Loss: 0.5433 Validation Loss: 0.5104\n",
      "12204/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.4943\n",
      "12205/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4974\n",
      "12206/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5013\n",
      "12207/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5000\n",
      "12208/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.5010\n",
      "12209/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4985\n",
      "12210/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5399\n",
      "12211/15000:\n",
      "Training Loss: 0.5390 Validation Loss: 0.5139\n",
      "12212/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5016\n",
      "12213/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5007\n",
      "12214/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5071\n",
      "12215/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.5074\n",
      "12216/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5002\n",
      "12217/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4963\n",
      "12218/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.4988\n",
      "12219/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4998\n",
      "12220/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.4956\n",
      "12221/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.4986\n",
      "12222/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.4983\n",
      "12223/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4994\n",
      "12224/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5090\n",
      "12225/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.4999\n",
      "12226/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5057\n",
      "12227/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5039\n",
      "12228/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5130\n",
      "12229/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5087\n",
      "12230/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5135\n",
      "12231/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5020\n",
      "12232/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5078\n",
      "12233/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5005\n",
      "12234/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.4988\n",
      "12235/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4963\n",
      "12236/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5068\n",
      "12237/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.4946\n",
      "12238/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.4964\n",
      "12239/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.4965\n",
      "12240/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5023\n",
      "12241/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5167\n",
      "12242/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5077\n",
      "12243/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5127\n",
      "12244/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5575\n",
      "12245/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5165\n",
      "12246/15000:\n",
      "Training Loss: 0.5207 Validation Loss: 0.5181\n",
      "12247/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5384\n",
      "12248/15000:\n",
      "Training Loss: 0.5242 Validation Loss: 0.5231\n",
      "12249/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5160\n",
      "12250/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5081\n",
      "12251/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5064\n",
      "12252/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5082\n",
      "12253/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4998\n",
      "12254/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5049\n",
      "12255/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5104\n",
      "12256/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5023\n",
      "12257/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4962\n",
      "12258/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4994\n",
      "12259/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.4977\n",
      "12260/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.4994\n",
      "12261/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5031\n",
      "12262/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5118\n",
      "12263/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5116\n",
      "12264/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5239\n",
      "12265/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5152\n",
      "12266/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5261\n",
      "12267/15000:\n",
      "Training Loss: 0.5261 Validation Loss: 0.5041\n",
      "12268/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5201\n",
      "12269/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5214\n",
      "12270/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5054\n",
      "12271/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5136\n",
      "12272/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5106\n",
      "12273/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5004\n",
      "12274/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5026\n",
      "12275/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.4994\n",
      "12276/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4953\n",
      "12277/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5130\n",
      "12278/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5010\n",
      "12279/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5072\n",
      "12280/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5020\n",
      "12281/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5106\n",
      "12282/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5374\n",
      "12283/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.5228\n",
      "12284/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5117\n",
      "12285/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5045\n",
      "12286/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5042\n",
      "12287/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5047\n",
      "12288/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5205\n",
      "12289/15000:\n",
      "Training Loss: 0.5299 Validation Loss: 0.5077\n",
      "12290/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5065\n",
      "12291/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5040\n",
      "12292/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5087\n",
      "12293/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5007\n",
      "12294/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.5112\n",
      "12295/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4971\n",
      "12296/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5062\n",
      "12297/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4938\n",
      "12298/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5015\n",
      "12299/15000:\n",
      "Training Loss: 0.4712 Validation Loss: 0.5003\n",
      "12300/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5121\n",
      "12301/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5096\n",
      "12302/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5102\n",
      "12303/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5044\n",
      "12304/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5127\n",
      "12305/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.4893\n",
      "12306/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.4900\n",
      "12307/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.4916\n",
      "12308/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.4976\n",
      "12309/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4950\n",
      "12310/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.4984\n",
      "12311/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5098\n",
      "12312/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5059\n",
      "12313/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5126\n",
      "12314/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5451\n",
      "12315/15000:\n",
      "Training Loss: 0.5335 Validation Loss: 0.5117\n",
      "12316/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5095\n",
      "12317/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4997\n",
      "12318/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5018\n",
      "12319/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.4971\n",
      "12320/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5056\n",
      "12321/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4965\n",
      "12322/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.4978\n",
      "12323/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5011\n",
      "12324/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5154\n",
      "12325/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5199\n",
      "12326/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5369\n",
      "12327/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5050\n",
      "12328/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5089\n",
      "12329/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.5087\n",
      "12330/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5103\n",
      "12331/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5093\n",
      "12332/15000:\n",
      "Training Loss: 0.5111 Validation Loss: 0.5060\n",
      "12333/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.4998\n",
      "12334/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5035\n",
      "12335/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5009\n",
      "12336/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.4983\n",
      "12337/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.4980\n",
      "12338/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.5045\n",
      "12339/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.4999\n",
      "12340/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4941\n",
      "12341/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5093\n",
      "12342/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5034\n",
      "12343/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5161\n",
      "12344/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5046\n",
      "12345/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5065\n",
      "12346/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4967\n",
      "12347/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5040\n",
      "12348/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.4987\n",
      "12349/15000:\n",
      "Training Loss: 0.4718 Validation Loss: 0.5422\n",
      "12350/15000:\n",
      "Training Loss: 0.5482 Validation Loss: 0.5547\n",
      "12351/15000:\n",
      "Training Loss: 0.5313 Validation Loss: 0.5195\n",
      "12352/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4958\n",
      "12353/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5127\n",
      "12354/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5238\n",
      "12355/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5099\n",
      "12356/15000:\n",
      "Training Loss: 0.5030 Validation Loss: 0.5285\n",
      "12357/15000:\n",
      "Training Loss: 0.5170 Validation Loss: 0.5259\n",
      "12358/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5057\n",
      "12359/15000:\n",
      "Training Loss: 0.4679 Validation Loss: 0.5040\n",
      "12360/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4977\n",
      "12361/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.4998\n",
      "12362/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.4956\n",
      "12363/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5012\n",
      "12364/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5119\n",
      "12365/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5018\n",
      "12366/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5062\n",
      "12367/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5027\n",
      "12368/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5015\n",
      "12369/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5120\n",
      "12370/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.4988\n",
      "12371/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5024\n",
      "12372/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5029\n",
      "12373/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.4984\n",
      "12374/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5049\n",
      "12375/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5041\n",
      "12376/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5011\n",
      "12377/15000:\n",
      "Training Loss: 0.4677 Validation Loss: 0.5194\n",
      "12378/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5139\n",
      "12379/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5205\n",
      "12380/15000:\n",
      "Training Loss: 0.5335 Validation Loss: 0.5073\n",
      "12381/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5284\n",
      "12382/15000:\n",
      "Training Loss: 0.5151 Validation Loss: 0.5178\n",
      "12383/15000:\n",
      "Training Loss: 0.5160 Validation Loss: 0.5141\n",
      "12384/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.4984\n",
      "12385/15000:\n",
      "Training Loss: 0.4650 Validation Loss: 0.4907\n",
      "12386/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.4974\n",
      "12387/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.4978\n",
      "12388/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5010\n",
      "12389/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.4959\n",
      "12390/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.4966\n",
      "12391/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.5011\n",
      "12392/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5019\n",
      "12393/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5280\n",
      "12394/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5008\n",
      "12395/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5194\n",
      "12396/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5019\n",
      "12397/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.4987\n",
      "12398/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5049\n",
      "12399/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.4979\n",
      "12400/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5005\n",
      "12401/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5052\n",
      "12402/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5299\n",
      "12403/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5223\n",
      "12404/15000:\n",
      "Training Loss: 0.5184 Validation Loss: 0.5301\n",
      "12405/15000:\n",
      "Training Loss: 0.5327 Validation Loss: 0.5014\n",
      "12406/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5011\n",
      "12407/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.4951\n",
      "12408/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5032\n",
      "12409/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.4990\n",
      "12410/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5025\n",
      "12411/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5146\n",
      "12412/15000:\n",
      "Training Loss: 0.5172 Validation Loss: 0.5016\n",
      "12413/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.4976\n",
      "12414/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.4962\n",
      "12415/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.4916\n",
      "12416/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.4993\n",
      "12417/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.4911\n",
      "12418/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.4946\n",
      "12419/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5132\n",
      "12420/15000:\n",
      "Training Loss: 0.5117 Validation Loss: 0.5064\n",
      "12421/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.4989\n",
      "12422/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.4914\n",
      "12423/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4941\n",
      "12424/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4975\n",
      "12425/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4984\n",
      "12426/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5013\n",
      "12427/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.4984\n",
      "12428/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5030\n",
      "12429/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5116\n",
      "12430/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5153\n",
      "12431/15000:\n",
      "Training Loss: 0.4696 Validation Loss: 0.4997\n",
      "12432/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5044\n",
      "12433/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.4966\n",
      "12434/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.4973\n",
      "12435/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5103\n",
      "12436/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5178\n",
      "12437/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5160\n",
      "12438/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5473\n",
      "12439/15000:\n",
      "Training Loss: 0.5204 Validation Loss: 0.5749\n",
      "12440/15000:\n",
      "Training Loss: 0.5458 Validation Loss: 0.5352\n",
      "12441/15000:\n",
      "Training Loss: 0.5069 Validation Loss: 0.5092\n",
      "12442/15000:\n",
      "Training Loss: 0.5157 Validation Loss: 0.5108\n",
      "12443/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5115\n",
      "12444/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5020\n",
      "12445/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4985\n",
      "12446/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.4995\n",
      "12447/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5016\n",
      "12448/15000:\n",
      "Training Loss: 0.4671 Validation Loss: 0.5040\n",
      "12449/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.4995\n",
      "12450/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.4976\n",
      "12451/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5065\n",
      "12452/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5002\n",
      "12453/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5061\n",
      "12454/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5050\n",
      "12455/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5043\n",
      "12456/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5046\n",
      "12457/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5072\n",
      "12458/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5021\n",
      "12459/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5335\n",
      "12460/15000:\n",
      "Training Loss: 0.5384 Validation Loss: 0.5295\n",
      "12461/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5291\n",
      "12462/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5137\n",
      "12463/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5061\n",
      "12464/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5054\n",
      "12465/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5050\n",
      "12466/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5083\n",
      "12467/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5136\n",
      "12468/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5355\n",
      "12469/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5068\n",
      "12470/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5125\n",
      "12471/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5106\n",
      "12472/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5043\n",
      "12473/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5047\n",
      "12474/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5181\n",
      "12475/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5126\n",
      "12476/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5089\n",
      "12477/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5024\n",
      "12478/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5225\n",
      "12479/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5232\n",
      "12480/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5009\n",
      "12481/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.4984\n",
      "12482/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5017\n",
      "12483/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5009\n",
      "12484/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5037\n",
      "12485/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5062\n",
      "12486/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5083\n",
      "12487/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5141\n",
      "12488/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5073\n",
      "12489/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5106\n",
      "12490/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5095\n",
      "12491/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5136\n",
      "12492/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5109\n",
      "12493/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5033\n",
      "12494/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5057\n",
      "12495/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5125\n",
      "12496/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5067\n",
      "12497/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4965\n",
      "12498/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5083\n",
      "12499/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.4946\n",
      "12500/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4982\n",
      "12501/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4951\n",
      "12502/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5057\n",
      "12503/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5115\n",
      "12504/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5200\n",
      "12505/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5141\n",
      "12506/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5119\n",
      "12507/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5204\n",
      "12508/15000:\n",
      "Training Loss: 0.5210 Validation Loss: 0.5039\n",
      "12509/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.5109\n",
      "12510/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5038\n",
      "12511/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.4985\n",
      "12512/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5072\n",
      "12513/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5107\n",
      "12514/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5108\n",
      "12515/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.5160\n",
      "12516/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5134\n",
      "12517/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5113\n",
      "12518/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5108\n",
      "12519/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.4991\n",
      "12520/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5102\n",
      "12521/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5160\n",
      "12522/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5056\n",
      "12523/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5162\n",
      "12524/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.4995\n",
      "12525/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5022\n",
      "12526/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5028\n",
      "12527/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5246\n",
      "12528/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5004\n",
      "12529/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5053\n",
      "12530/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.4967\n",
      "12531/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4976\n",
      "12532/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5077\n",
      "12533/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5030\n",
      "12534/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.4967\n",
      "12535/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.4968\n",
      "12536/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.4949\n",
      "12537/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5089\n",
      "12538/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5039\n",
      "12539/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5108\n",
      "12540/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5015\n",
      "12541/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5061\n",
      "12542/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5049\n",
      "12543/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5105\n",
      "12544/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5188\n",
      "12545/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5169\n",
      "12546/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.4955\n",
      "12547/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.4982\n",
      "12548/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5103\n",
      "12549/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5039\n",
      "12550/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5052\n",
      "12551/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5053\n",
      "12552/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5058\n",
      "12553/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5056\n",
      "12554/15000:\n",
      "Training Loss: 0.4714 Validation Loss: 0.5013\n",
      "12555/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5011\n",
      "12556/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5072\n",
      "12557/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5058\n",
      "12558/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5092\n",
      "12559/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5081\n",
      "12560/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5141\n",
      "12561/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5351\n",
      "12562/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5325\n",
      "12563/15000:\n",
      "Training Loss: 0.5158 Validation Loss: 0.5117\n",
      "12564/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5081\n",
      "12565/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5073\n",
      "12566/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5055\n",
      "12567/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5047\n",
      "12568/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.5177\n",
      "12569/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5169\n",
      "12570/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5419\n",
      "12571/15000:\n",
      "Training Loss: 0.5099 Validation Loss: 0.5049\n",
      "12572/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5171\n",
      "12573/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.5046\n",
      "12574/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5048\n",
      "12575/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5046\n",
      "12576/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.4950\n",
      "12577/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5055\n",
      "12578/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5009\n",
      "12579/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.4939\n",
      "12580/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4929\n",
      "12581/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4948\n",
      "12582/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5114\n",
      "12583/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5039\n",
      "12584/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5241\n",
      "12585/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5028\n",
      "12586/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5012\n",
      "12587/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5275\n",
      "12588/15000:\n",
      "Training Loss: 0.5148 Validation Loss: 0.5026\n",
      "12589/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.4967\n",
      "12590/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.4968\n",
      "12591/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5057\n",
      "12592/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4983\n",
      "12593/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5067\n",
      "12594/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.4997\n",
      "12595/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5029\n",
      "12596/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5014\n",
      "12597/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5078\n",
      "12598/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.5012\n",
      "12599/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5078\n",
      "12600/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4982\n",
      "12601/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.4998\n",
      "12602/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.4982\n",
      "12603/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4958\n",
      "12604/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.5101\n",
      "12605/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.4952\n",
      "12606/15000:\n",
      "Training Loss: 0.4626 Validation Loss: 0.5069\n",
      "12607/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.4986\n",
      "12608/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5065\n",
      "12609/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.4978\n",
      "12610/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5211\n",
      "12611/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5128\n",
      "12612/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5162\n",
      "12613/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5032\n",
      "12614/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5045\n",
      "12615/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.5035\n",
      "12616/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5056\n",
      "12617/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5086\n",
      "12618/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5091\n",
      "12619/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5051\n",
      "12620/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5223\n",
      "12621/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5095\n",
      "12622/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5151\n",
      "12623/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5041\n",
      "12624/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5096\n",
      "12625/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5002\n",
      "12626/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5036\n",
      "12627/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.4997\n",
      "12628/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5060\n",
      "12629/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5173\n",
      "12630/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5208\n",
      "12631/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5010\n",
      "12632/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5083\n",
      "12633/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4988\n",
      "12634/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5001\n",
      "12635/15000:\n",
      "Training Loss: 0.4649 Validation Loss: 0.4926\n",
      "12636/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4980\n",
      "12637/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5000\n",
      "12638/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.4958\n",
      "12639/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.4983\n",
      "12640/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5140\n",
      "12641/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.4944\n",
      "12642/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5002\n",
      "12643/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.4996\n",
      "12644/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5086\n",
      "12645/15000:\n",
      "Training Loss: 0.4678 Validation Loss: 0.4945\n",
      "12646/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5027\n",
      "12647/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5066\n",
      "12648/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5042\n",
      "12649/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4998\n",
      "12650/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5024\n",
      "12651/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4991\n",
      "12652/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5013\n",
      "12653/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5056\n",
      "12654/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5138\n",
      "12655/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5093\n",
      "12656/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5151\n",
      "12657/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5004\n",
      "12658/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.4955\n",
      "12659/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5024\n",
      "12660/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5019\n",
      "12661/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4992\n",
      "12662/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5018\n",
      "12663/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.4960\n",
      "12664/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.4993\n",
      "12665/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5087\n",
      "12666/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5048\n",
      "12667/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5028\n",
      "12668/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5051\n",
      "12669/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5050\n",
      "12670/15000:\n",
      "Training Loss: 0.5008 Validation Loss: 0.5084\n",
      "12671/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5174\n",
      "12672/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5052\n",
      "12673/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5019\n",
      "12674/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5003\n",
      "12675/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5085\n",
      "12676/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5280\n",
      "12677/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5007\n",
      "12678/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5028\n",
      "12679/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5085\n",
      "12680/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5000\n",
      "12681/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5009\n",
      "12682/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5068\n",
      "12683/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5083\n",
      "12684/15000:\n",
      "Training Loss: 0.4699 Validation Loss: 0.5048\n",
      "12685/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.5068\n",
      "12686/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.4999\n",
      "12687/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5075\n",
      "12688/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4995\n",
      "12689/15000:\n",
      "Training Loss: 0.5033 Validation Loss: 0.5050\n",
      "12690/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.4916\n",
      "12691/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.4945\n",
      "12692/15000:\n",
      "Training Loss: 0.4720 Validation Loss: 0.4921\n",
      "12693/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4952\n",
      "12694/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5163\n",
      "12695/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4892\n",
      "12696/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.4935\n",
      "12697/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5041\n",
      "12698/15000:\n",
      "Training Loss: 0.5045 Validation Loss: 0.5276\n",
      "12699/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5129\n",
      "12700/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5069\n",
      "12701/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.4980\n",
      "12702/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5042\n",
      "12703/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5025\n",
      "12704/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4943\n",
      "12705/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4982\n",
      "12706/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4997\n",
      "12707/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5163\n",
      "12708/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5076\n",
      "12709/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5097\n",
      "12710/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5104\n",
      "12711/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5040\n",
      "12712/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5189\n",
      "12713/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5110\n",
      "12714/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5100\n",
      "12715/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5104\n",
      "12716/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5178\n",
      "12717/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5084\n",
      "12718/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5088\n",
      "12719/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.4987\n",
      "12720/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.4956\n",
      "12721/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5108\n",
      "12722/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5083\n",
      "12723/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5459\n",
      "12724/15000:\n",
      "Training Loss: 0.5435 Validation Loss: 0.5627\n",
      "12725/15000:\n",
      "Training Loss: 0.5327 Validation Loss: 0.5817\n",
      "12726/15000:\n",
      "Training Loss: 0.6193 Validation Loss: 0.5499\n",
      "12727/15000:\n",
      "Training Loss: 0.5386 Validation Loss: 0.5922\n",
      "12728/15000:\n",
      "Training Loss: 0.6194 Validation Loss: 0.5173\n",
      "12729/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5165\n",
      "12730/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5194\n",
      "12731/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5167\n",
      "12732/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5238\n",
      "12733/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5220\n",
      "12734/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5216\n",
      "12735/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5137\n",
      "12736/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5153\n",
      "12737/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5126\n",
      "12738/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5107\n",
      "12739/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5137\n",
      "12740/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5139\n",
      "12741/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5219\n",
      "12742/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5172\n",
      "12743/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5118\n",
      "12744/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5162\n",
      "12745/15000:\n",
      "Training Loss: 0.4635 Validation Loss: 0.5055\n",
      "12746/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5064\n",
      "12747/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5065\n",
      "12748/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4985\n",
      "12749/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4999\n",
      "12750/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.5077\n",
      "12751/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5068\n",
      "12752/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5026\n",
      "12753/15000:\n",
      "Training Loss: 0.4662 Validation Loss: 0.5133\n",
      "12754/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5036\n",
      "12755/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5142\n",
      "12756/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5012\n",
      "12757/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.4999\n",
      "12758/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5081\n",
      "12759/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.4938\n",
      "12760/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5030\n",
      "12761/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5033\n",
      "12762/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5363\n",
      "12763/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5100\n",
      "12764/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5091\n",
      "12765/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5201\n",
      "12766/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4981\n",
      "12767/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4958\n",
      "12768/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5051\n",
      "12769/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4979\n",
      "12770/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4970\n",
      "12771/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4985\n",
      "12772/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4957\n",
      "12773/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.5018\n",
      "12774/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5035\n",
      "12775/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.4981\n",
      "12776/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5156\n",
      "12777/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5145\n",
      "12778/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5236\n",
      "12779/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5152\n",
      "12780/15000:\n",
      "Training Loss: 0.5213 Validation Loss: 0.5333\n",
      "12781/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5205\n",
      "12782/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5020\n",
      "12783/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5126\n",
      "12784/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.4981\n",
      "12785/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5037\n",
      "12786/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5120\n",
      "12787/15000:\n",
      "Training Loss: 0.5175 Validation Loss: 0.5036\n",
      "12788/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5007\n",
      "12789/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.4952\n",
      "12790/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5156\n",
      "12791/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5020\n",
      "12792/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5141\n",
      "12793/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5033\n",
      "12794/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5044\n",
      "12795/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.4949\n",
      "12796/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4983\n",
      "12797/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5008\n",
      "12798/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5123\n",
      "12799/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5167\n",
      "12800/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5055\n",
      "12801/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5081\n",
      "12802/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.4989\n",
      "12803/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5026\n",
      "12804/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5213\n",
      "12805/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5015\n",
      "12806/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5022\n",
      "12807/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.4972\n",
      "12808/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5037\n",
      "12809/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5000\n",
      "12810/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5085\n",
      "12811/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5139\n",
      "12812/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5118\n",
      "12813/15000:\n",
      "Training Loss: 0.5133 Validation Loss: 0.5462\n",
      "12814/15000:\n",
      "Training Loss: 0.5248 Validation Loss: 0.5623\n",
      "12815/15000:\n",
      "Training Loss: 0.5734 Validation Loss: 0.5038\n",
      "12816/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4980\n",
      "12817/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.4981\n",
      "12818/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5018\n",
      "12819/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5024\n",
      "12820/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5063\n",
      "12821/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5096\n",
      "12822/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5155\n",
      "12823/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5147\n",
      "12824/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5152\n",
      "12825/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5028\n",
      "12826/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5225\n",
      "12827/15000:\n",
      "Training Loss: 0.5208 Validation Loss: 0.5167\n",
      "12828/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5126\n",
      "12829/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5468\n",
      "12830/15000:\n",
      "Training Loss: 0.5327 Validation Loss: 0.5256\n",
      "12831/15000:\n",
      "Training Loss: 0.5129 Validation Loss: 0.5039\n",
      "12832/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5021\n",
      "12833/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4959\n",
      "12834/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5026\n",
      "12835/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5016\n",
      "12836/15000:\n",
      "Training Loss: 0.4702 Validation Loss: 0.5032\n",
      "12837/15000:\n",
      "Training Loss: 0.4663 Validation Loss: 0.5054\n",
      "12838/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.4964\n",
      "12839/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5079\n",
      "12840/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5059\n",
      "12841/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5018\n",
      "12842/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.4992\n",
      "12843/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5109\n",
      "12844/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5035\n",
      "12845/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5073\n",
      "12846/15000:\n",
      "Training Loss: 0.4620 Validation Loss: 0.5151\n",
      "12847/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5057\n",
      "12848/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5135\n",
      "12849/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5192\n",
      "12850/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5158\n",
      "12851/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5115\n",
      "12852/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5141\n",
      "12853/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5074\n",
      "12854/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5115\n",
      "12855/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5060\n",
      "12856/15000:\n",
      "Training Loss: 0.4688 Validation Loss: 0.5000\n",
      "12857/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5029\n",
      "12858/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5087\n",
      "12859/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.4990\n",
      "12860/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5145\n",
      "12861/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5042\n",
      "12862/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5246\n",
      "12863/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5216\n",
      "12864/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5091\n",
      "12865/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5031\n",
      "12866/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5555\n",
      "12867/15000:\n",
      "Training Loss: 0.5256 Validation Loss: 0.5014\n",
      "12868/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5237\n",
      "12869/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5093\n",
      "12870/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5184\n",
      "12871/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5174\n",
      "12872/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5124\n",
      "12873/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5064\n",
      "12874/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5161\n",
      "12875/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5026\n",
      "12876/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.5020\n",
      "12877/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5083\n",
      "12878/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5081\n",
      "12879/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5062\n",
      "12880/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4986\n",
      "12881/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.5021\n",
      "12882/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5112\n",
      "12883/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5090\n",
      "12884/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5044\n",
      "12885/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5087\n",
      "12886/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5069\n",
      "12887/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5026\n",
      "12888/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.4989\n",
      "12889/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5013\n",
      "12890/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.5025\n",
      "12891/15000:\n",
      "Training Loss: 0.4713 Validation Loss: 0.5100\n",
      "12892/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5113\n",
      "12893/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5075\n",
      "12894/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5005\n",
      "12895/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5111\n",
      "12896/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5001\n",
      "12897/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5026\n",
      "12898/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5056\n",
      "12899/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5121\n",
      "12900/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5098\n",
      "12901/15000:\n",
      "Training Loss: 0.4628 Validation Loss: 0.5040\n",
      "12902/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5143\n",
      "12903/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5023\n",
      "12904/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5108\n",
      "12905/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.4967\n",
      "12906/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.4966\n",
      "12907/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5026\n",
      "12908/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.4907\n",
      "12909/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.4924\n",
      "12910/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.4997\n",
      "12911/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5013\n",
      "12912/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.4993\n",
      "12913/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5034\n",
      "12914/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5055\n",
      "12915/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5016\n",
      "12916/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5079\n",
      "12917/15000:\n",
      "Training Loss: 0.4558 Validation Loss: 0.4994\n",
      "12918/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5067\n",
      "12919/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5157\n",
      "12920/15000:\n",
      "Training Loss: 0.5179 Validation Loss: 0.5273\n",
      "12921/15000:\n",
      "Training Loss: 0.5173 Validation Loss: 0.5077\n",
      "12922/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5182\n",
      "12923/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5068\n",
      "12924/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5031\n",
      "12925/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5003\n",
      "12926/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5062\n",
      "12927/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5025\n",
      "12928/15000:\n",
      "Training Loss: 0.4676 Validation Loss: 0.5108\n",
      "12929/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5042\n",
      "12930/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5424\n",
      "12931/15000:\n",
      "Training Loss: 0.5320 Validation Loss: 0.5096\n",
      "12932/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.4959\n",
      "12933/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.4997\n",
      "12934/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5045\n",
      "12935/15000:\n",
      "Training Loss: 0.4678 Validation Loss: 0.5111\n",
      "12936/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5002\n",
      "12937/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5190\n",
      "12938/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5079\n",
      "12939/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5262\n",
      "12940/15000:\n",
      "Training Loss: 0.5168 Validation Loss: 0.5324\n",
      "12941/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5080\n",
      "12942/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5152\n",
      "12943/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5046\n",
      "12944/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.4998\n",
      "12945/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5043\n",
      "12946/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5036\n",
      "12947/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5048\n",
      "12948/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5028\n",
      "12949/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5024\n",
      "12950/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5062\n",
      "12951/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4972\n",
      "12952/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4955\n",
      "12953/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5003\n",
      "12954/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5185\n",
      "12955/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5077\n",
      "12956/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5204\n",
      "12957/15000:\n",
      "Training Loss: 0.5255 Validation Loss: 0.5130\n",
      "12958/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5070\n",
      "12959/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5082\n",
      "12960/15000:\n",
      "Training Loss: 0.4636 Validation Loss: 0.4982\n",
      "12961/15000:\n",
      "Training Loss: 0.4995 Validation Loss: 0.5026\n",
      "12962/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5062\n",
      "12963/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5005\n",
      "12964/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4965\n",
      "12965/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5032\n",
      "12966/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5018\n",
      "12967/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5015\n",
      "12968/15000:\n",
      "Training Loss: 0.4682 Validation Loss: 0.5033\n",
      "12969/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5029\n",
      "12970/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5034\n",
      "12971/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5264\n",
      "12972/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5036\n",
      "12973/15000:\n",
      "Training Loss: 0.4714 Validation Loss: 0.4985\n",
      "12974/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5051\n",
      "12975/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.5031\n",
      "12976/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5015\n",
      "12977/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5105\n",
      "12978/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5079\n",
      "12979/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5066\n",
      "12980/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5262\n",
      "12981/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5222\n",
      "12982/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.5170\n",
      "12983/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5003\n",
      "12984/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5063\n",
      "12985/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5076\n",
      "12986/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5053\n",
      "12987/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5029\n",
      "12988/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5020\n",
      "12989/15000:\n",
      "Training Loss: 0.4662 Validation Loss: 0.5069\n",
      "12990/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4997\n",
      "12991/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5072\n",
      "12992/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.4981\n",
      "12993/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5023\n",
      "12994/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5069\n",
      "12995/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5037\n",
      "12996/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5135\n",
      "12997/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5039\n",
      "12998/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5014\n",
      "12999/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.5031\n",
      "13000/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4984\n",
      "13001/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.4960\n",
      "13002/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5052\n",
      "13003/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5023\n",
      "13004/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5020\n",
      "13005/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5001\n",
      "13006/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5055\n",
      "13007/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5166\n",
      "13008/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5118\n",
      "13009/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5121\n",
      "13010/15000:\n",
      "Training Loss: 0.5098 Validation Loss: 0.5215\n",
      "13011/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5081\n",
      "13012/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5130\n",
      "13013/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5010\n",
      "13014/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5027\n",
      "13015/15000:\n",
      "Training Loss: 0.4680 Validation Loss: 0.5019\n",
      "13016/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5096\n",
      "13017/15000:\n",
      "Training Loss: 0.4692 Validation Loss: 0.5217\n",
      "13018/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5076\n",
      "13019/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4980\n",
      "13020/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5211\n",
      "13021/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5067\n",
      "13022/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5034\n",
      "13023/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5015\n",
      "13024/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5013\n",
      "13025/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5193\n",
      "13026/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5026\n",
      "13027/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.4980\n",
      "13028/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.4984\n",
      "13029/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5015\n",
      "13030/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4949\n",
      "13031/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5036\n",
      "13032/15000:\n",
      "Training Loss: 0.4678 Validation Loss: 0.5004\n",
      "13033/15000:\n",
      "Training Loss: 0.4668 Validation Loss: 0.5037\n",
      "13034/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.4992\n",
      "13035/15000:\n",
      "Training Loss: 0.4686 Validation Loss: 0.5065\n",
      "13036/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5152\n",
      "13037/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5265\n",
      "13038/15000:\n",
      "Training Loss: 0.5171 Validation Loss: 0.5046\n",
      "13039/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5006\n",
      "13040/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.4999\n",
      "13041/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5034\n",
      "13042/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5018\n",
      "13043/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5081\n",
      "13044/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4981\n",
      "13045/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5105\n",
      "13046/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5149\n",
      "13047/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5134\n",
      "13048/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5114\n",
      "13049/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5065\n",
      "13050/15000:\n",
      "Training Loss: 0.5007 Validation Loss: 0.5037\n",
      "13051/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5056\n",
      "13052/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5111\n",
      "13053/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5149\n",
      "13054/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5121\n",
      "13055/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5075\n",
      "13056/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5102\n",
      "13057/15000:\n",
      "Training Loss: 0.4663 Validation Loss: 0.5049\n",
      "13058/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5139\n",
      "13059/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5270\n",
      "13060/15000:\n",
      "Training Loss: 0.5191 Validation Loss: 0.5487\n",
      "13061/15000:\n",
      "Training Loss: 0.5360 Validation Loss: 0.5360\n",
      "13062/15000:\n",
      "Training Loss: 0.5282 Validation Loss: 0.5216\n",
      "13063/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.5092\n",
      "13064/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5092\n",
      "13065/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5106\n",
      "13066/15000:\n",
      "Training Loss: 0.5208 Validation Loss: 0.5143\n",
      "13067/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5295\n",
      "13068/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5142\n",
      "13069/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5076\n",
      "13070/15000:\n",
      "Training Loss: 0.5018 Validation Loss: 0.5038\n",
      "13071/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.4959\n",
      "13072/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5005\n",
      "13073/15000:\n",
      "Training Loss: 0.4569 Validation Loss: 0.4983\n",
      "13074/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5050\n",
      "13075/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5157\n",
      "13076/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5023\n",
      "13077/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4947\n",
      "13078/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.5013\n",
      "13079/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5164\n",
      "13080/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5290\n",
      "13081/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5345\n",
      "13082/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5199\n",
      "13083/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5095\n",
      "13084/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5036\n",
      "13085/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5051\n",
      "13086/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.4963\n",
      "13087/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.4945\n",
      "13088/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5096\n",
      "13089/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5243\n",
      "13090/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5425\n",
      "13091/15000:\n",
      "Training Loss: 0.5360 Validation Loss: 0.5543\n",
      "13092/15000:\n",
      "Training Loss: 0.5277 Validation Loss: 0.6463\n",
      "13093/15000:\n",
      "Training Loss: 0.6568 Validation Loss: 0.5188\n",
      "13094/15000:\n",
      "Training Loss: 0.5119 Validation Loss: 0.5085\n",
      "13095/15000:\n",
      "Training Loss: 0.5139 Validation Loss: 0.5131\n",
      "13096/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5097\n",
      "13097/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5231\n",
      "13098/15000:\n",
      "Training Loss: 0.5156 Validation Loss: 0.5159\n",
      "13099/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5092\n",
      "13100/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5092\n",
      "13101/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5066\n",
      "13102/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5061\n",
      "13103/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5082\n",
      "13104/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5006\n",
      "13105/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5007\n",
      "13106/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5150\n",
      "13107/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5065\n",
      "13108/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5064\n",
      "13109/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5007\n",
      "13110/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5114\n",
      "13111/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.4978\n",
      "13112/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.5122\n",
      "13113/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5116\n",
      "13114/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5043\n",
      "13115/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5083\n",
      "13116/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5048\n",
      "13117/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5129\n",
      "13118/15000:\n",
      "Training Loss: 0.4649 Validation Loss: 0.5049\n",
      "13119/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5013\n",
      "13120/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5119\n",
      "13121/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5142\n",
      "13122/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5062\n",
      "13123/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5111\n",
      "13124/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5028\n",
      "13125/15000:\n",
      "Training Loss: 0.4660 Validation Loss: 0.5153\n",
      "13126/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5074\n",
      "13127/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5127\n",
      "13128/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5070\n",
      "13129/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5045\n",
      "13130/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5064\n",
      "13131/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5076\n",
      "13132/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4980\n",
      "13133/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.4980\n",
      "13134/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5048\n",
      "13135/15000:\n",
      "Training Loss: 0.4716 Validation Loss: 0.5025\n",
      "13136/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5010\n",
      "13137/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5047\n",
      "13138/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.4998\n",
      "13139/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5156\n",
      "13140/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5089\n",
      "13141/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4981\n",
      "13142/15000:\n",
      "Training Loss: 0.5020 Validation Loss: 0.4907\n",
      "13143/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.4920\n",
      "13144/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5013\n",
      "13145/15000:\n",
      "Training Loss: 0.4643 Validation Loss: 0.5055\n",
      "13146/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5006\n",
      "13147/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4978\n",
      "13148/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.4990\n",
      "13149/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.4986\n",
      "13150/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5119\n",
      "13151/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5073\n",
      "13152/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5185\n",
      "13153/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5001\n",
      "13154/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5091\n",
      "13155/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5097\n",
      "13156/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5108\n",
      "13157/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5044\n",
      "13158/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5110\n",
      "13159/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.5034\n",
      "13160/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5005\n",
      "13161/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5050\n",
      "13162/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5021\n",
      "13163/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.4985\n",
      "13164/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.4971\n",
      "13165/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5462\n",
      "13166/15000:\n",
      "Training Loss: 0.5329 Validation Loss: 0.5277\n",
      "13167/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5087\n",
      "13168/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5050\n",
      "13169/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5191\n",
      "13170/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5143\n",
      "13171/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.5044\n",
      "13172/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5057\n",
      "13173/15000:\n",
      "Training Loss: 0.5047 Validation Loss: 0.5145\n",
      "13174/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5207\n",
      "13175/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5131\n",
      "13176/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5107\n",
      "13177/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5076\n",
      "13178/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5196\n",
      "13179/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5123\n",
      "13180/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5120\n",
      "13181/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5265\n",
      "13182/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5275\n",
      "13183/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5151\n",
      "13184/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5139\n",
      "13185/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5249\n",
      "13186/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5192\n",
      "13187/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5148\n",
      "13188/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5134\n",
      "13189/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5080\n",
      "13190/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5109\n",
      "13191/15000:\n",
      "Training Loss: 0.4676 Validation Loss: 0.5094\n",
      "13192/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5141\n",
      "13193/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4989\n",
      "13194/15000:\n",
      "Training Loss: 0.4659 Validation Loss: 0.5032\n",
      "13195/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5100\n",
      "13196/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5074\n",
      "13197/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5141\n",
      "13198/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5183\n",
      "13199/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5057\n",
      "13200/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5043\n",
      "13201/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5053\n",
      "13202/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5210\n",
      "13203/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5138\n",
      "13204/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5199\n",
      "13205/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5177\n",
      "13206/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5059\n",
      "13207/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5088\n",
      "13208/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5063\n",
      "13209/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.4990\n",
      "13210/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5102\n",
      "13211/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5147\n",
      "13212/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5176\n",
      "13213/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5069\n",
      "13214/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5050\n",
      "13215/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5074\n",
      "13216/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5262\n",
      "13217/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.6133\n",
      "13218/15000:\n",
      "Training Loss: 0.5980 Validation Loss: 0.5163\n",
      "13219/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5155\n",
      "13220/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5099\n",
      "13221/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5122\n",
      "13222/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5109\n",
      "13223/15000:\n",
      "Training Loss: 0.5279 Validation Loss: 0.5414\n",
      "13224/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5477\n",
      "13225/15000:\n",
      "Training Loss: 0.5551 Validation Loss: 0.5206\n",
      "13226/15000:\n",
      "Training Loss: 0.5147 Validation Loss: 0.5114\n",
      "13227/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5104\n",
      "13228/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5070\n",
      "13229/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5047\n",
      "13230/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5252\n",
      "13231/15000:\n",
      "Training Loss: 0.5107 Validation Loss: 0.5104\n",
      "13232/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5116\n",
      "13233/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5052\n",
      "13234/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5038\n",
      "13235/15000:\n",
      "Training Loss: 0.4671 Validation Loss: 0.5033\n",
      "13236/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5088\n",
      "13237/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5015\n",
      "13238/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5148\n",
      "13239/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5111\n",
      "13240/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5151\n",
      "13241/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.5070\n",
      "13242/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5074\n",
      "13243/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.4986\n",
      "13244/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5041\n",
      "13245/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5095\n",
      "13246/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5031\n",
      "13247/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5196\n",
      "13248/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5275\n",
      "13249/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5100\n",
      "13250/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5161\n",
      "13251/15000:\n",
      "Training Loss: 0.5144 Validation Loss: 0.5432\n",
      "13252/15000:\n",
      "Training Loss: 0.5276 Validation Loss: 0.5209\n",
      "13253/15000:\n",
      "Training Loss: 0.5232 Validation Loss: 0.5086\n",
      "13254/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5273\n",
      "13255/15000:\n",
      "Training Loss: 0.5273 Validation Loss: 0.5195\n",
      "13256/15000:\n",
      "Training Loss: 0.5126 Validation Loss: 0.5134\n",
      "13257/15000:\n",
      "Training Loss: 0.5064 Validation Loss: 0.5310\n",
      "13258/15000:\n",
      "Training Loss: 0.5274 Validation Loss: 0.5063\n",
      "13259/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5062\n",
      "13260/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5045\n",
      "13261/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5105\n",
      "13262/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5122\n",
      "13263/15000:\n",
      "Training Loss: 0.5054 Validation Loss: 0.5114\n",
      "13264/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5050\n",
      "13265/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5043\n",
      "13266/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5054\n",
      "13267/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5076\n",
      "13268/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5033\n",
      "13269/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5050\n",
      "13270/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5138\n",
      "13271/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5095\n",
      "13272/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5111\n",
      "13273/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5036\n",
      "13274/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5056\n",
      "13275/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5068\n",
      "13276/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.4999\n",
      "13277/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5129\n",
      "13278/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5071\n",
      "13279/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5142\n",
      "13280/15000:\n",
      "Training Loss: 0.4979 Validation Loss: 0.5142\n",
      "13281/15000:\n",
      "Training Loss: 0.5049 Validation Loss: 0.5104\n",
      "13282/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5045\n",
      "13283/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5001\n",
      "13284/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.4995\n",
      "13285/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5053\n",
      "13286/15000:\n",
      "Training Loss: 0.4602 Validation Loss: 0.5032\n",
      "13287/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5007\n",
      "13288/15000:\n",
      "Training Loss: 0.4613 Validation Loss: 0.5170\n",
      "13289/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5041\n",
      "13290/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5096\n",
      "13291/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5180\n",
      "13292/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5165\n",
      "13293/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5256\n",
      "13294/15000:\n",
      "Training Loss: 0.5203 Validation Loss: 0.5189\n",
      "13295/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5314\n",
      "13296/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5054\n",
      "13297/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5063\n",
      "13298/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5031\n",
      "13299/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5003\n",
      "13300/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5048\n",
      "13301/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5051\n",
      "13302/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5018\n",
      "13303/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.4985\n",
      "13304/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4997\n",
      "13305/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.5064\n",
      "13306/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.4970\n",
      "13307/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5056\n",
      "13308/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5102\n",
      "13309/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5103\n",
      "13310/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5066\n",
      "13311/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5132\n",
      "13312/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5172\n",
      "13313/15000:\n",
      "Training Loss: 0.5156 Validation Loss: 0.5001\n",
      "13314/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.4989\n",
      "13315/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5130\n",
      "13316/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.4954\n",
      "13317/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5057\n",
      "13318/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.4963\n",
      "13319/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5001\n",
      "13320/15000:\n",
      "Training Loss: 0.4701 Validation Loss: 0.4944\n",
      "13321/15000:\n",
      "Training Loss: 0.4588 Validation Loss: 0.5048\n",
      "13322/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.4997\n",
      "13323/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5000\n",
      "13324/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.4982\n",
      "13325/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4947\n",
      "13326/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5011\n",
      "13327/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.4945\n",
      "13328/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5007\n",
      "13329/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4936\n",
      "13330/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4938\n",
      "13331/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.4994\n",
      "13332/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.4939\n",
      "13333/15000:\n",
      "Training Loss: 0.4681 Validation Loss: 0.4996\n",
      "13334/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5001\n",
      "13335/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.4977\n",
      "13336/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5241\n",
      "13337/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5379\n",
      "13338/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5356\n",
      "13339/15000:\n",
      "Training Loss: 0.5408 Validation Loss: 0.5384\n",
      "13340/15000:\n",
      "Training Loss: 0.5239 Validation Loss: 0.5153\n",
      "13341/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5090\n",
      "13342/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.4994\n",
      "13343/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5047\n",
      "13344/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5067\n",
      "13345/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.4976\n",
      "13346/15000:\n",
      "Training Loss: 0.4677 Validation Loss: 0.5053\n",
      "13347/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5084\n",
      "13348/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5058\n",
      "13349/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5148\n",
      "13350/15000:\n",
      "Training Loss: 0.5085 Validation Loss: 0.4992\n",
      "13351/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5048\n",
      "13352/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5053\n",
      "13353/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5176\n",
      "13354/15000:\n",
      "Training Loss: 0.5057 Validation Loss: 0.5056\n",
      "13355/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5146\n",
      "13356/15000:\n",
      "Training Loss: 0.4676 Validation Loss: 0.5027\n",
      "13357/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5116\n",
      "13358/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5040\n",
      "13359/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.4998\n",
      "13360/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5041\n",
      "13361/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5108\n",
      "13362/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5037\n",
      "13363/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5036\n",
      "13364/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5031\n",
      "13365/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.4930\n",
      "13366/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4944\n",
      "13367/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.4999\n",
      "13368/15000:\n",
      "Training Loss: 0.4668 Validation Loss: 0.4967\n",
      "13369/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5003\n",
      "13370/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5006\n",
      "13371/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5038\n",
      "13372/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5021\n",
      "13373/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5035\n",
      "13374/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5097\n",
      "13375/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5039\n",
      "13376/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.4913\n",
      "13377/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.4960\n",
      "13378/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.4941\n",
      "13379/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5062\n",
      "13380/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5019\n",
      "13381/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.4985\n",
      "13382/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5128\n",
      "13383/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5061\n",
      "13384/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5040\n",
      "13385/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.5136\n",
      "13386/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5082\n",
      "13387/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5148\n",
      "13388/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5059\n",
      "13389/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5078\n",
      "13390/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5021\n",
      "13391/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5054\n",
      "13392/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5005\n",
      "13393/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5151\n",
      "13394/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5105\n",
      "13395/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5041\n",
      "13396/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5092\n",
      "13397/15000:\n",
      "Training Loss: 0.4719 Validation Loss: 0.5174\n",
      "13398/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5034\n",
      "13399/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5160\n",
      "13400/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5058\n",
      "13401/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5060\n",
      "13402/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5086\n",
      "13403/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5005\n",
      "13404/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5646\n",
      "13405/15000:\n",
      "Training Loss: 0.5384 Validation Loss: 0.5219\n",
      "13406/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5304\n",
      "13407/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5196\n",
      "13408/15000:\n",
      "Training Loss: 0.5225 Validation Loss: 0.5132\n",
      "13409/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5075\n",
      "13410/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5051\n",
      "13411/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.4975\n",
      "13412/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5091\n",
      "13413/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5028\n",
      "13414/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5114\n",
      "13415/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.5023\n",
      "13416/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5052\n",
      "13417/15000:\n",
      "Training Loss: 0.5077 Validation Loss: 0.4997\n",
      "13418/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4995\n",
      "13419/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.4983\n",
      "13420/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4941\n",
      "13421/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5010\n",
      "13422/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.4930\n",
      "13423/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5015\n",
      "13424/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5027\n",
      "13425/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5063\n",
      "13426/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4981\n",
      "13427/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5053\n",
      "13428/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5016\n",
      "13429/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5010\n",
      "13430/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5036\n",
      "13431/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5086\n",
      "13432/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5106\n",
      "13433/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5078\n",
      "13434/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5055\n",
      "13435/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5018\n",
      "13436/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5083\n",
      "13437/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5108\n",
      "13438/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5242\n",
      "13439/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5083\n",
      "13440/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5082\n",
      "13441/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5028\n",
      "13442/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5087\n",
      "13443/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5149\n",
      "13444/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5127\n",
      "13445/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5127\n",
      "13446/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5072\n",
      "13447/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5175\n",
      "13448/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5119\n",
      "13449/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5113\n",
      "13450/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5136\n",
      "13451/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5098\n",
      "13452/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5425\n",
      "13453/15000:\n",
      "Training Loss: 0.5249 Validation Loss: 0.5295\n",
      "13454/15000:\n",
      "Training Loss: 0.5115 Validation Loss: 0.5588\n",
      "13455/15000:\n",
      "Training Loss: 0.5211 Validation Loss: 0.5121\n",
      "13456/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5169\n",
      "13457/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5408\n",
      "13458/15000:\n",
      "Training Loss: 0.5200 Validation Loss: 0.5295\n",
      "13459/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5093\n",
      "13460/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5058\n",
      "13461/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5070\n",
      "13462/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5064\n",
      "13463/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5086\n",
      "13464/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5071\n",
      "13465/15000:\n",
      "Training Loss: 0.5137 Validation Loss: 0.5152\n",
      "13466/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5144\n",
      "13467/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5019\n",
      "13468/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5023\n",
      "13469/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5044\n",
      "13470/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4992\n",
      "13471/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5068\n",
      "13472/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5110\n",
      "13473/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5089\n",
      "13474/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5059\n",
      "13475/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5035\n",
      "13476/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5147\n",
      "13477/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5193\n",
      "13478/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5067\n",
      "13479/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5039\n",
      "13480/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5049\n",
      "13481/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5003\n",
      "13482/15000:\n",
      "Training Loss: 0.4638 Validation Loss: 0.5045\n",
      "13483/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5053\n",
      "13484/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5092\n",
      "13485/15000:\n",
      "Training Loss: 0.4653 Validation Loss: 0.4943\n",
      "13486/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5040\n",
      "13487/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5023\n",
      "13488/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5017\n",
      "13489/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5054\n",
      "13490/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.4979\n",
      "13491/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.4997\n",
      "13492/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5136\n",
      "13493/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5159\n",
      "13494/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5141\n",
      "13495/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5074\n",
      "13496/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5143\n",
      "13497/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.4950\n",
      "13498/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.4996\n",
      "13499/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5048\n",
      "13500/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5028\n",
      "13501/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.4993\n",
      "13502/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5035\n",
      "13503/15000:\n",
      "Training Loss: 0.4965 Validation Loss: 0.5026\n",
      "13504/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5149\n",
      "13505/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5050\n",
      "13506/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5024\n",
      "13507/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4955\n",
      "13508/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5076\n",
      "13509/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.4993\n",
      "13510/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.5137\n",
      "13511/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5041\n",
      "13512/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5095\n",
      "13513/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5072\n",
      "13514/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5084\n",
      "13515/15000:\n",
      "Training Loss: 0.5026 Validation Loss: 0.5029\n",
      "13516/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5020\n",
      "13517/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5115\n",
      "13518/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5135\n",
      "13519/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5035\n",
      "13520/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5123\n",
      "13521/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.4993\n",
      "13522/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5007\n",
      "13523/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5061\n",
      "13524/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5033\n",
      "13525/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.4979\n",
      "13526/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5000\n",
      "13527/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.4982\n",
      "13528/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5000\n",
      "13529/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5051\n",
      "13530/15000:\n",
      "Training Loss: 0.5004 Validation Loss: 0.5046\n",
      "13531/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5105\n",
      "13532/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5025\n",
      "13533/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.4958\n",
      "13534/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5021\n",
      "13535/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4994\n",
      "13536/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5020\n",
      "13537/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5022\n",
      "13538/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5107\n",
      "13539/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5015\n",
      "13540/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5117\n",
      "13541/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.5019\n",
      "13542/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5004\n",
      "13543/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5020\n",
      "13544/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5012\n",
      "13545/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5025\n",
      "13546/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5048\n",
      "13547/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5029\n",
      "13548/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5135\n",
      "13549/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.4991\n",
      "13550/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.4981\n",
      "13551/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.4959\n",
      "13552/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5075\n",
      "13553/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.4982\n",
      "13554/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5202\n",
      "13555/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.5131\n",
      "13556/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5998\n",
      "13557/15000:\n",
      "Training Loss: 0.6241 Validation Loss: 0.5401\n",
      "13558/15000:\n",
      "Training Loss: 0.5373 Validation Loss: 0.5111\n",
      "13559/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5116\n",
      "13560/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5038\n",
      "13561/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5023\n",
      "13562/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4970\n",
      "13563/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.4973\n",
      "13564/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5028\n",
      "13565/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5134\n",
      "13566/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5081\n",
      "13567/15000:\n",
      "Training Loss: 0.4956 Validation Loss: 0.5119\n",
      "13568/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5078\n",
      "13569/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5275\n",
      "13570/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5058\n",
      "13571/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5283\n",
      "13572/15000:\n",
      "Training Loss: 0.5009 Validation Loss: 0.5104\n",
      "13573/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5114\n",
      "13574/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5124\n",
      "13575/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5038\n",
      "13576/15000:\n",
      "Training Loss: 0.4776 Validation Loss: 0.5076\n",
      "13577/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.4988\n",
      "13578/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5035\n",
      "13579/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5036\n",
      "13580/15000:\n",
      "Training Loss: 0.5050 Validation Loss: 0.5047\n",
      "13581/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5007\n",
      "13582/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5102\n",
      "13583/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5085\n",
      "13584/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5064\n",
      "13585/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5013\n",
      "13586/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5052\n",
      "13587/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5013\n",
      "13588/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.4932\n",
      "13589/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5028\n",
      "13590/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.4986\n",
      "13591/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5210\n",
      "13592/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5072\n",
      "13593/15000:\n",
      "Training Loss: 0.4722 Validation Loss: 0.5036\n",
      "13594/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5133\n",
      "13595/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5104\n",
      "13596/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.5172\n",
      "13597/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5113\n",
      "13598/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5135\n",
      "13599/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.4994\n",
      "13600/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5110\n",
      "13601/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5041\n",
      "13602/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5098\n",
      "13603/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.4984\n",
      "13604/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5213\n",
      "13605/15000:\n",
      "Training Loss: 0.5124 Validation Loss: 0.5086\n",
      "13606/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5256\n",
      "13607/15000:\n",
      "Training Loss: 0.5183 Validation Loss: 0.5244\n",
      "13608/15000:\n",
      "Training Loss: 0.5112 Validation Loss: 0.5197\n",
      "13609/15000:\n",
      "Training Loss: 0.5292 Validation Loss: 0.5220\n",
      "13610/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5122\n",
      "13611/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5034\n",
      "13612/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5046\n",
      "13613/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5031\n",
      "13614/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.5114\n",
      "13615/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5022\n",
      "13616/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.4983\n",
      "13617/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5053\n",
      "13618/15000:\n",
      "Training Loss: 0.4704 Validation Loss: 0.5011\n",
      "13619/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5044\n",
      "13620/15000:\n",
      "Training Loss: 0.4597 Validation Loss: 0.5030\n",
      "13621/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.5041\n",
      "13622/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5100\n",
      "13623/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5047\n",
      "13624/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5017\n",
      "13625/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4986\n",
      "13626/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5025\n",
      "13627/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.5104\n",
      "13628/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5147\n",
      "13629/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5158\n",
      "13630/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5520\n",
      "13631/15000:\n",
      "Training Loss: 0.5424 Validation Loss: 0.5007\n",
      "13632/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4986\n",
      "13633/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.4979\n",
      "13634/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5006\n",
      "13635/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.4977\n",
      "13636/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4966\n",
      "13637/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5014\n",
      "13638/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.4963\n",
      "13639/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5023\n",
      "13640/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5060\n",
      "13641/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.4970\n",
      "13642/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5108\n",
      "13643/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5003\n",
      "13644/15000:\n",
      "Training Loss: 0.4677 Validation Loss: 0.5080\n",
      "13645/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.5001\n",
      "13646/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5006\n",
      "13647/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5038\n",
      "13648/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.4955\n",
      "13649/15000:\n",
      "Training Loss: 0.4735 Validation Loss: 0.4928\n",
      "13650/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.4922\n",
      "13651/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5012\n",
      "13652/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.4931\n",
      "13653/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.4998\n",
      "13654/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4943\n",
      "13655/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.4902\n",
      "13656/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.4931\n",
      "13657/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.4954\n",
      "13658/15000:\n",
      "Training Loss: 0.4627 Validation Loss: 0.4923\n",
      "13659/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4974\n",
      "13660/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5039\n",
      "13661/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.4936\n",
      "13662/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5019\n",
      "13663/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5001\n",
      "13664/15000:\n",
      "Training Loss: 0.4685 Validation Loss: 0.5073\n",
      "13665/15000:\n",
      "Training Loss: 0.5108 Validation Loss: 0.5133\n",
      "13666/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5181\n",
      "13667/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4980\n",
      "13668/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5039\n",
      "13669/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.4977\n",
      "13670/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4996\n",
      "13671/15000:\n",
      "Training Loss: 0.5005 Validation Loss: 0.5013\n",
      "13672/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5006\n",
      "13673/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5038\n",
      "13674/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5035\n",
      "13675/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4949\n",
      "13676/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.4973\n",
      "13677/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5078\n",
      "13678/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5298\n",
      "13679/15000:\n",
      "Training Loss: 0.5270 Validation Loss: 0.5238\n",
      "13680/15000:\n",
      "Training Loss: 0.5123 Validation Loss: 0.5096\n",
      "13681/15000:\n",
      "Training Loss: 0.5161 Validation Loss: 0.5114\n",
      "13682/15000:\n",
      "Training Loss: 0.5044 Validation Loss: 0.5036\n",
      "13683/15000:\n",
      "Training Loss: 0.4978 Validation Loss: 0.4964\n",
      "13684/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.4990\n",
      "13685/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.5042\n",
      "13686/15000:\n",
      "Training Loss: 0.4988 Validation Loss: 0.5022\n",
      "13687/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5105\n",
      "13688/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5070\n",
      "13689/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5029\n",
      "13690/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5009\n",
      "13691/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4989\n",
      "13692/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4975\n",
      "13693/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5038\n",
      "13694/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.4959\n",
      "13695/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.4949\n",
      "13696/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4993\n",
      "13697/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5309\n",
      "13698/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5046\n",
      "13699/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5207\n",
      "13700/15000:\n",
      "Training Loss: 0.5211 Validation Loss: 0.4999\n",
      "13701/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.4935\n",
      "13702/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.4921\n",
      "13703/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5018\n",
      "13704/15000:\n",
      "Training Loss: 0.4726 Validation Loss: 0.5043\n",
      "13705/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5054\n",
      "13706/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5009\n",
      "13707/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5059\n",
      "13708/15000:\n",
      "Training Loss: 0.4662 Validation Loss: 0.5096\n",
      "13709/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5077\n",
      "13710/15000:\n",
      "Training Loss: 0.4693 Validation Loss: 0.4995\n",
      "13711/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5061\n",
      "13712/15000:\n",
      "Training Loss: 0.4571 Validation Loss: 0.5069\n",
      "13713/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5022\n",
      "13714/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4989\n",
      "13715/15000:\n",
      "Training Loss: 0.4647 Validation Loss: 0.5036\n",
      "13716/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5148\n",
      "13717/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5036\n",
      "13718/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5047\n",
      "13719/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5008\n",
      "13720/15000:\n",
      "Training Loss: 0.4768 Validation Loss: 0.5020\n",
      "13721/15000:\n",
      "Training Loss: 0.4686 Validation Loss: 0.5179\n",
      "13722/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5030\n",
      "13723/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5108\n",
      "13724/15000:\n",
      "Training Loss: 0.4850 Validation Loss: 0.5047\n",
      "13725/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5162\n",
      "13726/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5135\n",
      "13727/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5001\n",
      "13728/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.4960\n",
      "13729/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5051\n",
      "13730/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5037\n",
      "13731/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4962\n",
      "13732/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.4994\n",
      "13733/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5008\n",
      "13734/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5066\n",
      "13735/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.4971\n",
      "13736/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.4987\n",
      "13737/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5041\n",
      "13738/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5020\n",
      "13739/15000:\n",
      "Training Loss: 0.4719 Validation Loss: 0.5071\n",
      "13740/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5026\n",
      "13741/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.5167\n",
      "13742/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5109\n",
      "13743/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5115\n",
      "13744/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5019\n",
      "13745/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5108\n",
      "13746/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.4967\n",
      "13747/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5116\n",
      "13748/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.4992\n",
      "13749/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5041\n",
      "13750/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5013\n",
      "13751/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5151\n",
      "13752/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5114\n",
      "13753/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5097\n",
      "13754/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5115\n",
      "13755/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5211\n",
      "13756/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5101\n",
      "13757/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5282\n",
      "13758/15000:\n",
      "Training Loss: 0.5318 Validation Loss: 0.5268\n",
      "13759/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5214\n",
      "13760/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.4950\n",
      "13761/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5003\n",
      "13762/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5051\n",
      "13763/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.4999\n",
      "13764/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5034\n",
      "13765/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.4968\n",
      "13766/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.4981\n",
      "13767/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5006\n",
      "13768/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5044\n",
      "13769/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5051\n",
      "13770/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5208\n",
      "13771/15000:\n",
      "Training Loss: 0.5041 Validation Loss: 0.5042\n",
      "13772/15000:\n",
      "Training Loss: 0.4781 Validation Loss: 0.5103\n",
      "13773/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5041\n",
      "13774/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5036\n",
      "13775/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.4995\n",
      "13776/15000:\n",
      "Training Loss: 0.4936 Validation Loss: 0.5100\n",
      "13777/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5007\n",
      "13778/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5007\n",
      "13779/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5084\n",
      "13780/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5040\n",
      "13781/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5037\n",
      "13782/15000:\n",
      "Training Loss: 0.4718 Validation Loss: 0.5064\n",
      "13783/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5051\n",
      "13784/15000:\n",
      "Training Loss: 0.4736 Validation Loss: 0.5152\n",
      "13785/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5197\n",
      "13786/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5202\n",
      "13787/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5141\n",
      "13788/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5270\n",
      "13789/15000:\n",
      "Training Loss: 0.5268 Validation Loss: 0.5283\n",
      "13790/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5036\n",
      "13791/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5047\n",
      "13792/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5014\n",
      "13793/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5059\n",
      "13794/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5061\n",
      "13795/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.4966\n",
      "13796/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5028\n",
      "13797/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5005\n",
      "13798/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.4979\n",
      "13799/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5025\n",
      "13800/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5007\n",
      "13801/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5017\n",
      "13802/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5139\n",
      "13803/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5114\n",
      "13804/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5134\n",
      "13805/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5145\n",
      "13806/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5340\n",
      "13807/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5165\n",
      "13808/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5177\n",
      "13809/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5084\n",
      "13810/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5161\n",
      "13811/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5013\n",
      "13812/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5087\n",
      "13813/15000:\n",
      "Training Loss: 0.4694 Validation Loss: 0.5063\n",
      "13814/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5078\n",
      "13815/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5082\n",
      "13816/15000:\n",
      "Training Loss: 0.4682 Validation Loss: 0.5047\n",
      "13817/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5054\n",
      "13818/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.4979\n",
      "13819/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5021\n",
      "13820/15000:\n",
      "Training Loss: 0.4707 Validation Loss: 0.5046\n",
      "13821/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5157\n",
      "13822/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5151\n",
      "13823/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5110\n",
      "13824/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.4997\n",
      "13825/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5083\n",
      "13826/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.4991\n",
      "13827/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5009\n",
      "13828/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.4885\n",
      "13829/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.4986\n",
      "13830/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.4989\n",
      "13831/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5017\n",
      "13832/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5063\n",
      "13833/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5140\n",
      "13834/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5026\n",
      "13835/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5097\n",
      "13836/15000:\n",
      "Training Loss: 0.5072 Validation Loss: 0.5210\n",
      "13837/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5186\n",
      "13838/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5137\n",
      "13839/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5200\n",
      "13840/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.4966\n",
      "13841/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.5125\n",
      "13842/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.5042\n",
      "13843/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5011\n",
      "13844/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5065\n",
      "13845/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5084\n",
      "13846/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5067\n",
      "13847/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.5057\n",
      "13848/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5026\n",
      "13849/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5070\n",
      "13850/15000:\n",
      "Training Loss: 0.4679 Validation Loss: 0.5021\n",
      "13851/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5066\n",
      "13852/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5101\n",
      "13853/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5150\n",
      "13854/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5092\n",
      "13855/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5139\n",
      "13856/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.5080\n",
      "13857/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5032\n",
      "13858/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5060\n",
      "13859/15000:\n",
      "Training Loss: 0.4690 Validation Loss: 0.5106\n",
      "13860/15000:\n",
      "Training Loss: 0.4675 Validation Loss: 0.5040\n",
      "13861/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5046\n",
      "13862/15000:\n",
      "Training Loss: 0.4963 Validation Loss: 0.5061\n",
      "13863/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5100\n",
      "13864/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5053\n",
      "13865/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5037\n",
      "13866/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5054\n",
      "13867/15000:\n",
      "Training Loss: 0.4695 Validation Loss: 0.5044\n",
      "13868/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5261\n",
      "13869/15000:\n",
      "Training Loss: 0.5314 Validation Loss: 0.5171\n",
      "13870/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5691\n",
      "13871/15000:\n",
      "Training Loss: 0.5629 Validation Loss: 0.5295\n",
      "13872/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5458\n",
      "13873/15000:\n",
      "Training Loss: 0.5303 Validation Loss: 0.5243\n",
      "13874/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5100\n",
      "13875/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5081\n",
      "13876/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5043\n",
      "13877/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5127\n",
      "13878/15000:\n",
      "Training Loss: 0.5094 Validation Loss: 0.5121\n",
      "13879/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5103\n",
      "13880/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5127\n",
      "13881/15000:\n",
      "Training Loss: 0.5101 Validation Loss: 0.5112\n",
      "13882/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5140\n",
      "13883/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5044\n",
      "13884/15000:\n",
      "Training Loss: 0.4667 Validation Loss: 0.5121\n",
      "13885/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.4981\n",
      "13886/15000:\n",
      "Training Loss: 0.4714 Validation Loss: 0.5152\n",
      "13887/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5015\n",
      "13888/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5016\n",
      "13889/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5097\n",
      "13890/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5062\n",
      "13891/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5245\n",
      "13892/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5083\n",
      "13893/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5148\n",
      "13894/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5116\n",
      "13895/15000:\n",
      "Training Loss: 0.5091 Validation Loss: 0.5129\n",
      "13896/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5035\n",
      "13897/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5066\n",
      "13898/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5041\n",
      "13899/15000:\n",
      "Training Loss: 0.5110 Validation Loss: 0.5056\n",
      "13900/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5155\n",
      "13901/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5164\n",
      "13902/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5164\n",
      "13903/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5097\n",
      "13904/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5032\n",
      "13905/15000:\n",
      "Training Loss: 0.4589 Validation Loss: 0.5044\n",
      "13906/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5051\n",
      "13907/15000:\n",
      "Training Loss: 0.4684 Validation Loss: 0.5011\n",
      "13908/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.4954\n",
      "13909/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5055\n",
      "13910/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5118\n",
      "13911/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5059\n",
      "13912/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5298\n",
      "13913/15000:\n",
      "Training Loss: 0.5060 Validation Loss: 0.5088\n",
      "13914/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5124\n",
      "13915/15000:\n",
      "Training Loss: 0.5012 Validation Loss: 0.5080\n",
      "13916/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5099\n",
      "13917/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5090\n",
      "13918/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5220\n",
      "13919/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5087\n",
      "13920/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5050\n",
      "13921/15000:\n",
      "Training Loss: 0.4640 Validation Loss: 0.5072\n",
      "13922/15000:\n",
      "Training Loss: 0.4977 Validation Loss: 0.4988\n",
      "13923/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.4993\n",
      "13924/15000:\n",
      "Training Loss: 0.4689 Validation Loss: 0.5030\n",
      "13925/15000:\n",
      "Training Loss: 0.4729 Validation Loss: 0.5067\n",
      "13926/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.4964\n",
      "13927/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5040\n",
      "13928/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5057\n",
      "13929/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5064\n",
      "13930/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5001\n",
      "13931/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5097\n",
      "13932/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5056\n",
      "13933/15000:\n",
      "Training Loss: 0.4898 Validation Loss: 0.5064\n",
      "13934/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5028\n",
      "13935/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5164\n",
      "13936/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5091\n",
      "13937/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5113\n",
      "13938/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5189\n",
      "13939/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5272\n",
      "13940/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5436\n",
      "13941/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5193\n",
      "13942/15000:\n",
      "Training Loss: 0.5199 Validation Loss: 0.5016\n",
      "13943/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5076\n",
      "13944/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5035\n",
      "13945/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.4965\n",
      "13946/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.4997\n",
      "13947/15000:\n",
      "Training Loss: 0.4675 Validation Loss: 0.5174\n",
      "13948/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5030\n",
      "13949/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5022\n",
      "13950/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5074\n",
      "13951/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5278\n",
      "13952/15000:\n",
      "Training Loss: 0.5334 Validation Loss: 0.5171\n",
      "13953/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5037\n",
      "13954/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5052\n",
      "13955/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5083\n",
      "13956/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5027\n",
      "13957/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5069\n",
      "13958/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5161\n",
      "13959/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5067\n",
      "13960/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5285\n",
      "13961/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5238\n",
      "13962/15000:\n",
      "Training Loss: 0.5109 Validation Loss: 0.5155\n",
      "13963/15000:\n",
      "Training Loss: 0.4722 Validation Loss: 0.5101\n",
      "13964/15000:\n",
      "Training Loss: 0.4723 Validation Loss: 0.5231\n",
      "13965/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5141\n",
      "13966/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5123\n",
      "13967/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5214\n",
      "13968/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5051\n",
      "13969/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5081\n",
      "13970/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5099\n",
      "13971/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5212\n",
      "13972/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5083\n",
      "13973/15000:\n",
      "Training Loss: 0.4888 Validation Loss: 0.5033\n",
      "13974/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5057\n",
      "13975/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5099\n",
      "13976/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5178\n",
      "13977/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5007\n",
      "13978/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5062\n",
      "13979/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5058\n",
      "13980/15000:\n",
      "Training Loss: 0.4779 Validation Loss: 0.5075\n",
      "13981/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5177\n",
      "13982/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5021\n",
      "13983/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5067\n",
      "13984/15000:\n",
      "Training Loss: 0.4636 Validation Loss: 0.5078\n",
      "13985/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5067\n",
      "13986/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5045\n",
      "13987/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5136\n",
      "13988/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5117\n",
      "13989/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5116\n",
      "13990/15000:\n",
      "Training Loss: 0.5063 Validation Loss: 0.5086\n",
      "13991/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5071\n",
      "13992/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.5182\n",
      "13993/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5057\n",
      "13994/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5138\n",
      "13995/15000:\n",
      "Training Loss: 0.4655 Validation Loss: 0.5042\n",
      "13996/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5147\n",
      "13997/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5110\n",
      "13998/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5094\n",
      "13999/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5060\n",
      "14000/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5294\n",
      "14001/15000:\n",
      "Training Loss: 0.5262 Validation Loss: 0.5057\n",
      "14002/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5112\n",
      "14003/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5070\n",
      "14004/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5087\n",
      "14005/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5148\n",
      "14006/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5137\n",
      "14007/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5091\n",
      "14008/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5081\n",
      "14009/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5003\n",
      "14010/15000:\n",
      "Training Loss: 0.4665 Validation Loss: 0.5026\n",
      "14011/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5020\n",
      "14012/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5074\n",
      "14013/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5094\n",
      "14014/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5080\n",
      "14015/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5126\n",
      "14016/15000:\n",
      "Training Loss: 0.4984 Validation Loss: 0.5137\n",
      "14017/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5060\n",
      "14018/15000:\n",
      "Training Loss: 0.5029 Validation Loss: 0.5017\n",
      "14019/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5040\n",
      "14020/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5042\n",
      "14021/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5103\n",
      "14022/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5064\n",
      "14023/15000:\n",
      "Training Loss: 0.5090 Validation Loss: 0.5108\n",
      "14024/15000:\n",
      "Training Loss: 0.4720 Validation Loss: 0.5035\n",
      "14025/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5170\n",
      "14026/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5135\n",
      "14027/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5069\n",
      "14028/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5107\n",
      "14029/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5183\n",
      "14030/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5112\n",
      "14031/15000:\n",
      "Training Loss: 0.5038 Validation Loss: 0.5161\n",
      "14032/15000:\n",
      "Training Loss: 0.5006 Validation Loss: 0.5032\n",
      "14033/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5130\n",
      "14034/15000:\n",
      "Training Loss: 0.5130 Validation Loss: 0.5009\n",
      "14035/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5142\n",
      "14036/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5106\n",
      "14037/15000:\n",
      "Training Loss: 0.4981 Validation Loss: 0.5161\n",
      "14038/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5110\n",
      "14039/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5077\n",
      "14040/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5142\n",
      "14041/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5335\n",
      "14042/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5190\n",
      "14043/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5142\n",
      "14044/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5091\n",
      "14045/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5022\n",
      "14046/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5059\n",
      "14047/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.4984\n",
      "14048/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5013\n",
      "14049/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5068\n",
      "14050/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5074\n",
      "14051/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5118\n",
      "14052/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5130\n",
      "14053/15000:\n",
      "Training Loss: 0.5186 Validation Loss: 0.5182\n",
      "14054/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5826\n",
      "14055/15000:\n",
      "Training Loss: 0.5976 Validation Loss: 0.5213\n",
      "14056/15000:\n",
      "Training Loss: 0.5014 Validation Loss: 0.5095\n",
      "14057/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5111\n",
      "14058/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5100\n",
      "14059/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5086\n",
      "14060/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4993\n",
      "14061/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5108\n",
      "14062/15000:\n",
      "Training Loss: 0.5015 Validation Loss: 0.4981\n",
      "14063/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5011\n",
      "14064/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5039\n",
      "14065/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5077\n",
      "14066/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5090\n",
      "14067/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5139\n",
      "14068/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5094\n",
      "14069/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5052\n",
      "14070/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5078\n",
      "14071/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5019\n",
      "14072/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5125\n",
      "14073/15000:\n",
      "Training Loss: 0.4883 Validation Loss: 0.5024\n",
      "14074/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5133\n",
      "14075/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5098\n",
      "14076/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5047\n",
      "14077/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5006\n",
      "14078/15000:\n",
      "Training Loss: 0.4744 Validation Loss: 0.5044\n",
      "14079/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.4981\n",
      "14080/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.4990\n",
      "14081/15000:\n",
      "Training Loss: 0.4691 Validation Loss: 0.5113\n",
      "14082/15000:\n",
      "Training Loss: 0.4987 Validation Loss: 0.5160\n",
      "14083/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5254\n",
      "14084/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5483\n",
      "14085/15000:\n",
      "Training Loss: 0.5375 Validation Loss: 0.5576\n",
      "14086/15000:\n",
      "Training Loss: 0.5506 Validation Loss: 0.5235\n",
      "14087/15000:\n",
      "Training Loss: 0.5013 Validation Loss: 0.5133\n",
      "14088/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4989\n",
      "14089/15000:\n",
      "Training Loss: 0.4797 Validation Loss: 0.5159\n",
      "14090/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5034\n",
      "14091/15000:\n",
      "Training Loss: 0.4688 Validation Loss: 0.5030\n",
      "14092/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5068\n",
      "14093/15000:\n",
      "Training Loss: 0.4970 Validation Loss: 0.5113\n",
      "14094/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.5186\n",
      "14095/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5025\n",
      "14096/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5195\n",
      "14097/15000:\n",
      "Training Loss: 0.5023 Validation Loss: 0.5089\n",
      "14098/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5037\n",
      "14099/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.4970\n",
      "14100/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.4988\n",
      "14101/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.4956\n",
      "14102/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5005\n",
      "14103/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5039\n",
      "14104/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5024\n",
      "14105/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5024\n",
      "14106/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.4980\n",
      "14107/15000:\n",
      "Training Loss: 0.4685 Validation Loss: 0.5113\n",
      "14108/15000:\n",
      "Training Loss: 0.4625 Validation Loss: 0.5046\n",
      "14109/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5038\n",
      "14110/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5013\n",
      "14111/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5054\n",
      "14112/15000:\n",
      "Training Loss: 0.4952 Validation Loss: 0.5144\n",
      "14113/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5149\n",
      "14114/15000:\n",
      "Training Loss: 0.4973 Validation Loss: 0.5219\n",
      "14115/15000:\n",
      "Training Loss: 0.5113 Validation Loss: 0.5455\n",
      "14116/15000:\n",
      "Training Loss: 0.5314 Validation Loss: 0.5160\n",
      "14117/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5069\n",
      "14118/15000:\n",
      "Training Loss: 0.4683 Validation Loss: 0.5026\n",
      "14119/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5031\n",
      "14120/15000:\n",
      "Training Loss: 0.4674 Validation Loss: 0.5085\n",
      "14121/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5155\n",
      "14122/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5074\n",
      "14123/15000:\n",
      "Training Loss: 0.5002 Validation Loss: 0.5082\n",
      "14124/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5067\n",
      "14125/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5047\n",
      "14126/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5148\n",
      "14127/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5000\n",
      "14128/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.4993\n",
      "14129/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5015\n",
      "14130/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5009\n",
      "14131/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5193\n",
      "14132/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5075\n",
      "14133/15000:\n",
      "Training Loss: 0.5093 Validation Loss: 0.5125\n",
      "14134/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5145\n",
      "14135/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5171\n",
      "14136/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5119\n",
      "14137/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5077\n",
      "14138/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5152\n",
      "14139/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5070\n",
      "14140/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5041\n",
      "14141/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5069\n",
      "14142/15000:\n",
      "Training Loss: 0.4972 Validation Loss: 0.4999\n",
      "14143/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5024\n",
      "14144/15000:\n",
      "Training Loss: 0.4708 Validation Loss: 0.4998\n",
      "14145/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5096\n",
      "14146/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5004\n",
      "14147/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5012\n",
      "14148/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5034\n",
      "14149/15000:\n",
      "Training Loss: 0.4715 Validation Loss: 0.5247\n",
      "14150/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5024\n",
      "14151/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5044\n",
      "14152/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5261\n",
      "14153/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5041\n",
      "14154/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5169\n",
      "14155/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5155\n",
      "14156/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5114\n",
      "14157/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5135\n",
      "14158/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5227\n",
      "14159/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5369\n",
      "14160/15000:\n",
      "Training Loss: 0.5056 Validation Loss: 0.5133\n",
      "14161/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5163\n",
      "14162/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5199\n",
      "14163/15000:\n",
      "Training Loss: 0.5100 Validation Loss: 0.5286\n",
      "14164/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5128\n",
      "14165/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5066\n",
      "14166/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5071\n",
      "14167/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5025\n",
      "14168/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5071\n",
      "14169/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5076\n",
      "14170/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5079\n",
      "14171/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5116\n",
      "14172/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5200\n",
      "14173/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5145\n",
      "14174/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5164\n",
      "14175/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5077\n",
      "14176/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5110\n",
      "14177/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5084\n",
      "14178/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5033\n",
      "14179/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.5040\n",
      "14180/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5028\n",
      "14181/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5219\n",
      "14182/15000:\n",
      "Training Loss: 0.5040 Validation Loss: 0.5176\n",
      "14183/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5196\n",
      "14184/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5047\n",
      "14185/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5274\n",
      "14186/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5132\n",
      "14187/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5138\n",
      "14188/15000:\n",
      "Training Loss: 0.4649 Validation Loss: 0.5132\n",
      "14189/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5108\n",
      "14190/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5193\n",
      "14191/15000:\n",
      "Training Loss: 0.4847 Validation Loss: 0.5071\n",
      "14192/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5041\n",
      "14193/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5194\n",
      "14194/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5103\n",
      "14195/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5111\n",
      "14196/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5063\n",
      "14197/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5037\n",
      "14198/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5135\n",
      "14199/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5184\n",
      "14200/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5130\n",
      "14201/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.4991\n",
      "14202/15000:\n",
      "Training Loss: 0.4666 Validation Loss: 0.5037\n",
      "14203/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5062\n",
      "14204/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5033\n",
      "14205/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5059\n",
      "14206/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5061\n",
      "14207/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5073\n",
      "14208/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5074\n",
      "14209/15000:\n",
      "Training Loss: 0.4917 Validation Loss: 0.5069\n",
      "14210/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5051\n",
      "14211/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5017\n",
      "14212/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.5077\n",
      "14213/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5019\n",
      "14214/15000:\n",
      "Training Loss: 0.4725 Validation Loss: 0.5110\n",
      "14215/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5093\n",
      "14216/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5239\n",
      "14217/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5066\n",
      "14218/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5042\n",
      "14219/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5027\n",
      "14220/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5070\n",
      "14221/15000:\n",
      "Training Loss: 0.4953 Validation Loss: 0.5159\n",
      "14222/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5112\n",
      "14223/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5213\n",
      "14224/15000:\n",
      "Training Loss: 0.5103 Validation Loss: 0.5026\n",
      "14225/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5045\n",
      "14226/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.4964\n",
      "14227/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5046\n",
      "14228/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5031\n",
      "14229/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5090\n",
      "14230/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5028\n",
      "14231/15000:\n",
      "Training Loss: 0.4857 Validation Loss: 0.5067\n",
      "14232/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5114\n",
      "14233/15000:\n",
      "Training Loss: 0.4960 Validation Loss: 0.5266\n",
      "14234/15000:\n",
      "Training Loss: 0.5293 Validation Loss: 0.5033\n",
      "14235/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5125\n",
      "14236/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5174\n",
      "14237/15000:\n",
      "Training Loss: 0.5082 Validation Loss: 0.5162\n",
      "14238/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5047\n",
      "14239/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5064\n",
      "14240/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5035\n",
      "14241/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5097\n",
      "14242/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5129\n",
      "14243/15000:\n",
      "Training Loss: 0.5084 Validation Loss: 0.5077\n",
      "14244/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5080\n",
      "14245/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5393\n",
      "14246/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5116\n",
      "14247/15000:\n",
      "Training Loss: 0.5055 Validation Loss: 0.5062\n",
      "14248/15000:\n",
      "Training Loss: 0.4817 Validation Loss: 0.5064\n",
      "14249/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4983\n",
      "14250/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5067\n",
      "14251/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5104\n",
      "14252/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5073\n",
      "14253/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5070\n",
      "14254/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5017\n",
      "14255/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5194\n",
      "14256/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5053\n",
      "14257/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5143\n",
      "14258/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5277\n",
      "14259/15000:\n",
      "Training Loss: 0.5125 Validation Loss: 0.5417\n",
      "14260/15000:\n",
      "Training Loss: 0.5121 Validation Loss: 0.5006\n",
      "14261/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5122\n",
      "14262/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5048\n",
      "14263/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5071\n",
      "14264/15000:\n",
      "Training Loss: 0.4690 Validation Loss: 0.5041\n",
      "14265/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5108\n",
      "14266/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5107\n",
      "14267/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5127\n",
      "14268/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5240\n",
      "14269/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5074\n",
      "14270/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5031\n",
      "14271/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5065\n",
      "14272/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5121\n",
      "14273/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5131\n",
      "14274/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5146\n",
      "14275/15000:\n",
      "Training Loss: 0.4945 Validation Loss: 0.5130\n",
      "14276/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5109\n",
      "14277/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5156\n",
      "14278/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5069\n",
      "14279/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5122\n",
      "14280/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5051\n",
      "14281/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5041\n",
      "14282/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.5043\n",
      "14283/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5132\n",
      "14284/15000:\n",
      "Training Loss: 0.4634 Validation Loss: 0.5235\n",
      "14285/15000:\n",
      "Training Loss: 0.4990 Validation Loss: 0.5156\n",
      "14286/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5279\n",
      "14287/15000:\n",
      "Training Loss: 0.5096 Validation Loss: 0.5208\n",
      "14288/15000:\n",
      "Training Loss: 0.5118 Validation Loss: 0.5157\n",
      "14289/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5004\n",
      "14290/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5095\n",
      "14291/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5122\n",
      "14292/15000:\n",
      "Training Loss: 0.5027 Validation Loss: 0.5155\n",
      "14293/15000:\n",
      "Training Loss: 0.4959 Validation Loss: 0.5104\n",
      "14294/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5057\n",
      "14295/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5092\n",
      "14296/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5115\n",
      "14297/15000:\n",
      "Training Loss: 0.4903 Validation Loss: 0.5230\n",
      "14298/15000:\n",
      "Training Loss: 0.5076 Validation Loss: 0.5426\n",
      "14299/15000:\n",
      "Training Loss: 0.5141 Validation Loss: 0.5028\n",
      "14300/15000:\n",
      "Training Loss: 0.4993 Validation Loss: 0.5045\n",
      "14301/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.5144\n",
      "14302/15000:\n",
      "Training Loss: 0.5080 Validation Loss: 0.5161\n",
      "14303/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5139\n",
      "14304/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.5079\n",
      "14305/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5370\n",
      "14306/15000:\n",
      "Training Loss: 0.5138 Validation Loss: 0.5105\n",
      "14307/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5097\n",
      "14308/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5043\n",
      "14309/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5047\n",
      "14310/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5132\n",
      "14311/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5213\n",
      "14312/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5232\n",
      "14313/15000:\n",
      "Training Loss: 0.4896 Validation Loss: 0.5126\n",
      "14314/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5164\n",
      "14315/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5039\n",
      "14316/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5036\n",
      "14317/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5153\n",
      "14318/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5122\n",
      "14319/15000:\n",
      "Training Loss: 0.4935 Validation Loss: 0.5233\n",
      "14320/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5054\n",
      "14321/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.4982\n",
      "14322/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.4970\n",
      "14323/15000:\n",
      "Training Loss: 0.4756 Validation Loss: 0.5054\n",
      "14324/15000:\n",
      "Training Loss: 0.4653 Validation Loss: 0.4965\n",
      "14325/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5027\n",
      "14326/15000:\n",
      "Training Loss: 0.4666 Validation Loss: 0.4994\n",
      "14327/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5010\n",
      "14328/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5094\n",
      "14329/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.4944\n",
      "14330/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.4972\n",
      "14331/15000:\n",
      "Training Loss: 0.4548 Validation Loss: 0.5028\n",
      "14332/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.4991\n",
      "14333/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5197\n",
      "14334/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.4993\n",
      "14335/15000:\n",
      "Training Loss: 0.4724 Validation Loss: 0.5003\n",
      "14336/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.4983\n",
      "14337/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5062\n",
      "14338/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5066\n",
      "14339/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5083\n",
      "14340/15000:\n",
      "Training Loss: 0.4712 Validation Loss: 0.5239\n",
      "14341/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5042\n",
      "14342/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5054\n",
      "14343/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.4943\n",
      "14344/15000:\n",
      "Training Loss: 0.4934 Validation Loss: 0.5046\n",
      "14345/15000:\n",
      "Training Loss: 0.4866 Validation Loss: 0.4924\n",
      "14346/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.4993\n",
      "14347/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5035\n",
      "14348/15000:\n",
      "Training Loss: 0.4802 Validation Loss: 0.5042\n",
      "14349/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5079\n",
      "14350/15000:\n",
      "Training Loss: 0.4910 Validation Loss: 0.5087\n",
      "14351/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5134\n",
      "14352/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5044\n",
      "14353/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5166\n",
      "14354/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5056\n",
      "14355/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5076\n",
      "14356/15000:\n",
      "Training Loss: 0.5052 Validation Loss: 0.5104\n",
      "14357/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.5185\n",
      "14358/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5164\n",
      "14359/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5071\n",
      "14360/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5071\n",
      "14361/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5052\n",
      "14362/15000:\n",
      "Training Loss: 0.4845 Validation Loss: 0.5150\n",
      "14363/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5078\n",
      "14364/15000:\n",
      "Training Loss: 0.4932 Validation Loss: 0.5282\n",
      "14365/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5147\n",
      "14366/15000:\n",
      "Training Loss: 0.5032 Validation Loss: 0.5100\n",
      "14367/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5070\n",
      "14368/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5250\n",
      "14369/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5131\n",
      "14370/15000:\n",
      "Training Loss: 0.5081 Validation Loss: 0.5312\n",
      "14371/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.5089\n",
      "14372/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5019\n",
      "14373/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.4992\n",
      "14374/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5036\n",
      "14375/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5017\n",
      "14376/15000:\n",
      "Training Loss: 0.4971 Validation Loss: 0.5041\n",
      "14377/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5106\n",
      "14378/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.4973\n",
      "14379/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5026\n",
      "14380/15000:\n",
      "Training Loss: 0.4699 Validation Loss: 0.5031\n",
      "14381/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5039\n",
      "14382/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5100\n",
      "14383/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5069\n",
      "14384/15000:\n",
      "Training Loss: 0.4828 Validation Loss: 0.5190\n",
      "14385/15000:\n",
      "Training Loss: 0.5131 Validation Loss: 0.5259\n",
      "14386/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5529\n",
      "14387/15000:\n",
      "Training Loss: 0.5176 Validation Loss: 0.5187\n",
      "14388/15000:\n",
      "Training Loss: 0.5142 Validation Loss: 0.5169\n",
      "14389/15000:\n",
      "Training Loss: 0.5092 Validation Loss: 0.5061\n",
      "14390/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5097\n",
      "14391/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5069\n",
      "14392/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5095\n",
      "14393/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5109\n",
      "14394/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5032\n",
      "14395/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5059\n",
      "14396/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5008\n",
      "14397/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.4969\n",
      "14398/15000:\n",
      "Training Loss: 0.4900 Validation Loss: 0.5021\n",
      "14399/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5077\n",
      "14400/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5140\n",
      "14401/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5002\n",
      "14402/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5069\n",
      "14403/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5085\n",
      "14404/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4986\n",
      "14405/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5064\n",
      "14406/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5027\n",
      "14407/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5052\n",
      "14408/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.4997\n",
      "14409/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5001\n",
      "14410/15000:\n",
      "Training Loss: 0.4876 Validation Loss: 0.4975\n",
      "14411/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5006\n",
      "14412/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.4987\n",
      "14413/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5049\n",
      "14414/15000:\n",
      "Training Loss: 0.4930 Validation Loss: 0.5015\n",
      "14415/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5021\n",
      "14416/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5017\n",
      "14417/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5063\n",
      "14418/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5030\n",
      "14419/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5062\n",
      "14420/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5021\n",
      "14421/15000:\n",
      "Training Loss: 0.4851 Validation Loss: 0.5107\n",
      "14422/15000:\n",
      "Training Loss: 0.5079 Validation Loss: 0.5094\n",
      "14423/15000:\n",
      "Training Loss: 0.4975 Validation Loss: 0.5163\n",
      "14424/15000:\n",
      "Training Loss: 0.5102 Validation Loss: 0.5205\n",
      "14425/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5131\n",
      "14426/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5176\n",
      "14427/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5206\n",
      "14428/15000:\n",
      "Training Loss: 0.5146 Validation Loss: 0.5642\n",
      "14429/15000:\n",
      "Training Loss: 0.5411 Validation Loss: 0.6352\n",
      "14430/15000:\n",
      "Training Loss: 0.6238 Validation Loss: 0.5116\n",
      "14431/15000:\n",
      "Training Loss: 0.4831 Validation Loss: 0.5189\n",
      "14432/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5152\n",
      "14433/15000:\n",
      "Training Loss: 0.4890 Validation Loss: 0.5071\n",
      "14434/15000:\n",
      "Training Loss: 0.4832 Validation Loss: 0.5133\n",
      "14435/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5111\n",
      "14436/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5085\n",
      "14437/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5119\n",
      "14438/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5078\n",
      "14439/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5034\n",
      "14440/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5085\n",
      "14441/15000:\n",
      "Training Loss: 0.4841 Validation Loss: 0.5091\n",
      "14442/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5001\n",
      "14443/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5039\n",
      "14444/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5040\n",
      "14445/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5052\n",
      "14446/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5023\n",
      "14447/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5010\n",
      "14448/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5066\n",
      "14449/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5499\n",
      "14450/15000:\n",
      "Training Loss: 0.5387 Validation Loss: 0.5212\n",
      "14451/15000:\n",
      "Training Loss: 0.5106 Validation Loss: 0.5105\n",
      "14452/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5010\n",
      "14453/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.4973\n",
      "14454/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5114\n",
      "14455/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5154\n",
      "14456/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5118\n",
      "14457/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5113\n",
      "14458/15000:\n",
      "Training Loss: 0.4942 Validation Loss: 0.5115\n",
      "14459/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5061\n",
      "14460/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5224\n",
      "14461/15000:\n",
      "Training Loss: 0.5162 Validation Loss: 0.5068\n",
      "14462/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5091\n",
      "14463/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.5290\n",
      "14464/15000:\n",
      "Training Loss: 0.5192 Validation Loss: 0.5191\n",
      "14465/15000:\n",
      "Training Loss: 0.4946 Validation Loss: 0.5390\n",
      "14466/15000:\n",
      "Training Loss: 0.5672 Validation Loss: 0.5195\n",
      "14467/15000:\n",
      "Training Loss: 0.4974 Validation Loss: 0.5114\n",
      "14468/15000:\n",
      "Training Loss: 0.4870 Validation Loss: 0.5119\n",
      "14469/15000:\n",
      "Training Loss: 0.5011 Validation Loss: 0.5020\n",
      "14470/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.4986\n",
      "14471/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5010\n",
      "14472/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5001\n",
      "14473/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5081\n",
      "14474/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.4989\n",
      "14475/15000:\n",
      "Training Loss: 0.4666 Validation Loss: 0.4976\n",
      "14476/15000:\n",
      "Training Loss: 0.4697 Validation Loss: 0.5232\n",
      "14477/15000:\n",
      "Training Loss: 0.5104 Validation Loss: 0.5200\n",
      "14478/15000:\n",
      "Training Loss: 0.4985 Validation Loss: 0.5042\n",
      "14479/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5046\n",
      "14480/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.5102\n",
      "14481/15000:\n",
      "Training Loss: 0.4899 Validation Loss: 0.5083\n",
      "14482/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5109\n",
      "14483/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5032\n",
      "14484/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5118\n",
      "14485/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5178\n",
      "14486/15000:\n",
      "Training Loss: 0.5043 Validation Loss: 0.5015\n",
      "14487/15000:\n",
      "Training Loss: 0.4730 Validation Loss: 0.5104\n",
      "14488/15000:\n",
      "Training Loss: 0.4949 Validation Loss: 0.5036\n",
      "14489/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5057\n",
      "14490/15000:\n",
      "Training Loss: 0.4753 Validation Loss: 0.5090\n",
      "14491/15000:\n",
      "Training Loss: 0.4715 Validation Loss: 0.4992\n",
      "14492/15000:\n",
      "Training Loss: 0.4771 Validation Loss: 0.5059\n",
      "14493/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5145\n",
      "14494/15000:\n",
      "Training Loss: 0.4722 Validation Loss: 0.5073\n",
      "14495/15000:\n",
      "Training Loss: 0.4662 Validation Loss: 0.5086\n",
      "14496/15000:\n",
      "Training Loss: 0.4581 Validation Loss: 0.5052\n",
      "14497/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5056\n",
      "14498/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5128\n",
      "14499/15000:\n",
      "Training Loss: 0.4790 Validation Loss: 0.5177\n",
      "14500/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5101\n",
      "14501/15000:\n",
      "Training Loss: 0.4769 Validation Loss: 0.5083\n",
      "14502/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5061\n",
      "14503/15000:\n",
      "Training Loss: 0.4868 Validation Loss: 0.5030\n",
      "14504/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5137\n",
      "14505/15000:\n",
      "Training Loss: 0.4922 Validation Loss: 0.5088\n",
      "14506/15000:\n",
      "Training Loss: 0.4739 Validation Loss: 0.5093\n",
      "14507/15000:\n",
      "Training Loss: 0.4938 Validation Loss: 0.5094\n",
      "14508/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5100\n",
      "14509/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5069\n",
      "14510/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5022\n",
      "14511/15000:\n",
      "Training Loss: 0.4671 Validation Loss: 0.5052\n",
      "14512/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5143\n",
      "14513/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5082\n",
      "14514/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5325\n",
      "14515/15000:\n",
      "Training Loss: 0.5216 Validation Loss: 0.5011\n",
      "14516/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5112\n",
      "14517/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.4996\n",
      "14518/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5050\n",
      "14519/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.4957\n",
      "14520/15000:\n",
      "Training Loss: 0.4679 Validation Loss: 0.5034\n",
      "14521/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5051\n",
      "14522/15000:\n",
      "Training Loss: 0.5067 Validation Loss: 0.5021\n",
      "14523/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5073\n",
      "14524/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5020\n",
      "14525/15000:\n",
      "Training Loss: 0.4902 Validation Loss: 0.5149\n",
      "14526/15000:\n",
      "Training Loss: 0.5088 Validation Loss: 0.5047\n",
      "14527/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5160\n",
      "14528/15000:\n",
      "Training Loss: 0.4909 Validation Loss: 0.5025\n",
      "14529/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5099\n",
      "14530/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5123\n",
      "14531/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5164\n",
      "14532/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5057\n",
      "14533/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5103\n",
      "14534/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5029\n",
      "14535/15000:\n",
      "Training Loss: 0.4656 Validation Loss: 0.5048\n",
      "14536/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.4985\n",
      "14537/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.4993\n",
      "14538/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5044\n",
      "14539/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.4961\n",
      "14540/15000:\n",
      "Training Loss: 0.4690 Validation Loss: 0.4961\n",
      "14541/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.4965\n",
      "14542/15000:\n",
      "Training Loss: 0.4616 Validation Loss: 0.5286\n",
      "14543/15000:\n",
      "Training Loss: 0.4968 Validation Loss: 0.4949\n",
      "14544/15000:\n",
      "Training Loss: 0.4825 Validation Loss: 0.4964\n",
      "14545/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5002\n",
      "14546/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5079\n",
      "14547/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5016\n",
      "14548/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5033\n",
      "14549/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5037\n",
      "14550/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5006\n",
      "14551/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5013\n",
      "14552/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5035\n",
      "14553/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.4995\n",
      "14554/15000:\n",
      "Training Loss: 0.4684 Validation Loss: 0.5057\n",
      "14555/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5043\n",
      "14556/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.4974\n",
      "14557/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5152\n",
      "14558/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5075\n",
      "14559/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5026\n",
      "14560/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5121\n",
      "14561/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5067\n",
      "14562/15000:\n",
      "Training Loss: 0.4879 Validation Loss: 0.5038\n",
      "14563/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.5075\n",
      "14564/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5037\n",
      "14565/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5017\n",
      "14566/15000:\n",
      "Training Loss: 0.4696 Validation Loss: 0.4997\n",
      "14567/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4978\n",
      "14568/15000:\n",
      "Training Loss: 0.4667 Validation Loss: 0.4982\n",
      "14569/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.4975\n",
      "14570/15000:\n",
      "Training Loss: 0.4547 Validation Loss: 0.5047\n",
      "14571/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.4958\n",
      "14572/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5075\n",
      "14573/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5136\n",
      "14574/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5113\n",
      "14575/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5045\n",
      "14576/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5037\n",
      "14577/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5050\n",
      "14578/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.5103\n",
      "14579/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.4977\n",
      "14580/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.5021\n",
      "14581/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5160\n",
      "14582/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5186\n",
      "14583/15000:\n",
      "Training Loss: 0.4941 Validation Loss: 0.5124\n",
      "14584/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.4986\n",
      "14585/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5102\n",
      "14586/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5074\n",
      "14587/15000:\n",
      "Training Loss: 0.4964 Validation Loss: 0.5054\n",
      "14588/15000:\n",
      "Training Loss: 0.4706 Validation Loss: 0.5031\n",
      "14589/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5030\n",
      "14590/15000:\n",
      "Training Loss: 0.4708 Validation Loss: 0.5028\n",
      "14591/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.4990\n",
      "14592/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5000\n",
      "14593/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5070\n",
      "14594/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.4990\n",
      "14595/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5054\n",
      "14596/15000:\n",
      "Training Loss: 0.4798 Validation Loss: 0.5003\n",
      "14597/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5063\n",
      "14598/15000:\n",
      "Training Loss: 0.4719 Validation Loss: 0.5088\n",
      "14599/15000:\n",
      "Training Loss: 0.4997 Validation Loss: 0.5090\n",
      "14600/15000:\n",
      "Training Loss: 0.4614 Validation Loss: 0.4995\n",
      "14601/15000:\n",
      "Training Loss: 0.4877 Validation Loss: 0.5107\n",
      "14602/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5110\n",
      "14603/15000:\n",
      "Training Loss: 0.4906 Validation Loss: 0.5177\n",
      "14604/15000:\n",
      "Training Loss: 0.5025 Validation Loss: 0.5151\n",
      "14605/15000:\n",
      "Training Loss: 0.4920 Validation Loss: 0.5098\n",
      "14606/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5047\n",
      "14607/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5021\n",
      "14608/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5577\n",
      "14609/15000:\n",
      "Training Loss: 0.5349 Validation Loss: 0.5202\n",
      "14610/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5146\n",
      "14611/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5098\n",
      "14612/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5043\n",
      "14613/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5048\n",
      "14614/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.4994\n",
      "14615/15000:\n",
      "Training Loss: 0.4655 Validation Loss: 0.5006\n",
      "14616/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.4999\n",
      "14617/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5033\n",
      "14618/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5047\n",
      "14619/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5118\n",
      "14620/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5053\n",
      "14621/15000:\n",
      "Training Loss: 0.4678 Validation Loss: 0.5081\n",
      "14622/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5087\n",
      "14623/15000:\n",
      "Training Loss: 0.4591 Validation Loss: 0.5084\n",
      "14624/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.5002\n",
      "14625/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.4973\n",
      "14626/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5062\n",
      "14627/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.5069\n",
      "14628/15000:\n",
      "Training Loss: 0.4752 Validation Loss: 0.5077\n",
      "14629/15000:\n",
      "Training Loss: 0.4754 Validation Loss: 0.4942\n",
      "14630/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.4990\n",
      "14631/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5445\n",
      "14632/15000:\n",
      "Training Loss: 0.5598 Validation Loss: 0.4962\n",
      "14633/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5012\n",
      "14634/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.4945\n",
      "14635/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4936\n",
      "14636/15000:\n",
      "Training Loss: 0.4702 Validation Loss: 0.4972\n",
      "14637/15000:\n",
      "Training Loss: 0.5039 Validation Loss: 0.4979\n",
      "14638/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5193\n",
      "14639/15000:\n",
      "Training Loss: 0.5003 Validation Loss: 0.5278\n",
      "14640/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5297\n",
      "14641/15000:\n",
      "Training Loss: 0.5316 Validation Loss: 0.5250\n",
      "14642/15000:\n",
      "Training Loss: 0.4998 Validation Loss: 0.5032\n",
      "14643/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.4992\n",
      "14644/15000:\n",
      "Training Loss: 0.4778 Validation Loss: 0.5093\n",
      "14645/15000:\n",
      "Training Loss: 0.4919 Validation Loss: 0.5213\n",
      "14646/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5244\n",
      "14647/15000:\n",
      "Training Loss: 0.5165 Validation Loss: 0.5150\n",
      "14648/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5077\n",
      "14649/15000:\n",
      "Training Loss: 0.4948 Validation Loss: 0.5079\n",
      "14650/15000:\n",
      "Training Loss: 0.4824 Validation Loss: 0.5115\n",
      "14651/15000:\n",
      "Training Loss: 0.4863 Validation Loss: 0.5049\n",
      "14652/15000:\n",
      "Training Loss: 0.4805 Validation Loss: 0.5105\n",
      "14653/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5114\n",
      "14654/15000:\n",
      "Training Loss: 0.4992 Validation Loss: 0.5116\n",
      "14655/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5045\n",
      "14656/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5174\n",
      "14657/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5108\n",
      "14658/15000:\n",
      "Training Loss: 0.4989 Validation Loss: 0.5086\n",
      "14659/15000:\n",
      "Training Loss: 0.4788 Validation Loss: 0.5024\n",
      "14660/15000:\n",
      "Training Loss: 0.4991 Validation Loss: 0.5000\n",
      "14661/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5119\n",
      "14662/15000:\n",
      "Training Loss: 0.4801 Validation Loss: 0.5046\n",
      "14663/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5020\n",
      "14664/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5241\n",
      "14665/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5177\n",
      "14666/15000:\n",
      "Training Loss: 0.4750 Validation Loss: 0.5093\n",
      "14667/15000:\n",
      "Training Loss: 0.5001 Validation Loss: 0.5048\n",
      "14668/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5129\n",
      "14669/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5144\n",
      "14670/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5131\n",
      "14671/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5138\n",
      "14672/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.5065\n",
      "14673/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5040\n",
      "14674/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5143\n",
      "14675/15000:\n",
      "Training Loss: 0.4702 Validation Loss: 0.5262\n",
      "14676/15000:\n",
      "Training Loss: 0.4951 Validation Loss: 0.5213\n",
      "14677/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5178\n",
      "14678/15000:\n",
      "Training Loss: 0.4923 Validation Loss: 0.5121\n",
      "14679/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5173\n",
      "14680/15000:\n",
      "Training Loss: 0.5017 Validation Loss: 0.5049\n",
      "14681/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5029\n",
      "14682/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5098\n",
      "14683/15000:\n",
      "Training Loss: 0.4894 Validation Loss: 0.5062\n",
      "14684/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5058\n",
      "14685/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5143\n",
      "14686/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5129\n",
      "14687/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5091\n",
      "14688/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5075\n",
      "14689/15000:\n",
      "Training Loss: 0.4830 Validation Loss: 0.5165\n",
      "14690/15000:\n",
      "Training Loss: 0.4901 Validation Loss: 0.5126\n",
      "14691/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5104\n",
      "14692/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5124\n",
      "14693/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.5046\n",
      "14694/15000:\n",
      "Training Loss: 0.4804 Validation Loss: 0.5062\n",
      "14695/15000:\n",
      "Training Loss: 0.5000 Validation Loss: 0.5179\n",
      "14696/15000:\n",
      "Training Loss: 0.5095 Validation Loss: 0.5175\n",
      "14697/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5180\n",
      "14698/15000:\n",
      "Training Loss: 0.4957 Validation Loss: 0.5176\n",
      "14699/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5193\n",
      "14700/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5006\n",
      "14701/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5026\n",
      "14702/15000:\n",
      "Training Loss: 0.4897 Validation Loss: 0.5020\n",
      "14703/15000:\n",
      "Training Loss: 0.4864 Validation Loss: 0.5064\n",
      "14704/15000:\n",
      "Training Loss: 0.4668 Validation Loss: 0.5103\n",
      "14705/15000:\n",
      "Training Loss: 0.4950 Validation Loss: 0.5172\n",
      "14706/15000:\n",
      "Training Loss: 0.4947 Validation Loss: 0.5118\n",
      "14707/15000:\n",
      "Training Loss: 0.4734 Validation Loss: 0.5109\n",
      "14708/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5083\n",
      "14709/15000:\n",
      "Training Loss: 0.4812 Validation Loss: 0.5143\n",
      "14710/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5262\n",
      "14711/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5083\n",
      "14712/15000:\n",
      "Training Loss: 0.4703 Validation Loss: 0.5204\n",
      "14713/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5112\n",
      "14714/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5165\n",
      "14715/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5113\n",
      "14716/15000:\n",
      "Training Loss: 0.4755 Validation Loss: 0.5078\n",
      "14717/15000:\n",
      "Training Loss: 0.4871 Validation Loss: 0.5023\n",
      "14718/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5079\n",
      "14719/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5037\n",
      "14720/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5132\n",
      "14721/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5087\n",
      "14722/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5162\n",
      "14723/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5097\n",
      "14724/15000:\n",
      "Training Loss: 0.4875 Validation Loss: 0.5080\n",
      "14725/15000:\n",
      "Training Loss: 0.4925 Validation Loss: 0.5046\n",
      "14726/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5016\n",
      "14727/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5061\n",
      "14728/15000:\n",
      "Training Loss: 0.4719 Validation Loss: 0.5056\n",
      "14729/15000:\n",
      "Training Loss: 0.4826 Validation Loss: 0.5188\n",
      "14730/15000:\n",
      "Training Loss: 0.5062 Validation Loss: 0.5009\n",
      "14731/15000:\n",
      "Training Loss: 0.4689 Validation Loss: 0.5036\n",
      "14732/15000:\n",
      "Training Loss: 0.4674 Validation Loss: 0.5051\n",
      "14733/15000:\n",
      "Training Loss: 0.4815 Validation Loss: 0.5179\n",
      "14734/15000:\n",
      "Training Loss: 0.5114 Validation Loss: 0.5058\n",
      "14735/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.4993\n",
      "14736/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.4953\n",
      "14737/15000:\n",
      "Training Loss: 0.4792 Validation Loss: 0.4992\n",
      "14738/15000:\n",
      "Training Loss: 0.4758 Validation Loss: 0.5141\n",
      "14739/15000:\n",
      "Training Loss: 0.4929 Validation Loss: 0.5117\n",
      "14740/15000:\n",
      "Training Loss: 0.4955 Validation Loss: 0.5154\n",
      "14741/15000:\n",
      "Training Loss: 0.5078 Validation Loss: 0.5072\n",
      "14742/15000:\n",
      "Training Loss: 0.4846 Validation Loss: 0.5017\n",
      "14743/15000:\n",
      "Training Loss: 0.4872 Validation Loss: 0.4929\n",
      "14744/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.4927\n",
      "14745/15000:\n",
      "Training Loss: 0.4843 Validation Loss: 0.4997\n",
      "14746/15000:\n",
      "Training Loss: 0.4675 Validation Loss: 0.5109\n",
      "14747/15000:\n",
      "Training Loss: 0.4811 Validation Loss: 0.5094\n",
      "14748/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5105\n",
      "14749/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5055\n",
      "14750/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5160\n",
      "14751/15000:\n",
      "Training Loss: 0.5075 Validation Loss: 0.5032\n",
      "14752/15000:\n",
      "Training Loss: 0.4858 Validation Loss: 0.5069\n",
      "14753/15000:\n",
      "Training Loss: 0.4893 Validation Loss: 0.5006\n",
      "14754/15000:\n",
      "Training Loss: 0.4784 Validation Loss: 0.5014\n",
      "14755/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5056\n",
      "14756/15000:\n",
      "Training Loss: 0.4886 Validation Loss: 0.4969\n",
      "14757/15000:\n",
      "Training Loss: 0.4839 Validation Loss: 0.5005\n",
      "14758/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5007\n",
      "14759/15000:\n",
      "Training Loss: 0.4835 Validation Loss: 0.5027\n",
      "14760/15000:\n",
      "Training Loss: 0.4928 Validation Loss: 0.5112\n",
      "14761/15000:\n",
      "Training Loss: 0.4714 Validation Loss: 0.5049\n",
      "14762/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5125\n",
      "14763/15000:\n",
      "Training Loss: 0.4849 Validation Loss: 0.5097\n",
      "14764/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5178\n",
      "14765/15000:\n",
      "Training Loss: 0.4915 Validation Loss: 0.5086\n",
      "14766/15000:\n",
      "Training Loss: 0.4862 Validation Loss: 0.5139\n",
      "14767/15000:\n",
      "Training Loss: 0.4913 Validation Loss: 0.5122\n",
      "14768/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5135\n",
      "14769/15000:\n",
      "Training Loss: 0.4986 Validation Loss: 0.5250\n",
      "14770/15000:\n",
      "Training Loss: 0.5042 Validation Loss: 0.5198\n",
      "14771/15000:\n",
      "Training Loss: 0.4904 Validation Loss: 0.5089\n",
      "14772/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5079\n",
      "14773/15000:\n",
      "Training Loss: 0.4670 Validation Loss: 0.5001\n",
      "14774/15000:\n",
      "Training Loss: 0.4823 Validation Loss: 0.5004\n",
      "14775/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5048\n",
      "14776/15000:\n",
      "Training Loss: 0.4751 Validation Loss: 0.4964\n",
      "14777/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5025\n",
      "14778/15000:\n",
      "Training Loss: 0.4813 Validation Loss: 0.5053\n",
      "14779/15000:\n",
      "Training Loss: 0.4707 Validation Loss: 0.5124\n",
      "14780/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.4986\n",
      "14781/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5037\n",
      "14782/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.4985\n",
      "14783/15000:\n",
      "Training Loss: 0.4732 Validation Loss: 0.5037\n",
      "14784/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5179\n",
      "14785/15000:\n",
      "Training Loss: 0.4741 Validation Loss: 0.5041\n",
      "14786/15000:\n",
      "Training Loss: 0.4635 Validation Loss: 0.5089\n",
      "14787/15000:\n",
      "Training Loss: 0.4714 Validation Loss: 0.5093\n",
      "14788/15000:\n",
      "Training Loss: 0.4837 Validation Loss: 0.5027\n",
      "14789/15000:\n",
      "Training Loss: 0.4624 Validation Loss: 0.5051\n",
      "14790/15000:\n",
      "Training Loss: 0.4773 Validation Loss: 0.5119\n",
      "14791/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5090\n",
      "14792/15000:\n",
      "Training Loss: 0.5034 Validation Loss: 0.5133\n",
      "14793/15000:\n",
      "Training Loss: 0.5089 Validation Loss: 0.5108\n",
      "14794/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5196\n",
      "14795/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5120\n",
      "14796/15000:\n",
      "Training Loss: 0.4885 Validation Loss: 0.5145\n",
      "14797/15000:\n",
      "Training Loss: 0.4921 Validation Loss: 0.5029\n",
      "14798/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5004\n",
      "14799/15000:\n",
      "Training Loss: 0.5046 Validation Loss: 0.4991\n",
      "14800/15000:\n",
      "Training Loss: 0.4738 Validation Loss: 0.5182\n",
      "14801/15000:\n",
      "Training Loss: 0.4881 Validation Loss: 0.5075\n",
      "14802/15000:\n",
      "Training Loss: 0.4874 Validation Loss: 0.5125\n",
      "14803/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5091\n",
      "14804/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5026\n",
      "14805/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5121\n",
      "14806/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5212\n",
      "14807/15000:\n",
      "Training Loss: 0.4933 Validation Loss: 0.5140\n",
      "14808/15000:\n",
      "Training Loss: 0.4852 Validation Loss: 0.5156\n",
      "14809/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5133\n",
      "14810/15000:\n",
      "Training Loss: 0.4761 Validation Loss: 0.5046\n",
      "14811/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5136\n",
      "14812/15000:\n",
      "Training Loss: 0.4764 Validation Loss: 0.5255\n",
      "14813/15000:\n",
      "Training Loss: 0.5073 Validation Loss: 0.5198\n",
      "14814/15000:\n",
      "Training Loss: 0.5022 Validation Loss: 0.5259\n",
      "14815/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5116\n",
      "14816/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.5169\n",
      "14817/15000:\n",
      "Training Loss: 0.4714 Validation Loss: 0.5178\n",
      "14818/15000:\n",
      "Training Loss: 0.4994 Validation Loss: 0.5156\n",
      "14819/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5241\n",
      "14820/15000:\n",
      "Training Loss: 0.5068 Validation Loss: 0.5197\n",
      "14821/15000:\n",
      "Training Loss: 0.5070 Validation Loss: 0.5051\n",
      "14822/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5107\n",
      "14823/15000:\n",
      "Training Loss: 0.4818 Validation Loss: 0.5106\n",
      "14824/15000:\n",
      "Training Loss: 0.4712 Validation Loss: 0.5195\n",
      "14825/15000:\n",
      "Training Loss: 0.4962 Validation Loss: 0.5123\n",
      "14826/15000:\n",
      "Training Loss: 0.4954 Validation Loss: 0.5092\n",
      "14827/15000:\n",
      "Training Loss: 0.4677 Validation Loss: 0.5147\n",
      "14828/15000:\n",
      "Training Loss: 0.5053 Validation Loss: 0.5126\n",
      "14829/15000:\n",
      "Training Loss: 0.4943 Validation Loss: 0.5129\n",
      "14830/15000:\n",
      "Training Loss: 0.5074 Validation Loss: 0.5223\n",
      "14831/15000:\n",
      "Training Loss: 0.4996 Validation Loss: 0.5139\n",
      "14832/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5201\n",
      "14833/15000:\n",
      "Training Loss: 0.5021 Validation Loss: 0.5005\n",
      "14834/15000:\n",
      "Training Loss: 0.5122 Validation Loss: 0.5085\n",
      "14835/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5089\n",
      "14836/15000:\n",
      "Training Loss: 0.5061 Validation Loss: 0.5117\n",
      "14837/15000:\n",
      "Training Loss: 0.5016 Validation Loss: 0.5130\n",
      "14838/15000:\n",
      "Training Loss: 0.4982 Validation Loss: 0.5070\n",
      "14839/15000:\n",
      "Training Loss: 0.4840 Validation Loss: 0.5080\n",
      "14840/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5081\n",
      "14841/15000:\n",
      "Training Loss: 0.4819 Validation Loss: 0.5064\n",
      "14842/15000:\n",
      "Training Loss: 0.4908 Validation Loss: 0.5098\n",
      "14843/15000:\n",
      "Training Loss: 0.4807 Validation Loss: 0.5135\n",
      "14844/15000:\n",
      "Training Loss: 0.4747 Validation Loss: 0.5109\n",
      "14845/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5076\n",
      "14846/15000:\n",
      "Training Loss: 0.4999 Validation Loss: 0.5057\n",
      "14847/15000:\n",
      "Training Loss: 0.4710 Validation Loss: 0.5157\n",
      "14848/15000:\n",
      "Training Loss: 0.4912 Validation Loss: 0.5072\n",
      "14849/15000:\n",
      "Training Loss: 0.4873 Validation Loss: 0.5294\n",
      "14850/15000:\n",
      "Training Loss: 0.5024 Validation Loss: 0.5070\n",
      "14851/15000:\n",
      "Training Loss: 0.4914 Validation Loss: 0.5109\n",
      "14852/15000:\n",
      "Training Loss: 0.4633 Validation Loss: 0.4968\n",
      "14853/15000:\n",
      "Training Loss: 0.4861 Validation Loss: 0.5024\n",
      "14854/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5000\n",
      "14855/15000:\n",
      "Training Loss: 0.4895 Validation Loss: 0.5012\n",
      "14856/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5064\n",
      "14857/15000:\n",
      "Training Loss: 0.4869 Validation Loss: 0.5017\n",
      "14858/15000:\n",
      "Training Loss: 0.4814 Validation Loss: 0.5142\n",
      "14859/15000:\n",
      "Training Loss: 0.4770 Validation Loss: 0.5012\n",
      "14860/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5061\n",
      "14861/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.5037\n",
      "14862/15000:\n",
      "Training Loss: 0.4799 Validation Loss: 0.5045\n",
      "14863/15000:\n",
      "Training Loss: 0.4604 Validation Loss: 0.5035\n",
      "14864/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.4972\n",
      "14865/15000:\n",
      "Training Loss: 0.4677 Validation Loss: 0.5106\n",
      "14866/15000:\n",
      "Training Loss: 0.4855 Validation Loss: 0.5032\n",
      "14867/15000:\n",
      "Training Loss: 0.4789 Validation Loss: 0.5051\n",
      "14868/15000:\n",
      "Training Loss: 0.4742 Validation Loss: 0.5117\n",
      "14869/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5103\n",
      "14870/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5107\n",
      "14871/15000:\n",
      "Training Loss: 0.4865 Validation Loss: 0.5099\n",
      "14872/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5079\n",
      "14873/15000:\n",
      "Training Loss: 0.4795 Validation Loss: 0.5209\n",
      "14874/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5208\n",
      "14875/15000:\n",
      "Training Loss: 0.4983 Validation Loss: 0.5183\n",
      "14876/15000:\n",
      "Training Loss: 0.5065 Validation Loss: 0.5091\n",
      "14877/15000:\n",
      "Training Loss: 0.5031 Validation Loss: 0.5034\n",
      "14878/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5084\n",
      "14879/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5020\n",
      "14880/15000:\n",
      "Training Loss: 0.5036 Validation Loss: 0.5144\n",
      "14881/15000:\n",
      "Training Loss: 0.4793 Validation Loss: 0.5073\n",
      "14882/15000:\n",
      "Training Loss: 0.4740 Validation Loss: 0.5115\n",
      "14883/15000:\n",
      "Training Loss: 0.4765 Validation Loss: 0.5003\n",
      "14884/15000:\n",
      "Training Loss: 0.4670 Validation Loss: 0.5101\n",
      "14885/15000:\n",
      "Training Loss: 0.4711 Validation Loss: 0.5126\n",
      "14886/15000:\n",
      "Training Loss: 0.4937 Validation Loss: 0.5130\n",
      "14887/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5263\n",
      "14888/15000:\n",
      "Training Loss: 0.4878 Validation Loss: 0.5150\n",
      "14889/15000:\n",
      "Training Loss: 0.4961 Validation Loss: 0.5129\n",
      "14890/15000:\n",
      "Training Loss: 0.4860 Validation Loss: 0.5089\n",
      "14891/15000:\n",
      "Training Loss: 0.4931 Validation Loss: 0.5102\n",
      "14892/15000:\n",
      "Training Loss: 0.4787 Validation Loss: 0.5026\n",
      "14893/15000:\n",
      "Training Loss: 0.4808 Validation Loss: 0.5099\n",
      "14894/15000:\n",
      "Training Loss: 0.4889 Validation Loss: 0.5062\n",
      "14895/15000:\n",
      "Training Loss: 0.4727 Validation Loss: 0.5084\n",
      "14896/15000:\n",
      "Training Loss: 0.4737 Validation Loss: 0.5003\n",
      "14897/15000:\n",
      "Training Loss: 0.4698 Validation Loss: 0.5067\n",
      "14898/15000:\n",
      "Training Loss: 0.4628 Validation Loss: 0.5036\n",
      "14899/15000:\n",
      "Training Loss: 0.4891 Validation Loss: 0.5059\n",
      "14900/15000:\n",
      "Training Loss: 0.4702 Validation Loss: 0.5086\n",
      "14901/15000:\n",
      "Training Loss: 0.4916 Validation Loss: 0.5163\n",
      "14902/15000:\n",
      "Training Loss: 0.4958 Validation Loss: 0.5179\n",
      "14903/15000:\n",
      "Training Loss: 0.4976 Validation Loss: 0.5156\n",
      "14904/15000:\n",
      "Training Loss: 0.4969 Validation Loss: 0.5038\n",
      "14905/15000:\n",
      "Training Loss: 0.5051 Validation Loss: 0.5119\n",
      "14906/15000:\n",
      "Training Loss: 0.5058 Validation Loss: 0.5178\n",
      "14907/15000:\n",
      "Training Loss: 0.4966 Validation Loss: 0.5006\n",
      "14908/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5075\n",
      "14909/15000:\n",
      "Training Loss: 0.4926 Validation Loss: 0.5031\n",
      "14910/15000:\n",
      "Training Loss: 0.4733 Validation Loss: 0.5049\n",
      "14911/15000:\n",
      "Training Loss: 0.4762 Validation Loss: 0.5039\n",
      "14912/15000:\n",
      "Training Loss: 0.4794 Validation Loss: 0.5202\n",
      "14913/15000:\n",
      "Training Loss: 0.5010 Validation Loss: 0.5035\n",
      "14914/15000:\n",
      "Training Loss: 0.4834 Validation Loss: 0.5110\n",
      "14915/15000:\n",
      "Training Loss: 0.4743 Validation Loss: 0.5172\n",
      "14916/15000:\n",
      "Training Loss: 0.4892 Validation Loss: 0.5067\n",
      "14917/15000:\n",
      "Training Loss: 0.4580 Validation Loss: 0.5081\n",
      "14918/15000:\n",
      "Training Loss: 0.4859 Validation Loss: 0.5032\n",
      "14919/15000:\n",
      "Training Loss: 0.4939 Validation Loss: 0.4985\n",
      "14920/15000:\n",
      "Training Loss: 0.4745 Validation Loss: 0.5141\n",
      "14921/15000:\n",
      "Training Loss: 0.4772 Validation Loss: 0.5056\n",
      "14922/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5035\n",
      "14923/15000:\n",
      "Training Loss: 0.4911 Validation Loss: 0.5030\n",
      "14924/15000:\n",
      "Training Loss: 0.4630 Validation Loss: 0.4996\n",
      "14925/15000:\n",
      "Training Loss: 0.4586 Validation Loss: 0.5049\n",
      "14926/15000:\n",
      "Training Loss: 0.4827 Validation Loss: 0.4988\n",
      "14927/15000:\n",
      "Training Loss: 0.4884 Validation Loss: 0.5012\n",
      "14928/15000:\n",
      "Training Loss: 0.4907 Validation Loss: 0.5022\n",
      "14929/15000:\n",
      "Training Loss: 0.4766 Validation Loss: 0.5041\n",
      "14930/15000:\n",
      "Training Loss: 0.4944 Validation Loss: 0.5001\n",
      "14931/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5009\n",
      "14932/15000:\n",
      "Training Loss: 0.4800 Validation Loss: 0.5036\n",
      "14933/15000:\n",
      "Training Loss: 0.4748 Validation Loss: 0.5157\n",
      "14934/15000:\n",
      "Training Loss: 0.4940 Validation Loss: 0.5061\n",
      "14935/15000:\n",
      "Training Loss: 0.4836 Validation Loss: 0.5137\n",
      "14936/15000:\n",
      "Training Loss: 0.4728 Validation Loss: 0.5066\n",
      "14937/15000:\n",
      "Training Loss: 0.4980 Validation Loss: 0.5041\n",
      "14938/15000:\n",
      "Training Loss: 0.4927 Validation Loss: 0.4995\n",
      "14939/15000:\n",
      "Training Loss: 0.4803 Validation Loss: 0.5147\n",
      "14940/15000:\n",
      "Training Loss: 0.4709 Validation Loss: 0.5119\n",
      "14941/15000:\n",
      "Training Loss: 0.4833 Validation Loss: 0.5095\n",
      "14942/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5240\n",
      "14943/15000:\n",
      "Training Loss: 0.5167 Validation Loss: 0.5751\n",
      "14944/15000:\n",
      "Training Loss: 0.5403 Validation Loss: 0.4994\n",
      "14945/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5048\n",
      "14946/15000:\n",
      "Training Loss: 0.4763 Validation Loss: 0.5043\n",
      "14947/15000:\n",
      "Training Loss: 0.4552 Validation Loss: 0.5187\n",
      "14948/15000:\n",
      "Training Loss: 0.5035 Validation Loss: 0.5105\n",
      "14949/15000:\n",
      "Training Loss: 0.4880 Validation Loss: 0.5109\n",
      "14950/15000:\n",
      "Training Loss: 0.5066 Validation Loss: 0.5140\n",
      "14951/15000:\n",
      "Training Loss: 0.4882 Validation Loss: 0.5130\n",
      "14952/15000:\n",
      "Training Loss: 0.4810 Validation Loss: 0.5103\n",
      "14953/15000:\n",
      "Training Loss: 0.4791 Validation Loss: 0.4979\n",
      "14954/15000:\n",
      "Training Loss: 0.4774 Validation Loss: 0.5055\n",
      "14955/15000:\n",
      "Training Loss: 0.4777 Validation Loss: 0.5064\n",
      "14956/15000:\n",
      "Training Loss: 0.4767 Validation Loss: 0.5161\n",
      "14957/15000:\n",
      "Training Loss: 0.5019 Validation Loss: 0.5053\n",
      "14958/15000:\n",
      "Training Loss: 0.4636 Validation Loss: 0.5128\n",
      "14959/15000:\n",
      "Training Loss: 0.4822 Validation Loss: 0.5078\n",
      "14960/15000:\n",
      "Training Loss: 0.4731 Validation Loss: 0.5036\n",
      "14961/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5027\n",
      "14962/15000:\n",
      "Training Loss: 0.4759 Validation Loss: 0.5155\n",
      "14963/15000:\n",
      "Training Loss: 0.4757 Validation Loss: 0.5109\n",
      "14964/15000:\n",
      "Training Loss: 0.4786 Validation Loss: 0.5151\n",
      "14965/15000:\n",
      "Training Loss: 0.4887 Validation Loss: 0.5057\n",
      "14966/15000:\n",
      "Training Loss: 0.4780 Validation Loss: 0.5097\n",
      "14967/15000:\n",
      "Training Loss: 0.4842 Validation Loss: 0.5082\n",
      "14968/15000:\n",
      "Training Loss: 0.4783 Validation Loss: 0.5147\n",
      "14969/15000:\n",
      "Training Loss: 0.4782 Validation Loss: 0.5098\n",
      "14970/15000:\n",
      "Training Loss: 0.4918 Validation Loss: 0.5152\n",
      "14971/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5108\n",
      "14972/15000:\n",
      "Training Loss: 0.4809 Validation Loss: 0.5048\n",
      "14973/15000:\n",
      "Training Loss: 0.4760 Validation Loss: 0.5114\n",
      "14974/15000:\n",
      "Training Loss: 0.4775 Validation Loss: 0.5078\n",
      "14975/15000:\n",
      "Training Loss: 0.4844 Validation Loss: 0.5100\n",
      "14976/15000:\n",
      "Training Loss: 0.4821 Validation Loss: 0.5084\n",
      "14977/15000:\n",
      "Training Loss: 0.4853 Validation Loss: 0.5106\n",
      "14978/15000:\n",
      "Training Loss: 0.4856 Validation Loss: 0.5097\n",
      "14979/15000:\n",
      "Training Loss: 0.4820 Validation Loss: 0.5103\n",
      "14980/15000:\n",
      "Training Loss: 0.4721 Validation Loss: 0.5045\n",
      "14981/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.5075\n",
      "14982/15000:\n",
      "Training Loss: 0.4816 Validation Loss: 0.5106\n",
      "14983/15000:\n",
      "Training Loss: 0.4867 Validation Loss: 0.5071\n",
      "14984/15000:\n",
      "Training Loss: 0.4829 Validation Loss: 0.5184\n",
      "14985/15000:\n",
      "Training Loss: 0.4785 Validation Loss: 0.5031\n",
      "14986/15000:\n",
      "Training Loss: 0.4848 Validation Loss: 0.5109\n",
      "14987/15000:\n",
      "Training Loss: 0.4905 Validation Loss: 0.5058\n",
      "14988/15000:\n",
      "Training Loss: 0.4854 Validation Loss: 0.5053\n",
      "14989/15000:\n",
      "Training Loss: 0.4654 Validation Loss: 0.5051\n",
      "14990/15000:\n",
      "Training Loss: 0.4666 Validation Loss: 0.5122\n",
      "14991/15000:\n",
      "Training Loss: 0.4796 Validation Loss: 0.4989\n",
      "14992/15000:\n",
      "Training Loss: 0.4637 Validation Loss: 0.5066\n",
      "14993/15000:\n",
      "Training Loss: 0.4806 Validation Loss: 0.4994\n",
      "14994/15000:\n",
      "Training Loss: 0.4664 Validation Loss: 0.5062\n",
      "14995/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5074\n",
      "14996/15000:\n",
      "Training Loss: 0.4749 Validation Loss: 0.5146\n",
      "14997/15000:\n",
      "Training Loss: 0.4838 Validation Loss: 0.5070\n",
      "14998/15000:\n",
      "Training Loss: 0.4746 Validation Loss: 0.5147\n",
      "14999/15000:\n",
      "Training Loss: 0.4924 Validation Loss: 0.5195\n",
      "15000/15000:\n",
      "Training Loss: 0.4967 Validation Loss: 0.5060\n"
     ]
    }
   ],
   "source": [
    "second_model = second_model.fit(X_train, y_train, X_test, y_test, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d6554ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7443946188340808"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = second_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1632ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e1db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf3705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
