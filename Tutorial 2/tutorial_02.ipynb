{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d46373b",
   "metadata": {},
   "source": [
    "### 1. Load the Fish Data, split into train and test set, and standardize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4671bbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    Species  Length1  Length2  Length3   Height   Width  Weight\n0     Bream     23.2     25.4     30.0  11.5200  4.0200   242.0\n1     Bream     24.0     26.3     31.2  12.4800  4.3056   290.0\n2     Bream     23.9     26.5     31.1  12.3778  4.6961   340.0\n3     Bream     26.3     29.0     33.5  12.7300  4.4555   363.0\n4     Bream     26.5     29.0     34.0  12.4440  5.1340   430.0\n..      ...      ...      ...      ...      ...     ...     ...\n154   Smelt     11.5     12.2     13.4   2.0904  1.3936    12.2\n155   Smelt     11.7     12.4     13.5   2.4300  1.2690    13.4\n156   Smelt     12.1     13.0     13.8   2.2770  1.2558    12.2\n157   Smelt     13.2     14.3     15.2   2.8728  2.0672    19.7\n158   Smelt     13.8     15.0     16.2   2.9322  1.8792    19.9\n\n[159 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Species</th>\n      <th>Length1</th>\n      <th>Length2</th>\n      <th>Length3</th>\n      <th>Height</th>\n      <th>Width</th>\n      <th>Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bream</td>\n      <td>23.2</td>\n      <td>25.4</td>\n      <td>30.0</td>\n      <td>11.5200</td>\n      <td>4.0200</td>\n      <td>242.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bream</td>\n      <td>24.0</td>\n      <td>26.3</td>\n      <td>31.2</td>\n      <td>12.4800</td>\n      <td>4.3056</td>\n      <td>290.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bream</td>\n      <td>23.9</td>\n      <td>26.5</td>\n      <td>31.1</td>\n      <td>12.3778</td>\n      <td>4.6961</td>\n      <td>340.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bream</td>\n      <td>26.3</td>\n      <td>29.0</td>\n      <td>33.5</td>\n      <td>12.7300</td>\n      <td>4.4555</td>\n      <td>363.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bream</td>\n      <td>26.5</td>\n      <td>29.0</td>\n      <td>34.0</td>\n      <td>12.4440</td>\n      <td>5.1340</td>\n      <td>430.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>Smelt</td>\n      <td>11.5</td>\n      <td>12.2</td>\n      <td>13.4</td>\n      <td>2.0904</td>\n      <td>1.3936</td>\n      <td>12.2</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>Smelt</td>\n      <td>11.7</td>\n      <td>12.4</td>\n      <td>13.5</td>\n      <td>2.4300</td>\n      <td>1.2690</td>\n      <td>13.4</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>Smelt</td>\n      <td>12.1</td>\n      <td>13.0</td>\n      <td>13.8</td>\n      <td>2.2770</td>\n      <td>1.2558</td>\n      <td>12.2</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>Smelt</td>\n      <td>13.2</td>\n      <td>14.3</td>\n      <td>15.2</td>\n      <td>2.8728</td>\n      <td>2.0672</td>\n      <td>19.7</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>Smelt</td>\n      <td>13.8</td>\n      <td>15.0</td>\n      <td>16.2</td>\n      <td>2.9322</td>\n      <td>1.8792</td>\n      <td>19.9</td>\n    </tr>\n  </tbody>\n</table>\n<p>159 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "fish_data = pd.read_csv('fish2.csv')\n",
    "fish_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26e4c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Dummy Variables and convert to torch\n",
    "import torch\n",
    "X = fish_data[['Length1', 'Length2', 'Length3', 'Height', 'Width', 'Species']]\n",
    "X = torch.tensor(pd.get_dummies(X, dtype=float).to_numpy(), dtype=torch.float)\n",
    "y = torch.tensor(fish_data[['Weight']].to_numpy(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a909d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split into train and test set\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "idx = torch.randperm(X.shape[0], generator=generator)\n",
    "X_train, X_test = X[idx[:127],:], X[idx[127:],:]\n",
    "y_train, y_test = y[idx[:127],:], y[idx[127:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b4bec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize Data\n",
    "# Lambda Function\n",
    "standardize = lambda z, z_mean, z_std: (z - z_mean) / (z_std + 1e-5) \n",
    "\n",
    "# Standardize X\n",
    "x_mean, x_std = X_train[:,:5].mean(0, keepdims=True), X_train[:,:5].std(0, keepdims=True)\n",
    "X_train[:,:5], X_test[:,:5] = standardize(X_train[:,:5], x_mean, x_std), standardize(X_test[:,:5], x_mean, x_std)\n",
    "# Standardize y\n",
    "y_mean, y_std = y_train.mean(0, keepdims=True), y_train.std(0, keepdims=True)\n",
    "y_train = standardize(y_train, y_mean, y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x0000021D92EADA30>\n"
     ]
    }
   ],
   "source": [
    "print(y_test.type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "37f35a5d",
   "metadata": {},
   "source": [
    "### 2 Create k Nearest Neighbor Regressor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fc3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNNRegressor:\n",
    "    # k: Number of k Nearest Neighbors\n",
    "    # p: L_p distance function\n",
    "    # Note: output label is simple average of k Nearest Neighbors\n",
    "    def __init__(self, k, p=2.0):\n",
    "        self.k = k\n",
    "        self.p = p\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        y : Array of shape [n_samples, 1]\n",
    "        \"\"\"  \n",
    "        ...\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X, mean=None, std=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        # Calculate distance matrix\n",
    "        dist = ...\n",
    "        dist = dist.pow(self.p).mean(2).pow(1./self.p)\n",
    "        \n",
    "        # Get k nearest neighbots\n",
    "        _, idx_arg = ...\n",
    "        \n",
    "        # Collect labels\n",
    "        train_y = ... # First repeat train labels to match idx_arg\n",
    "        predictions = ... # Next, gather train labels\n",
    "        predictions = ... # Finally, calculate mean\n",
    "        \n",
    "        # Recompute unstandardized data\n",
    "        if mean is not None and std is not None:\n",
    "            predictions = ...\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "k, p = 5, 2.\n",
    "knn_model = kNNRegressor(k, p=p).fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test, y_mean, y_std)\n",
    "mse = ...\n",
    "print(f'The MSE of the {k}-NN model with L_{p}-Distance is: {mse:10.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964685f",
   "metadata": {},
   "source": [
    "### 3. Create Linear Regressor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce1c3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.weight = None\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        y : Array of shape [n_samples, 1]\n",
    "        \"\"\"        \n",
    "        \n",
    "        # prepend a column of ones\n",
    "        ones = numpy.ones((X.shape[0], 1))\n",
    "        X = numpy.concatenate((ones, X), axis=1)\n",
    "\n",
    "        # compute weights\n",
    "        X = torch.tensor(X)\n",
    "        XtX_pinv = torch.inverse(torch.matmul(X.T, X))\n",
    "        X = X.float()\n",
    "        Xty = torch.matmul(X.T, y)\n",
    "        \n",
    "        # dot: matrix multiplication\n",
    "        XtX_pinv = XtX_pinv.float()\n",
    "        self.weight = torch.matmul(XtX_pinv, Xty)\n",
    "        return self\n",
    "                \n",
    "    def predict(self, X, mean=None, std=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        \"\"\"                     \n",
    "        # prepend a column of ones\n",
    "        ones = numpy.ones((X.shape[0], 1))\n",
    "        X = numpy.concatenate((ones, X), axis=1)\n",
    "\n",
    "        # compute predictions\n",
    "        predictions = numpy.dot(X, self.weight)\n",
    "        \n",
    "        # Recompute unstandardized data\n",
    "        if mean is not None and std is not None:\n",
    "            std = std.numpy()\n",
    "            mean = mean.numpy()\n",
    "            predictions = predictions * std + mean\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83d20b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the linear regression model is: 104965.0249\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test, y_mean, y_std)\n",
    "mse = numpy.mean((y_pred - y_test.numpy()) ** 2)\n",
    "print(f'The MSE of the linear regression model is: {mse:10.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447fd24d",
   "metadata": {},
   "source": [
    "### 4. Create a Linear Regressor class, but this time use PyTorch autograd function to calculate the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d40a7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionGradientDescent:\n",
    "    def __init__(self, input_features, lr=0.1, epochs=1000):\n",
    "        self.weight = nn.Parameter(torch.zeros(input_features + 1, 1))\n",
    "        self.lr, self.epochs = lr, epochs\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        y : Array of shape [n_samples, 1]\n",
    "        \"\"\"        \n",
    "        for _ in range(self.epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = nn.functional.mse_loss(y_pred, y)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                self.weight -= self.lr * self.weight.grad\n",
    "            self.weight.grad = None\n",
    "        return self\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        \"\"\"                     \n",
    "        # prepend a column of ones\n",
    "        ones = numpy.ones((X.shape[0], 1))\n",
    "        X = numpy.concatenate((ones, X), axis=1)\n",
    "\n",
    "        # compute predictions\n",
    "        predictions = torch.matmul(torch.Tensor(X), self.weight)\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, X, mean=None, std=None):\n",
    "        # Execute forward pass\n",
    "        predictions = self.forward(X)\n",
    "        \n",
    "        # Recompute unstandardized data\n",
    "        if mean is not None and std is not None:\n",
    "            predictions = predictions * std + mean\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4be0098",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[63], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m lrd_model \u001B[38;5;241m=\u001B[39m \u001B[43mLinearRegressionGradientDescent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m lrd_model\u001B[38;5;241m.\u001B[39mpredict(X_test, y_mean, y_std)\n\u001B[0;32m      3\u001B[0m mse \u001B[38;5;241m=\u001B[39m ((y_pred \u001B[38;5;241m-\u001B[39m y_test)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mmean()\n",
      "Cell \u001B[1;32mIn[62], line 16\u001B[0m, in \u001B[0;36mLinearRegressionGradientDescent.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03m----------\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03mX : Array of shape [n_samples, n_features]\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03my : Array of shape [n_samples, 1]\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m        \n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs):\n\u001B[1;32m---> 16\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mmse_loss(y_pred, y)\n\u001B[0;32m     18\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "Cell \u001B[1;32mIn[62], line 33\u001B[0m, in \u001B[0;36mLinearRegressionGradientDescent.forward\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     31\u001B[0m ones \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39mones((X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m#X = numpy.concatenate((ones, X), axis=1)\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mones\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# compute predictions\u001B[39;00m\n\u001B[0;32m     35\u001B[0m predictions \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(torch\u001B[38;5;241m.\u001B[39mTensor(X), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight)\n",
      "\u001B[1;31mTypeError\u001B[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "lrd_model = LinearRegressionGradientDescent(12).fit(X_train, y_train)\n",
    "y_pred = lrd_model.predict(X_test, y_mean, y_std)\n",
    "mse = ((y_pred - y_test)**2).mean()\n",
    "print(f'The MSE of the gradient descent linear regression model is: {mse:10.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b513974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
