{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918a149d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T22:03:16.693632Z",
     "start_time": "2023-07-28T22:03:13.775976900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58103ac6",
   "metadata": {},
   "source": [
    "### First, we load the titatic dataset and convert all categorical variables to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2501c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T22:05:26.811623500Z",
     "start_time": "2023-07-28T22:05:26.705246700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Survived        Age  SibSp  Parch     Fare  Pclass_1   \n0              1         0  22.000000      1      0   7.2500     False  \\\n1              2         1  38.000000      1      0  71.2833      True   \n2              3         1  26.000000      0      0   7.9250     False   \n3              4         1  35.000000      1      0  53.1000      True   \n4              5         0  35.000000      0      0   8.0500     False   \n..           ...       ...        ...    ...    ...      ...       ...   \n886          887         0  27.000000      0      0  13.0000     False   \n887          888         1  19.000000      0      0  30.0000      True   \n888          889         0  29.699118      1      2  23.4500     False   \n889          890         1  26.000000      0      0  30.0000      True   \n890          891         0  32.000000      0      0   7.7500     False   \n\n     Pclass_2  Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q   \n0       False      True       False      True       False       False  \\\n1       False     False        True     False        True       False   \n2       False      True        True     False       False       False   \n3       False     False        True     False       False       False   \n4       False      True       False      True       False       False   \n..        ...       ...         ...       ...         ...         ...   \n886      True     False       False      True       False       False   \n887     False     False        True     False       False       False   \n888     False      True        True     False       False       False   \n889     False     False       False      True        True       False   \n890     False      True       False      True       False        True   \n\n     Embarked_S  \n0          True  \n1         False  \n2          True  \n3          True  \n4          True  \n..          ...  \n886        True  \n887        True  \n888        True  \n889       False  \n890       False  \n\n[891 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>22.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>38.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>26.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>35.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>35.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>27.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>19.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>29.699118</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>26.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>32.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.read_csv('titanic.csv')\n",
    "data_frame = data_frame.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "data_frame = pd.get_dummies(data_frame, columns=['Pclass', 'Sex','Embarked'])\n",
    "data_frame = data_frame.fillna(data_frame.mean())\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d57442",
   "metadata": {},
   "source": [
    "### Next, we convert the dataset to a NumPy array and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69c4087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T22:10:30.258209600Z",
     "start_time": "2023-07-28T22:10:30.225999900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[29.69911765,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  1.        ],\n       [25.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  1.        ],\n       [24.        ,  0.        ,  2.        , ...,  0.        ,\n         0.        ,  1.        ],\n       ...,\n       [41.        ,  2.        ,  0.        , ...,  0.        ,\n         0.        ,  1.        ],\n       [14.        ,  1.        ,  2.        , ...,  0.        ,\n         0.        ,  1.        ],\n       [21.        ,  0.        ,  1.        , ...,  0.        ,\n         0.        ,  1.        ]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data_frame[['Survived']].to_numpy().astype(float)\n",
    "observ = data_frame.drop(['PassengerId', 'Survived'], axis=1).to_numpy().astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(observ, labels, test_size=0.25, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55cc6cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T22:09:55.152872300Z",
     "start_time": "2023-07-28T22:09:55.122844700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.00528593,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  1.        ],\n       [-0.00529525,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  1.        ],\n       [-0.00529724,  0.        ,  2.        , ...,  0.        ,\n         0.        ,  1.        ],\n       ...,\n       [-0.00526351,  2.        ,  0.        , ...,  0.        ,\n         0.        ,  1.        ],\n       [-0.00531708,  1.        ,  2.        , ...,  0.        ,\n         0.        ,  1.        ],\n       [-0.00530319,  0.        ,  1.        , ...,  0.        ,\n         0.        ,  1.        ]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to normalize Age and Fare, so columns 0,3\n",
    "age_min, age_max = data_frame['Age'].min(), data_frame['Age'].max()\n",
    "fare_min, fare_max = data_frame['Fare'].min(), data_frame['Fare'].max()\n",
    "# Apply\n",
    "X_train[:,0] = (X_train[:,0] - age_min) / (age_max - age_min + 1e-5)\n",
    "X_test[:,0] = (X_test[:,0] - age_min) / (age_max - age_min + 1e-5)\n",
    "X_train[:,3] = (X_train[:,3] - fare_min) / (fare_max - fare_min + 1e-5)\n",
    "X_test[:,3] = (X_test[:,3] - fare_min) / (fare_max - fare_min + 1e-5)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c978636",
   "metadata": {},
   "source": [
    "### Now, let's create our sequential model with four linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad6c9f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.744501400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "first_model = nn.Sequential(\n",
    "    nn.Linear(..., 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(64, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d05f0",
   "metadata": {},
   "source": [
    "### We can already apply it to our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5b5b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T22:03:18.748507200Z",
     "start_time": "2023-07-28T22:03:18.747502900Z"
    }
   },
   "outputs": [],
   "source": [
    "first_model(torch.tensor(X_test[:20], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e2188",
   "metadata": {},
   "source": [
    "### Now, let's fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6631ad",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.751517100Z"
    }
   },
   "outputs": [],
   "source": [
    "first_model.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44284ecb",
   "metadata": {},
   "source": [
    "### As you may have seen, this does not work. We have to implement the training ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b3c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T22:03:18.824010800Z",
     "start_time": "2023-07-28T22:03:18.754519300Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyMLPModel(nn.Module):\n",
    "    def __init__(self, input, *hidden_layers, lr=0.1, dropout=0.2):\n",
    "        super().__init__() # <- Very important!\n",
    "        self.lr = lr\n",
    "        ## Build model\n",
    "        n_neurons = [input] + list(hidden_layers)\n",
    "        self.layers = []\n",
    "        for i, o in zip(n_neurons[:-1], n_neurons[1:]):\n",
    "            self.layers += [\n",
    "                ...\n",
    "            ]\n",
    "        self.layers += [\n",
    "            ...\n",
    "        ]\n",
    "        \n",
    "        self.layers = nn.Sequential(*self.layers) # Create a sequential model\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "    \n",
    "    def predict(self, X, th=0.5):\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            y_hat = ...\n",
    "        return (...).float()\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        y_hat = self(X)\n",
    "        return ...\n",
    "        \n",
    "    def validation_step(self, X, y):\n",
    "        with torch.no_grad():\n",
    "            return ...\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_valid, y_valid, epochs=10):\n",
    "        ## Convert dataset\n",
    "        X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float)\n",
    "        \n",
    "        X_valid = torch.tensor(X_valid, dtype=torch.float)\n",
    "        y_valid = torch.tensor(y_valid, dtype=torch.float)\n",
    "        \n",
    "        ## Load Optimizer\n",
    "        optimizer = self.configure_optimizers()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f'{epoch+1}/{epochs}:')\n",
    "            # Training\n",
    "            self.train() # Set model to training mode\n",
    "            ... # Sets all gradients to Zero\n",
    "            loss = ...# Execute Forward pass and calculate Loss\n",
    "            ... # Execute Backward pass\n",
    "            ... # Update weights\n",
    "            self.eval() # Set model to validation mode\n",
    "            \n",
    "            # Validation\n",
    "            loss_valid = ...\n",
    "            print(f'Training Loss: {loss.item():1.4f}', f'Validation Loss: {loss_valid.item():1.4f}')\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4f12f",
   "metadata": {},
   "source": [
    "### Create a model similar to the one before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cdd767",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.758524600Z"
    }
   },
   "outputs": [],
   "source": [
    "second_model = MyMLPModel(X_train.shape[1], 32, 16, 8, 4)\n",
    "second_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b6bdd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.760535800Z"
    }
   },
   "outputs": [],
   "source": [
    "second_model.predict(X_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee888a",
   "metadata": {},
   "source": [
    "### Train it and calculate the test accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343e931",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.763548800Z"
    }
   },
   "outputs": [],
   "source": [
    "second_model = second_model.fit(X_train, y_train, X_test, y_test, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6554ff5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.765550100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = second_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1632ddf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.767553800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e1db8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.769102800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf3705",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-28T22:03:18.772109600Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
